{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "year = input(\"Enter year (e.g. 2025): \").strip()\n",
    "quarter = input(\"Enter quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "BASE_DIR = os.path.join(\n",
    "    \"C:\\\\Users\",\n",
    "    os.environ.get(\"USERNAME\"),\n",
    "    \"Documents\",\n",
    "    \"Equity\"\n",
    ")\n",
    "\n",
    "HOME = os.path.join(BASE_DIR, f\"{year}_{quarter}\")\n",
    "DATA_DIR = os.path.join(HOME, \"data\")\n",
    "\n",
    "print(\"Reading data from:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "cashflows = pd.read_parquet(os.path.join(DATA_DIR, \"cashflows.parquet\"))\n",
    "kmp = pd.read_parquet(os.path.join(DATA_DIR, \"kmp.parquet\"))\n",
    "grades = pd.read_parquet(os.path.join(DATA_DIR, \"grades.parquet\"))\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(f\"cashflows: {cashflows.shape}\")\n",
    "print(f\"kmp:        {kmp.shape}\")\n",
    "print(f\"grades:     {grades.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure quarter is numeric 1-4 (adjust if yours is 'Q1' style)\n",
    "# cashflows['Quarter of Transaction Date'] should already be 1..4 based on your SQL\n",
    "\n",
    "cashflows[\"q_idx\"] = cashflows[\"Year of Transaction Date\"] * 4 + cashflows[\"Quarter of Transaction Date\"]\n",
    "\n",
    "# If grades uses different column names, align them (edit as needed)\n",
    "# grades = grades.rename(columns={\"Year\": \"Year of Transaction Date\", \"Quarter\": \"Quarter of Transaction Date\"})\n",
    "grades[\"q_idx\"] = grades[\"Year of Transaction Date\"] * 4 + grades[\"Quarter of Transaction Date\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ca474",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pgrade_by_fund = (\n",
    "    cashflows\n",
    "    .sort_values([\"FundID\", \"q_idx\"])\n",
    "    .groupby(\"FundID\")[\"First Grading-P\"]\n",
    "    .apply(lambda s: s.dropna().iloc[0] if s.notna().any() else pd.NA)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cashflows.merge(\n",
    "    grades[[\"FundID\", \"Year of Transaction Date\", \"Quarter of Transaction Date\", \"Grade\"]],\n",
    "    on=[\"FundID\", \"Year of Transaction Date\", \"Quarter of Transaction Date\"],\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge grades onto cashflows timeline\n",
    "df = cashflows.merge(\n",
    "    grades[[\"FundID\", \"Year of Transaction Date\", \"Quarter of Transaction Date\", \"Grade\"]],\n",
    "    on=[\"FundID\", \"Year of Transaction Date\", \"Quarter of Transaction Date\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Build quarter index and sort\n",
    "df[\"q_idx\"] = df[\"Year of Transaction Date\"] * 4 + df[\"Quarter of Transaction Date\"]\n",
    "df = df.sort_values([\"FundID\", \"q_idx\"]).copy()\n",
    "\n",
    "# Fund-level seed: first available P-grade from cashflows\n",
    "first_pgrade_by_fund = (\n",
    "    cashflows\n",
    "    .sort_values([\"FundID\", \"q_idx\"])\n",
    "    .groupby(\"FundID\")[\"First Grading-P\"]\n",
    "    .apply(lambda s: s.dropna().iloc[0] if s.notna().any() else pd.NA)\n",
    ")\n",
    "\n",
    "# 1) Forward-fill grades within each fund (fills gaps in-between + trailing)\n",
    "df[\"Grade\"] = df.groupby(\"FundID\")[\"Grade\"].ffill()\n",
    "\n",
    "# 2) Fill ONLY the beginning (leading NaNs) using first P-grade\n",
    "# (after ffill, the only NaNs left are at the start of each fund, or funds with no grades at all)\n",
    "df[\"Grade\"] = df[\"Grade\"].fillna(df[\"FundID\"].map(first_pgrade_by_fund))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(\n",
    "    kmp,\n",
    "    on=\"FundID\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_kmp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    'VC Fund Name', 'VC Fund Status',\n",
    "    'Vintage Year',\n",
    "    'Year of Transaction Date', 'Quarter of Transaction Date',\n",
    "    'FundID',\n",
    "    'Fund Workflow Stage', 'Investment Strategy Set Up',\n",
    "    'Adj Strategy', 'Main Sector', 'Stage Focus',\n",
    "    'Target Fund Size', 'Team Location', 'New Team',\n",
    "    'First Closing Date', 'Final Closing Date',\n",
    "    'Planned end date with add. years as per legal doc',\n",
    "    'Fund Currency',\n",
    "    'Transaction Quarter', 'Commitment EUR',\n",
    "    'Signed Amount EUR',\n",
    "    'Adj Drawdown EUR', 'Adj Repayment EUR', 'Recallable',\n",
    "    'NAV Adjusted EUR', 'Grade',\n",
    "    'Recallable_Percentage_Decimal', 'Expiration_Quarters'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2817c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns that actually exist\n",
    "final_cols = [c for c in cols_to_keep if c in df.columns]\n",
    "\n",
    "# Optional: warn if something is missing\n",
    "missing_cols = set(cols_to_keep) - set(final_cols)\n",
    "if missing_cols:\n",
    "    print(\"Warning: missing columns:\", missing_cols)\n",
    "\n",
    "data = df[final_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Vintage Year as datetime\n",
    "data[\"Vintage Year\"] = pd.to_datetime(data[\"Vintage Year\"], errors=\"coerce\")\n",
    "\n",
    "# Keep only vintage year after 2004\n",
    "data = data[data[\"Vintage Year\"].dt.year > 2004].copy()\n",
    "data[\"Vintage Year\"].dt.year.min(), data[\"Vintage Year\"].dt.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c99460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Funds with no grade\n",
    "data = data[data[\"Grade\"].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Nav values constraint at 0\n",
    "\n",
    "data.loc[data[\"NAV Adjusted EUR\"] < 0, \"NAV Adjusted EUR\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Age in columns\n",
    "# Ensure datetime type\n",
    "data[\"First Closing Date\"] = pd.to_datetime(data[\"First Closing Date\"], errors=\"coerce\")\n",
    "\n",
    "# Build quarter index for transaction date\n",
    "data[\"tx_q_idx\"] = data[\"Year of Transaction Date\"] * 4 + data[\"Quarter of Transaction Date\"]\n",
    "\n",
    "# Build quarter index for first closing date\n",
    "data[\"fc_q_idx\"] = data[\"First Closing Date\"].dt.year * 4 + data[\"First Closing Date\"].dt.quarter\n",
    "\n",
    "# Fund age in quarters\n",
    "data[\"Fund_Age_Quarters\"] = data[\"tx_q_idx\"] - data[\"fc_q_idx\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care of negative Drawdons\n",
    "\n",
    "draw_col = \"Adj Drawdown EUR\"\n",
    "lookback_quarters = 20  # 5 years\n",
    "\n",
    "# Ensure numeric\n",
    "data[draw_col] = pd.to_numeric(data[draw_col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Sort by fund and time\n",
    "data = data.sort_values([\"FundID\", \"tx_q_idx\"]).copy()\n",
    "\n",
    "for fund_id, grp in data.groupby(\"FundID\"):\n",
    "    idx = grp.index.tolist()\n",
    "\n",
    "    for pos, i in enumerate(idx):\n",
    "        val = data.at[i, draw_col]\n",
    "\n",
    "        if val < 0:\n",
    "            refund = -val\n",
    "            data.at[i, draw_col] = 0\n",
    "\n",
    "            # walk backwards up to 20 quarters\n",
    "            start = max(0, pos - lookback_quarters)\n",
    "            for j in range(pos - 1, start - 1, -1):\n",
    "                prev_idx = idx[j]\n",
    "                prev_val = data.at[prev_idx, draw_col]\n",
    "\n",
    "                if refund <= 0:\n",
    "                    break\n",
    "\n",
    "                if prev_val > 0:\n",
    "                    take = min(prev_val, refund)\n",
    "                    data.at[prev_idx, draw_col] = prev_val - take\n",
    "                    refund -= take\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0339d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capacity and Drawdown ratio\n",
    "\n",
    "fund_col = \"FundID\"\n",
    "time_col = \"tx_q_idx\"\n",
    "\n",
    "draw_col = \"Adj Drawdown EUR\"   # draw_i,t\n",
    "commit_flow_col = \"Commitment EUR\"\n",
    "rc_flow_col = \"Recallable\"\n",
    "\n",
    "# Ensure numeric\n",
    "for c in [draw_col, commit_flow_col, rc_flow_col]:\n",
    "    data[c] = pd.to_numeric(data[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Sort for correct cumulative logic\n",
    "data = data.sort_values([fund_col, time_col]).copy()\n",
    "\n",
    "# Commitment level at t (handles commitments at different times)\n",
    "data[\"commit_cum_t\"] = data.groupby(fund_col)[commit_flow_col].cumsum()\n",
    "\n",
    "# Recallable capacity level at t (use cumsum if Recallable is a flow per quarter)\n",
    "data[\"rc_cum_t\"] = data.groupby(fund_col)[rc_flow_col].cumsum()\n",
    "\n",
    "# Cumulative drawdown up to previous quarter (t-1)\n",
    "data[\"draw_cum_prev\"] = (\n",
    "    data.groupby(fund_col)[draw_col].cumsum().shift(1).fillna(0)\n",
    ")\n",
    "\n",
    "# Capacity before draw: commitment_i,t + RC_i,t - draw_cum_{t-1}, floored at 0\n",
    "data[\"Capacity\"] = (data[\"commit_cum_t\"] + data[\"rc_cum_t\"] - data[\"draw_cum_prev\"]).clip(lower=0)\n",
    "\n",
    "# Drawdown ratio rD = draw / capacity (only when capacity > 0)\n",
    "data[\"Drawdown_Ratio\"] = 0.0\n",
    "m = data[\"Capacity\"] > 0\n",
    "data.loc[m, \"Drawdown_Ratio\"] = data.loc[m, draw_col] / data.loc[m, \"Capacity\"]\n",
    "\n",
    "# Optional: keep within [0,1]\n",
    "data[\"Drawdown_Ratio\"] = data[\"Drawdown_Ratio\"].clip(lower=0, upper=1)\n",
    "\n",
    "helper_cols = [\n",
    "    \"commit_cum_t\",\n",
    "    \"rc_cum_t\",\n",
    "]\n",
    "\n",
    "data = data.drop(columns=[c for c in helper_cols if c in data.columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repayment Ratio\n",
    "\n",
    "repay_col = \"Adj Repayment EUR\"\n",
    "nav_col = \"NAV Adjusted EUR\"\n",
    "\n",
    "# Ensure numeric\n",
    "data[repay_col] = pd.to_numeric(data[repay_col], errors=\"coerce\").fillna(0)\n",
    "data[nav_col] = pd.to_numeric(data[nav_col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Floor negative repayments to 0 (if that’s your rule)\n",
    "data.loc[data[repay_col] < 0, repay_col] = 0\n",
    "\n",
    "# Make sure we're sorted by fund-quarter\n",
    "data = data.sort_values([\"FundID\", \"tx_q_idx\"]).copy()\n",
    "\n",
    "# Previous quarter NAV (within fund)\n",
    "data[\"NAV_Adj_EUR_prev_q\"] = data.groupby(\"FundID\")[nav_col].shift(1)\n",
    "\n",
    "# Treat \"very close to 0\" NAV as 0\n",
    "NAV_EPS = 100  # adjust if you want (e.g., 1, 10, 100 EUR depending on your scale)\n",
    "\n",
    "data[\"Repayment_Ratio\"] = 0.0\n",
    "m = data[\"NAV_Adj_EUR_prev_q\"].fillna(0).abs() > NAV_EPS\n",
    "data.loc[m, \"Repayment_Ratio\"] = data.loc[m, repay_col] / data.loc[m, \"NAV_Adj_EUR_prev_q\"].abs()\n",
    "\n",
    "# Floor at 0 (should already be non-negative)\n",
    "data[\"Repayment_Ratio\"] = data[\"Repayment_Ratio\"].clip(lower=0)\n",
    "\n",
    "helper_cols = [\"NAV_Adj_EUR_prev_q\", \"tx_q_idx\", \"fc_q_idx\"]\n",
    "\n",
    "data = data.drop(columns=[c for c in helper_cols if c in data.columns])\n",
    "\n",
    "# Identify FundIDs to remove (any quarter with Repayment_Ratio > 1)\n",
    "funds_to_remove = (\n",
    "    data.loc[data[\"Repayment_Ratio\"] > 1, \"FundID\"]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# Count how many funds will be removed\n",
    "n_funds_removed = len(funds_to_remove)\n",
    "\n",
    "# Remove those FundIDs completely\n",
    "data = data[~data[\"FundID\"].isin(funds_to_remove)].copy()\n",
    "\n",
    "print(f\"Removed {n_funds_removed} FundID(s) with Repayment_Ratio > 1.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef884df",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_csv = os.path.join(DATA_DIR, \"data.csv\")\n",
    "merged_parquet = os.path.join(DATA_DIR, \"data.parquet\")\n",
    "\n",
    "data.to_csv(\n",
    "    merged_csv,\n",
    "    index=False,\n",
    "    sep=\";\",              # Excel-friendly\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "data.to_parquet(merged_parquet, index=False)\n",
    "\n",
    "print(\"Filtered merged dataset saved:\")\n",
    "print(merged_csv)\n",
    "print(merged_parquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_col = \"Adj Strategy\"\n",
    "grade_col = \"Grade\"\n",
    "\n",
    "# Convert quarters → years\n",
    "data[\"Fund_Age_Years\"] = pd.to_numeric(\n",
    "    data[\"Fund_Age_Quarters\"], errors=\"coerce\"\n",
    ") / 4\n",
    "\n",
    "# Define buckets to match downstream script EXACTLY\n",
    "bins = [0, 2, 4, 6, 8, 10, 15, 20, float(\"inf\")]\n",
    "labels = [\"0-2y\", \"2-4y\", \"4-6y\", \"6-8y\", \"8-10y\", \"10-15y\", \"15-20y\", \"20y+\"]\n",
    "\n",
    "data[\"Age_Bucket\"] = pd.cut(\n",
    "    data[\"Fund_Age_Years\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False   # [0,2), [2,4), ...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_s_g_age = (\n",
    "    data\n",
    "    .dropna(subset=[strategy_col, grade_col, \"Age_Bucket\"])\n",
    "    .groupby([strategy_col, grade_col, \"Age_Bucket\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Datapoints\")\n",
    "    .sort_values([strategy_col, grade_col, \"Age_Bucket\"])\n",
    ")\n",
    "\n",
    "print(counts_s_g_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e498b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_s_g_age = (\n",
    "    data\n",
    "    .dropna(subset=[strategy_col, grade_col, \"Age_Bucket\"])\n",
    "    .pivot_table(\n",
    "        index=[strategy_col, grade_col],\n",
    "        columns=\"Age_Bucket\",\n",
    "        values=\"FundID\",\n",
    "        aggfunc=\"count\",\n",
    "        fill_value=0\n",
    "    )\n",
    ")\n",
    "\n",
    "print(pivot_s_g_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10-year (40-quarter) Migration Matrices for VC and PE\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "H_YEARS = 10\n",
    "H_Q = H_YEARS * 4  # 40 quarters\n",
    "\n",
    "strategy_filter = [\"Venture Capital\", \"Private Equity\"]\n",
    "strategy_col = \"Adj Strategy\"\n",
    "fund_col = \"FundID\"\n",
    "time_col = \"tx_q_idx\"          # quarter index already in your data earlier\n",
    "grade_col = \"Grade\"\n",
    "\n",
    "# Ensure we still have tx_q_idx (your script drops it later)\n",
    "# If tx_q_idx was dropped, reconstruct it from year/quarter columns:\n",
    "if time_col not in data.columns:\n",
    "    data[time_col] = data[\"Year of Transaction Date\"] * 4 + data[\"Quarter of Transaction Date\"]\n",
    "\n",
    "# Keep only relevant rows\n",
    "mig = data.loc[data[strategy_col].isin(strategy_filter), [fund_col, time_col, grade_col, strategy_col]].copy()\n",
    "\n",
    "# Clean grades (optional: keep only A/B/C/D if you want)\n",
    "# If grades are already A/B/C/D, this is fine.\n",
    "mig[grade_col] = mig[grade_col].astype(str).str.strip()\n",
    "\n",
    "# Sort within fund time\n",
    "mig = mig.sort_values([fund_col, time_col])\n",
    "\n",
    "# Map (FundID, tx_q_idx) -> Grade, then join future grade at +40 quarters\n",
    "mig[\"future_q_idx\"] = mig[time_col] + H_Q\n",
    "\n",
    "future = mig[[fund_col, time_col, grade_col]].copy()\n",
    "future = future.rename(columns={time_col: \"future_q_idx\", grade_col: \"Grade_tplus10y\"})\n",
    "\n",
    "mig = mig.merge(future, on=[fund_col, \"future_q_idx\"], how=\"left\")\n",
    "\n",
    "# Keep only rows where we have a 10y-ahead grade\n",
    "mig = mig.dropna(subset=[\"Grade_tplus10y\"]).copy()\n",
    "\n",
    "# Function to build migration matrices\n",
    "def migration_matrix(df_sub: pd.DataFrame, from_col=\"Grade\", to_col=\"Grade_tplus10y\"):\n",
    "    # counts\n",
    "    counts = pd.crosstab(df_sub[from_col], df_sub[to_col])\n",
    "    # row-normalized probabilities\n",
    "    probs = counts.div(counts.sum(axis=1), axis=0)\n",
    "    return counts, probs\n",
    "\n",
    "results = {}\n",
    "\n",
    "for strat in strategy_filter:\n",
    "    sub = mig[mig[strategy_col] == strat].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"\\nNo 10-year transitions available for: {strat}\")\n",
    "        continue\n",
    "\n",
    "    counts, probs = migration_matrix(sub, from_col=grade_col, to_col=\"Grade_tplus10y\")\n",
    "    results[strat] = (counts, probs)\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"10Y Migration Matrix — {strat}\")\n",
    "    print(f\"Transitions counted: {len(sub)}\")\n",
    "    print(f\"From (rows) -> To (cols) over {H_YEARS} years\")\n",
    "    print(f\"==============================\\n\")\n",
    "\n",
    "    print(\"Counts:\")\n",
    "    print(counts)\n",
    "    print(\"\\nProbabilities (row-normalized):\")\n",
    "    print(probs.round(4))\n",
    "\n",
    "# Optional: save to Excel-friendly CSVs\n",
    "out_dir = DATA_DIR\n",
    "for strat, (counts, probs) in results.items():\n",
    "    safe = strat.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    counts_path = os.path.join(out_dir, f\"migration_{safe}_{H_YEARS}y_counts.csv\")\n",
    "    probs_path  = os.path.join(out_dir, f\"migration_{safe}_{H_YEARS}y_probs.csv\")\n",
    "\n",
    "    counts.to_csv(counts_path, sep=\";\", encoding=\"utf-8-sig\")\n",
    "    probs.to_csv(probs_path, sep=\";\", encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"\\nSaved {strat} migration outputs:\")\n",
    "    print(counts_path)\n",
    "    print(probs_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
