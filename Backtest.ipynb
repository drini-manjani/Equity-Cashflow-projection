{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344dca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import erf, sqrt\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: time and paths\n",
    "# -----------------------------\n",
    "\n",
    "def quarter_end_from_year_quarter(year: int, quarter: str) -> pd.Timestamp:\n",
    "    q = quarter.upper().strip()\n",
    "    if q not in {\"Q1\", \"Q2\", \"Q3\", \"Q4\"}:\n",
    "        raise ValueError(\"Quarter must be one of: Q1, Q2, Q3, Q4\")\n",
    "    q_num = int(q[1])\n",
    "    return pd.Period(f\"{year}Q{q_num}\", freq=\"Q\").to_timestamp(\"Q\")\n",
    "\n",
    "\n",
    "def add_quarters(qe: pd.Timestamp, q: int) -> pd.Timestamp:\n",
    "    if pd.isna(qe):\n",
    "        return pd.NaT\n",
    "    p = pd.Period(qe, freq=\"Q\")\n",
    "    return (p + int(q)).to_timestamp(\"Q\")\n",
    "\n",
    "\n",
    "def quarter_range(start_qe: pd.Timestamp, end_qe: pd.Timestamp) -> List[pd.Timestamp]:\n",
    "    if pd.isna(start_qe) or pd.isna(end_qe):\n",
    "        return []\n",
    "    p0 = pd.Period(start_qe, freq=\"Q\")\n",
    "    p1 = pd.Period(end_qe, freq=\"Q\")\n",
    "    if p1 < p0:\n",
    "        return []\n",
    "    return [p.to_timestamp(\"Q\") for p in pd.period_range(p0, p1, freq=\"Q\")]\n",
    "\n",
    "\n",
    "def _to_period_q(x) -> pd.Period:\n",
    "    if isinstance(x, pd.Period):\n",
    "        return x.asfreq(\"Q\")\n",
    "    try:\n",
    "        return pd.Period(x, freq=\"Q\")\n",
    "    except Exception:\n",
    "        return pd.Period(pd.Timestamp(x), freq=\"Q\")\n",
    "\n",
    "\n",
    "def quarter_diff(qe: pd.Timestamp, start_qe: pd.Timestamp) -> int:\n",
    "    p = _to_period_q(qe)\n",
    "    s = _to_period_q(start_qe)\n",
    "    return int(p.ordinal - s.ordinal)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config (aligns with Structural-cashflows)\n",
    "# -----------------------------\n",
    "\n",
    "AGE_BINS_Q = [-1, 7, 15, 23, 31, 39, 59, 79, 10_000]\n",
    "AGE_LABELS = [\"0-2y\", \"2-4y\", \"4-6y\", \"6-8y\", \"8-10y\", \"10-15y\", \"15-20y\", \"20y+\"]\n",
    "\n",
    "NAV_EPS = 100.0\n",
    "NAV_STOP_EPS = 1.0\n",
    "CAP_EPS = 1.0\n",
    "\n",
    "RUNOFF_Q = 12\n",
    "REP_RAMP_P = 2.0\n",
    "REP_RAMP_SIZE = 1.0\n",
    "REP_RAMP_FLOOR = 0.05\n",
    "\n",
    "USE_RUNOFF_CALIBRATION = True\n",
    "RUNOFF_MULT_MIN = 0.5\n",
    "RUNOFF_MULT_MAX = 3.0\n",
    "\n",
    "IP_YEARS_DEFAULT = 5\n",
    "IP_Q_DEFAULT = int(IP_YEARS_DEFAULT * 4)\n",
    "IP_CUM_PCTL = 0.80\n",
    "IP_Q_MIN = 4\n",
    "IP_Q_MAX = 40\n",
    "DRAW_AGE_MIN_MULT = 0.2\n",
    "DRAW_AGE_DECAY_POWER = 1.0\n",
    "\n",
    "ENFORCE_IP_LIMITS = False\n",
    "USE_DRAW_AGE_SHAPE = False\n",
    "USE_FORCED_TERMINAL_REPAY = False\n",
    "AGE_SOURCE = \"fund_age\"  # \"fund_age\" or \"first_close\"\n",
    "USE_NAV_PROJECTIONS = True  # use NAV Logic omega/nav_start files if available\n",
    "RUN_NAV_LOGIC_INLINE = True  # run NAV Logic in-memory for backtest window (no file outputs)\n",
    "NAV_LOGIC_ALPHA_LEVEL = 0.10\n",
    "NAV_LOGIC_MIN_CLUSTERS = 8\n",
    "NAV_LOGIC_MSCI_MODE = \"unconditional\"  # \"conditional\" or \"unconditional\"\n",
    "RUN_CONDITIONAL = False\n",
    "RUN_UNCONDITIONAL = True\n",
    "\n",
    "# Calibration / reporting bucketing\n",
    "CALIBRATION_BUCKET_MODE = \"strategy_grade\"  # \"strategy_grade_age\" or \"strategy_grade\"\n",
    "REPORT_BUCKET_MODE = \"strategy_grade\"       # \"strategy_grade_age\", \"strategy_grade\", or \"strategy\"\n",
    "\n",
    "GRADE_P_MULT = {\"A\": 1.15, \"B\": 1.00, \"C\": 0.85, \"D\": 0.70}\n",
    "GRADE_SIZE_MULT = {\"A\": 1.10, \"B\": 1.00, \"C\": 0.90, \"D\": 0.80}\n",
    "\n",
    "GRADE_DRAW_P_MULT = {\"A\": 0.95, \"B\": 1.00, \"C\": 1.05, \"D\": 1.10}\n",
    "GRADE_DRAW_SIZE_MULT = {\"A\": 0.95, \"B\": 1.00, \"C\": 1.05, \"D\": 1.10}\n",
    "\n",
    "MSCI_REP_P_BETA = 0.6\n",
    "MSCI_REP_SIZE_BETA = 0.4\n",
    "MSCI_Z_CLIP = 2.0\n",
    "MSCI_REP_POS_ONLY = True\n",
    "\n",
    "SIGMA_FLOOR = 0.35\n",
    "SIGMA_CAP = 2.0\n",
    "\n",
    "MIN_LN_OBS = 30\n",
    "MIN_LN_FUNDS = 5\n",
    "KS_ALPHA = 0.05\n",
    "SHRINK_N = 100\n",
    "SHRINK_FUNDS = 10\n",
    "\n",
    "USE_HAZARD_MODELS = True\n",
    "LOGIT_L2 = 1.0\n",
    "LOGIT_MAX_ITER = 50\n",
    "LOGIT_TOL = 1e-6\n",
    "\n",
    "SOFT_RHO_PCTL = 0.95\n",
    "SOFT_EXPIRY_FALLBACK = 20\n",
    "\n",
    "GRADE_STATES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "OMEGA_CLIP = 0.8\n",
    "GRADE_OMEGA_BIAS = {\"A\": 0.005, \"B\": 0.0, \"C\": -0.005, \"D\": -0.01}\n",
    "\n",
    "# -----------------------------\n",
    "# Calibration controls\n",
    "# -----------------------------\n",
    "USE_DRAWDOWN_CALIBRATION = False\n",
    "# \"mean\", \"median\", or \"auto\" (pick lower SSE per group)\n",
    "DRAW_CALIB_TARGET = \"auto\"\n",
    "DRAW_CALIB_MIN_FUNDS = 10\n",
    "DRAW_CALIB_MIN_AGES = 8\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: math / distributions\n",
    "# -----------------------------\n",
    "\n",
    "def make_age_bucket_q(age_q: float):\n",
    "    return pd.cut(pd.Series([age_q]), bins=AGE_BINS_Q, labels=AGE_LABELS).iloc[0]\n",
    "\n",
    "\n",
    "def norm_cdf(x: float) -> float:\n",
    "    return 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
    "\n",
    "\n",
    "def one_factor_uniforms(n: int, rng: np.random.Generator, rho_mkt: float) -> np.ndarray:\n",
    "    rho_mkt = float(np.clip(rho_mkt, 0.0, 0.999))\n",
    "    Z = rng.standard_normal()\n",
    "    eps = rng.standard_normal(n)\n",
    "    X = np.sqrt(rho_mkt) * Z + np.sqrt(1.0 - rho_mkt) * eps\n",
    "    return np.array([norm_cdf(x) for x in X], dtype=float)\n",
    "\n",
    "\n",
    "def inv_norm(u: float) -> float:\n",
    "    try:\n",
    "        from scipy.special import erfinv\n",
    "        return sqrt(2.0) * float(erfinv(2.0 * u - 1.0))\n",
    "    except Exception:\n",
    "        u = float(np.clip(u, 1e-6, 1.0 - 1e-6))\n",
    "        return float(np.sign(u - 0.5) * np.sqrt(2.0) * np.sqrt(abs(np.log(1.0 - 2.0 * abs(u - 0.5)))))\n",
    "\n",
    "\n",
    "def lognormal_from_u(mu: float, sigma: float, u: float) -> float:\n",
    "    z = inv_norm(u)\n",
    "    return float(np.exp(mu + sigma * z))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Recallable ledger\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class RecallableBucket:\n",
    "    created_q: int\n",
    "    expiry_q: int\n",
    "    amount_remaining: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RecallableLedger:\n",
    "    rho: float\n",
    "    expiry_quarters: int\n",
    "    commitment: float\n",
    "    buckets: List[RecallableBucket] = field(default_factory=list)\n",
    "\n",
    "    def _rc_cap(self) -> float:\n",
    "        return max(float(self.rho), 0.0) * max(float(self.commitment), 0.0)\n",
    "\n",
    "    def drop_expired(self, q: int) -> None:\n",
    "        if int(self.expiry_quarters) <= 0:\n",
    "            self.buckets = []\n",
    "            return\n",
    "        self.buckets = [b for b in self.buckets if b.expiry_q >= q and b.amount_remaining > 0]\n",
    "\n",
    "    def available(self, q: int) -> float:\n",
    "        self.drop_expired(q)\n",
    "        return float(sum(b.amount_remaining for b in self.buckets))\n",
    "\n",
    "    def add_recallable(self, q: int, rc_amount: float, enforce_cap: bool = True) -> float:\n",
    "        self.drop_expired(q)\n",
    "        x = max(float(rc_amount or 0.0), 0.0)\n",
    "        if x <= 0.0 or int(self.expiry_quarters) <= 0:\n",
    "            return 0.0\n",
    "\n",
    "        add_amt = x\n",
    "        if enforce_cap:\n",
    "            cap = self._rc_cap()\n",
    "            cur = self.available(q)\n",
    "            room = max(cap - cur, 0.0)\n",
    "            add_amt = min(add_amt, room)\n",
    "\n",
    "        if add_amt <= 0.0:\n",
    "            return 0.0\n",
    "\n",
    "        self.buckets.append(RecallableBucket(\n",
    "            created_q=q,\n",
    "            expiry_q=q + int(self.expiry_quarters),\n",
    "            amount_remaining=float(add_amt)\n",
    "        ))\n",
    "        return float(add_amt)\n",
    "\n",
    "    def consume_for_drawdown(self, q: int, draw_amount: float) -> Dict[str, float]:\n",
    "        self.drop_expired(q)\n",
    "        need = max(float(draw_amount or 0.0), 0.0)\n",
    "        if need <= 0.0:\n",
    "            return {\"use_rc\": 0.0, \"use_commitment\": 0.0}\n",
    "\n",
    "        self.buckets.sort(key=lambda b: b.created_q)\n",
    "        use_rc = 0.0\n",
    "        for b in self.buckets:\n",
    "            if need <= 0:\n",
    "                break\n",
    "            take = min(b.amount_remaining, need)\n",
    "            b.amount_remaining -= take\n",
    "            need -= take\n",
    "            use_rc += take\n",
    "\n",
    "        self.buckets = [b for b in self.buckets if b.amount_remaining > 0]\n",
    "        use_commitment = max(float(draw_amount) - use_rc, 0.0)\n",
    "        return {\"use_rc\": float(use_rc), \"use_commitment\": float(use_commitment)}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Hazard model helpers\n",
    "# -----------------------------\n",
    "\n",
    "def _sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def build_feature_matrix(df: pd.DataFrame, include_nav: bool) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[\"Adj Strategy\"] = d[\"Adj Strategy\"].fillna(\"Unknown\")\n",
    "    d[\"Grade\"] = d[\"Grade\"].fillna(\"D\").astype(str).str.strip()\n",
    "\n",
    "    X = pd.DataFrame(index=d.index)\n",
    "    X[\"intercept\"] = 1.0\n",
    "    X[\"age_q\"] = d[\"age_q\"].astype(float)\n",
    "    X[\"age_q2\"] = (d[\"age_q\"].astype(float) ** 2)\n",
    "    if include_nav:\n",
    "        X[\"log_nav_prev\"] = d[\"log_nav_prev\"].astype(float)\n",
    "\n",
    "    strat_d = pd.get_dummies(d[\"Adj Strategy\"], prefix=\"strat\", drop_first=True)\n",
    "    grade_d = pd.get_dummies(d[\"Grade\"], prefix=\"grade\", drop_first=True)\n",
    "\n",
    "    X = pd.concat([X, strat_d, grade_d], axis=1)\n",
    "    return X\n",
    "\n",
    "\n",
    "def standardize_X(X: pd.DataFrame, cont_cols: list) -> Tuple[pd.DataFrame, dict, dict]:\n",
    "    means = {}\n",
    "    stds = {}\n",
    "    X = X.copy()\n",
    "    for c in cont_cols:\n",
    "        if c in X.columns:\n",
    "            mu = float(X[c].mean())\n",
    "            sd = float(X[c].std(ddof=1)) if len(X) > 1 else 1.0\n",
    "            if not np.isfinite(sd) or sd <= 0:\n",
    "                sd = 1.0\n",
    "            means[c] = mu\n",
    "            stds[c] = sd\n",
    "            X[c] = (X[c] - mu) / sd\n",
    "    return X, means, stds\n",
    "\n",
    "\n",
    "def apply_standardize(X: pd.DataFrame, means: dict, stds: dict) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    for c, mu in means.items():\n",
    "        if c in X.columns:\n",
    "            sd = stds.get(c, 1.0)\n",
    "            if not np.isfinite(sd) or sd <= 0:\n",
    "                sd = 1.0\n",
    "            X[c] = (X[c] - mu) / sd\n",
    "    return X\n",
    "\n",
    "\n",
    "def fit_logit(X: np.ndarray, y: np.ndarray, l2: float = LOGIT_L2, max_iter: int = LOGIT_MAX_ITER, tol: float = LOGIT_TOL) -> np.ndarray:\n",
    "    n, p = X.shape\n",
    "    beta = np.zeros(p, dtype=float)\n",
    "    I = np.eye(p)\n",
    "    for _ in range(max_iter):\n",
    "        z = X @ beta\n",
    "        p_hat = _sigmoid(z)\n",
    "        W = p_hat * (1.0 - p_hat)\n",
    "        W = np.clip(W, 1e-6, None)\n",
    "        z_adj = z + (y - p_hat) / W\n",
    "        XTW = X.T * W\n",
    "        A = XTW @ X + l2 * I\n",
    "        b = XTW @ z_adj\n",
    "        try:\n",
    "            beta_new = np.linalg.solve(A, b)\n",
    "        except Exception:\n",
    "            beta_new = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "        if np.linalg.norm(beta_new - beta) < tol:\n",
    "            beta = beta_new\n",
    "            break\n",
    "        beta = beta_new\n",
    "    return beta\n",
    "\n",
    "\n",
    "def build_feature_row(strategy: str, grade: str, age_q: int, log_nav_prev: float, include_nav: bool,\n",
    "                      cols: list, means: dict, stds: dict) -> np.ndarray:\n",
    "    row = {\n",
    "        \"Adj Strategy\": strategy,\n",
    "        \"Grade\": grade,\n",
    "        \"age_q\": float(age_q),\n",
    "        \"age_q2\": float(age_q) ** 2,\n",
    "        \"log_nav_prev\": float(log_nav_prev) if include_nav else 0.0,\n",
    "    }\n",
    "    df = pd.DataFrame([row])\n",
    "    X = build_feature_matrix(df, include_nav=include_nav)\n",
    "    X = X.reindex(columns=cols, fill_value=0.0)\n",
    "    X = apply_standardize(X, means, stds)\n",
    "    return X.to_numpy(dtype=float)\n",
    "\n",
    "\n",
    "def ks_test_normal(log_x: np.ndarray, alpha: float = KS_ALPHA) -> Tuple[float, bool]:\n",
    "    n = len(log_x)\n",
    "    if n < 2:\n",
    "        return float(\"nan\"), False\n",
    "    mu = float(np.mean(log_x))\n",
    "    sig = float(np.std(log_x, ddof=1)) if n > 1 else 0.0\n",
    "    if not np.isfinite(sig) or sig <= 0:\n",
    "        return float(\"nan\"), False\n",
    "\n",
    "    x = np.sort(log_x)\n",
    "    z = (x - mu) / (sig * np.sqrt(2.0))\n",
    "    try:\n",
    "        F = 0.5 * (1.0 + np.erf(z))\n",
    "    except Exception:\n",
    "        F = 0.5 * (1.0 + np.vectorize(erf)(z))\n",
    "    i = np.arange(1, n + 1)\n",
    "    d_plus = np.max(i / n - F)\n",
    "    d_minus = np.max(F - (i - 1) / n)\n",
    "    D = float(max(d_plus, d_minus))\n",
    "\n",
    "    dcrit = float(np.sqrt(-0.5 * np.log(alpha / 2.0) / n))\n",
    "    return D, bool(D <= dcrit)\n",
    "\n",
    "\n",
    "def fit_lognormal_stats(x: pd.Series, fund_ids: pd.Series) -> Dict[str, float]:\n",
    "    g = x.dropna()\n",
    "    g = g[g > 0]\n",
    "    n_obs = int(len(g))\n",
    "    if n_obs == 0:\n",
    "        return {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR,\n",
    "            \"n\": 0, \"n_funds\": 0,\n",
    "            \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "\n",
    "    n_funds = int(fund_ids.loc[g.index].nunique()) if fund_ids is not None else 0\n",
    "\n",
    "    lx = np.log(g.to_numpy(dtype=float))\n",
    "    mu = float(np.mean(lx))\n",
    "    sig = float(np.std(lx, ddof=1)) if n_obs > 1 else SIGMA_FLOOR\n",
    "    sig = float(np.clip(max(sig, SIGMA_FLOOR), SIGMA_FLOOR, SIGMA_CAP))\n",
    "\n",
    "    ks_D, ks_pass = (float(\"nan\"), False)\n",
    "    if n_obs >= MIN_LN_OBS and n_funds >= MIN_LN_FUNDS:\n",
    "        ks_D, ks_pass = ks_test_normal(lx, alpha=KS_ALPHA)\n",
    "\n",
    "    return {\n",
    "        \"mu\": mu, \"sig\": sig,\n",
    "        \"n\": n_obs, \"n_funds\": n_funds,\n",
    "        \"ks_D\": ks_D, \"ks_pass\": ks_pass,\n",
    "    }\n",
    "\n",
    "\n",
    "def _weight(n_obs: float, n_funds: float, ks_pass: bool) -> float:\n",
    "    if not ks_pass:\n",
    "        return 0.0\n",
    "    if n_obs is None or n_obs <= 0 or n_funds is None or n_funds <= 0:\n",
    "        return 0.0\n",
    "    w = (n_obs / (n_obs + SHRINK_N)) * (n_funds / (n_funds + SHRINK_FUNDS))\n",
    "    return float(np.clip(w, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _weight_h(n_obs: float, n_funds: float) -> float:\n",
    "    if n_obs is None or n_obs <= 0 or n_funds is None or n_funds <= 0:\n",
    "        return 0.0\n",
    "    w = (n_obs / (n_obs + SHRINK_N)) * (n_funds / (n_funds + SHRINK_FUNDS))\n",
    "    return float(np.clip(w, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _blend_p(p_c: float, n_c: float, nf_c: float, p_p: float) -> float:\n",
    "    w = _weight_h(n_c, nf_c)\n",
    "    return float(np.clip(w * float(p_c) + (1.0 - w) * float(p_p), 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _combine_p(p_sg, n_sg, nf_sg, p_sa, n_sa, nf_sa, p_s):\n",
    "    w_sg = _weight_h(n_sg, nf_sg)\n",
    "    w_sa = _weight_h(n_sa, nf_sa)\n",
    "    tot = w_sg + w_sa\n",
    "    if tot > 0:\n",
    "        p_mid = (w_sg * float(p_sg) + w_sa * float(p_sa)) / tot\n",
    "        return float(np.clip(tot * p_mid + (1.0 - tot) * float(p_s), 0.0, 1.0))\n",
    "    return float(np.clip(float(p_s), 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _combine_mu_sig(mu_sg, sig_sg, n_sg, nf_sg, ks_sg,\n",
    "                    mu_sa, sig_sa, n_sa, nf_sa, ks_sa,\n",
    "                    mu_s, sig_s):\n",
    "    w_sg = _weight(n_sg, nf_sg, ks_sg)\n",
    "    w_sa = _weight(n_sa, nf_sa, ks_sa)\n",
    "    tot = w_sg + w_sa\n",
    "    if tot > 0:\n",
    "        mu_mid = (w_sg * float(mu_sg) + w_sa * float(mu_sa)) / tot\n",
    "        sig_mid = (w_sg * float(sig_sg) + w_sa * float(sig_sa)) / tot\n",
    "        mu = tot * mu_mid + (1.0 - tot) * float(mu_s)\n",
    "        sig = tot * sig_mid + (1.0 - tot) * float(sig_s)\n",
    "    else:\n",
    "        mu = float(mu_s)\n",
    "        sig = float(sig_s)\n",
    "    sig = float(np.clip(max(sig, SIGMA_FLOOR), SIGMA_FLOOR, SIGMA_CAP))\n",
    "    return mu, sig\n",
    "\n",
    "\n",
    "def _blend(mu_c, sig_c, n_c, nf_c, ks_c, mu_p, sig_p, n_p, nf_p, ks_p):\n",
    "    w = _weight(n_c, nf_c, ks_c)\n",
    "    mu = w * float(mu_c) + (1.0 - w) * float(mu_p)\n",
    "    sig = w * float(sig_c) + (1.0 - w) * float(sig_p)\n",
    "    sig = float(np.clip(max(sig, SIGMA_FLOOR), SIGMA_FLOOR, SIGMA_CAP))\n",
    "    return mu, sig\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MSCI model (simplified from msci_projection)\n",
    "# -----------------------------\n",
    "\n",
    "def load_msci_quarterly(msci_xlsx_path: str) -> pd.DataFrame:\n",
    "    msci = pd.read_excel(msci_xlsx_path)\n",
    "    if \"Date\" not in msci.columns or \"SCXP Index\" not in msci.columns:\n",
    "        raise ValueError(\"MSCI file must contain columns: 'Date' and 'SCXP Index'\")\n",
    "    msci = msci[[\"Date\", \"SCXP Index\"]].copy()\n",
    "    msci[\"Date\"] = pd.to_datetime(msci[\"Date\"], errors=\"coerce\")\n",
    "    msci[\"SCXP Index\"] = pd.to_numeric(msci[\"SCXP Index\"], errors=\"coerce\")\n",
    "    msci = msci.dropna(subset=[\"Date\", \"SCXP Index\"]).sort_values(\"Date\")\n",
    "    msci[\"quarter_end\"] = msci[\"Date\"].dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    q = (msci.groupby(\"quarter_end\", as_index=False)[\"SCXP Index\"]\n",
    "         .last()\n",
    "         .rename(columns={\"SCXP Index\": \"index_level\"})\n",
    "         .sort_values(\"quarter_end\")\n",
    "         .reset_index(drop=True))\n",
    "    q[\"msci_ret_q\"] = q[\"index_level\"].pct_change()\n",
    "    q = q.dropna(subset=[\"msci_ret_q\"]).reset_index(drop=True)\n",
    "    return q\n",
    "\n",
    "\n",
    "def label_regimes_by_quantiles(q_returns: pd.Series, low_q=0.33, high_q=0.67) -> pd.Series:\n",
    "    q_low = q_returns.quantile(low_q)\n",
    "    q_high = q_returns.quantile(high_q)\n",
    "    regime = pd.Series(index=q_returns.index, dtype=\"object\")\n",
    "    regime[q_returns <= q_low] = \"bear\"\n",
    "    regime[q_returns >= q_high] = \"bull\"\n",
    "    regime[(q_returns > q_low) & (q_returns < q_high)] = \"flat\"\n",
    "    return regime\n",
    "\n",
    "\n",
    "def estimate_transition_matrix(regimes: pd.Series, states=(\"bear\", \"flat\", \"bull\"), laplace=1.0) -> pd.DataFrame:\n",
    "    states = list(states)\n",
    "    counts = pd.DataFrame(0.0, index=states, columns=states)\n",
    "    r = regimes.dropna().tolist()\n",
    "    for a, b in zip(r[:-1], r[1:]):\n",
    "        if a in states and b in states:\n",
    "            counts.loc[a, b] += 1.0\n",
    "    counts = counts + laplace\n",
    "    P = counts.div(counts.sum(axis=1), axis=0)\n",
    "    return P\n",
    "\n",
    "\n",
    "def estimate_regime_params(df_q: pd.DataFrame, states=(\"bear\", \"flat\", \"bull\")) -> pd.DataFrame:\n",
    "    overall_sigma = float(df_q[\"msci_ret_q\"].std(ddof=1))\n",
    "    overall_sigma = max(overall_sigma, 1e-6)\n",
    "    out = []\n",
    "    for s in states:\n",
    "        sub = df_q.loc[df_q[\"regime\"] == s, \"msci_ret_q\"].dropna()\n",
    "        mu = float(sub.mean()) if len(sub) else 0.0\n",
    "        sigma = float(sub.std(ddof=1)) if len(sub) > 1 else overall_sigma\n",
    "        sigma = max(sigma, 1e-6)\n",
    "        out.append((s, mu, sigma))\n",
    "    return pd.DataFrame(out, columns=[\"regime\", \"mu_q\", \"sigma_q\"]).set_index(\"regime\")\n",
    "\n",
    "\n",
    "def apply_persistence_tilt(P: pd.DataFrame, scenario: str, k: float = 1.2) -> pd.DataFrame:\n",
    "    scenario = scenario.lower().strip()\n",
    "    if scenario not in {\"bullish\", \"neutral\", \"bearish\"}:\n",
    "        raise ValueError(\"scenario must be one of: bullish, neutral, bearish\")\n",
    "    if scenario == \"neutral\":\n",
    "        return P.copy()\n",
    "    target = \"bull\" if scenario == \"bullish\" else \"bear\"\n",
    "    P2 = P.copy()\n",
    "    for s in P2.index:\n",
    "        P2.loc[s, target] *= k\n",
    "    P2.loc[target, target] *= k\n",
    "    P2 = P2.div(P2.sum(axis=1), axis=0)\n",
    "    return P2\n",
    "\n",
    "\n",
    "def simulate_markov_regimes(P: pd.DataFrame, start_state: str, n_steps: int, rng: np.random.Generator) -> list:\n",
    "    states = list(P.index)\n",
    "    if start_state not in states:\n",
    "        start_state = \"flat\" if \"flat\" in states else states[0]\n",
    "    path = [start_state]\n",
    "    for _ in range(n_steps):\n",
    "        cur = path[-1]\n",
    "        probs = P.loc[cur].values.astype(float)\n",
    "        nxt = rng.choice(states, p=probs)\n",
    "        path.append(nxt)\n",
    "    return path[1:]\n",
    "\n",
    "\n",
    "def simulate_msci_path(df_q_hist: pd.DataFrame, start_qe: pd.Timestamp, n_quarters: int,\n",
    "                       scenario: str, tilt_strength: float, rng: np.random.Generator) -> pd.DataFrame:\n",
    "    df = df_q_hist.copy()\n",
    "    df[\"regime\"] = label_regimes_by_quantiles(df[\"msci_ret_q\"], low_q=0.33, high_q=0.67)\n",
    "    P = estimate_transition_matrix(df[\"regime\"], laplace=1.0)\n",
    "    params = estimate_regime_params(df)\n",
    "    P_tilted = apply_persistence_tilt(P, scenario=scenario, k=tilt_strength)\n",
    "    df_reg = df.loc[df[\"quarter_end\"] <= start_qe].dropna(subset=[\"regime\"])\n",
    "    start_regime = df_reg[\"regime\"].iloc[-1] if not df_reg.empty else \"flat\"\n",
    "    future_qe = quarter_range(add_quarters(start_qe, 1), add_quarters(start_qe, n_quarters))\n",
    "    regime_path = simulate_markov_regimes(P_tilted, start_regime, n_quarters, rng)\n",
    "    rows = []\n",
    "    for qe, s in zip(future_qe, regime_path):\n",
    "        mu = float(params.loc[s, \"mu_q\"])\n",
    "        sig = float(params.loc[s, \"sigma_q\"])\n",
    "        r = mu + sig * rng.standard_normal()\n",
    "        rows.append({\"quarter_end\": qe, \"msci_ret_q\": r, \"regime\": s})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Grade transitions (yearly)\n",
    "# -----------------------------\n",
    "\n",
    "def build_yearly_transition_from_data(df: pd.DataFrame, strategy: Optional[str] = None) -> Tuple[pd.DataFrame, pd.DataFrame, int]:\n",
    "    df = df.copy()\n",
    "    if strategy is not None:\n",
    "        df = df[df[\"Adj Strategy\"] == strategy].copy()\n",
    "    transitions = []\n",
    "    for _, g in df.groupby(\"FundID\"):\n",
    "        g = g.sort_values(\"quarter_end\")\n",
    "        grades = g[\"Grade\"].fillna(\"D\").astype(str).tolist()\n",
    "        if len(grades) < 5:\n",
    "            continue\n",
    "        yearly = grades[::4]\n",
    "        transitions.extend(list(zip(yearly[:-1], yearly[1:])))\n",
    "    if not transitions:\n",
    "        states = GRADE_STATES\n",
    "        counts = pd.DataFrame(1.0, index=states, columns=states)\n",
    "        probs = counts.div(counts.sum(axis=1), axis=0)\n",
    "        return counts, probs, 0\n",
    "\n",
    "    counts = pd.crosstab(\n",
    "        [a for a, _ in transitions],\n",
    "        [b for _, b in transitions]\n",
    "    ).reindex(index=GRADE_STATES, columns=GRADE_STATES, fill_value=0.0)\n",
    "    counts = counts + 1.0\n",
    "    probs = counts.div(counts.sum(axis=1), axis=0)\n",
    "    return counts, probs, len(transitions)\n",
    "\n",
    "\n",
    "def sample_next_grade(curr_grade: str, P_df: pd.DataFrame, rng: np.random.Generator) -> str:\n",
    "    if curr_grade not in GRADE_STATES:\n",
    "        curr_grade = \"D\"\n",
    "    row = P_df.loc[curr_grade].values.astype(float)\n",
    "    return str(rng.choice(GRADE_STATES, p=row))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Omega model (simplified NAV Logic)\n",
    "# -----------------------------\n",
    "\n",
    "def fit_ols_beta(y: np.ndarray, x: np.ndarray) -> Tuple[float, float, float]:\n",
    "    # x: n x 2 (r_t, r_{t-1})\n",
    "    X = np.column_stack([np.ones(len(y)), x])\n",
    "    try:\n",
    "        beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    except Exception:\n",
    "        beta = np.zeros(3, dtype=float)\n",
    "    return float(beta[0]), float(beta[1]), float(beta[2])\n",
    "\n",
    "\n",
    "def build_omega_models(cal: pd.DataFrame) -> Tuple[Dict[Tuple[str, str], Tuple[float, float, str]],\n",
    "                                                   Dict[Tuple[str, str, str], Tuple[float, str]],\n",
    "                                                   Dict[Tuple[str, str], Tuple[float, str]]]:\n",
    "    # Betas by (strategy, grade), fallback to strategy, then global\n",
    "    betas_sg = {}\n",
    "    betas_s = {}\n",
    "    betas_g = (0.0, 0.0, 0.0)\n",
    "\n",
    "    # Global\n",
    "    y = cal[\"omega\"].to_numpy(dtype=float)\n",
    "    x = cal[[\"msci_ret_q\", \"msci_ret_q_lag1\"]].to_numpy(dtype=float)\n",
    "    a_g, b0_g, b1_g = fit_ols_beta(y, x)\n",
    "    betas_g = (a_g, b0_g, b1_g)\n",
    "\n",
    "    # Strategy-level\n",
    "    for s, grp in cal.groupby(\"Adj Strategy\"):\n",
    "        y = grp[\"omega\"].to_numpy(dtype=float)\n",
    "        x = grp[[\"msci_ret_q\", \"msci_ret_q_lag1\"]].to_numpy(dtype=float)\n",
    "        a, b0, b1 = fit_ols_beta(y, x)\n",
    "        betas_s[s] = (a, b0, b1)\n",
    "\n",
    "    # Strategy+grade\n",
    "    for (s, g), grp in cal.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "        if len(grp) < 20:\n",
    "            continue\n",
    "        y = grp[\"omega\"].to_numpy(dtype=float)\n",
    "        x = grp[[\"msci_ret_q\", \"msci_ret_q_lag1\"]].to_numpy(dtype=float)\n",
    "        a, b0, b1 = fit_ols_beta(y, x)\n",
    "        betas_sg[(s, g)] = (a, b0, b1)\n",
    "\n",
    "    # Alpha by (strategy, grade, age_bucket)\n",
    "    alpha_sga = {}\n",
    "    alpha_sg = {}\n",
    "    alpha_s = {}\n",
    "\n",
    "    cal2 = cal.copy()\n",
    "    # Use best available betas to compute omega_adj\n",
    "    def get_betas(strategy: str, grade: str) -> Tuple[float, float, float]:\n",
    "        if (strategy, grade) in betas_sg:\n",
    "            return betas_sg[(strategy, grade)]\n",
    "        if strategy in betas_s:\n",
    "            return betas_s[strategy]\n",
    "        return betas_g\n",
    "\n",
    "    b0_list = []\n",
    "    b1_list = []\n",
    "    for _, r in cal2.iterrows():\n",
    "        a, b0, b1 = get_betas(r[\"Adj Strategy\"], r[\"Grade\"])\n",
    "        b0_list.append(b0)\n",
    "        b1_list.append(b1)\n",
    "    cal2[\"b0_used\"] = b0_list\n",
    "    cal2[\"b1_used\"] = b1_list\n",
    "    cal2[\"omega_adj\"] = cal2[\"omega\"] - cal2[\"b0_used\"] * cal2[\"msci_ret_q\"] - cal2[\"b1_used\"] * cal2[\"msci_ret_q_lag1\"]\n",
    "\n",
    "    for (s, g, a), grp in cal2.groupby([\"Adj Strategy\", \"Grade\", \"AgeBucket\"]):\n",
    "        if len(grp) < 10:\n",
    "            continue\n",
    "        alpha_sga[(s, g, a)] = (float(grp[\"omega_adj\"].mean()), \"sga\")\n",
    "\n",
    "    for (s, g), grp in cal2.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "        if len(grp) < 10:\n",
    "            continue\n",
    "        alpha_sg[(s, g)] = (float(grp[\"omega_adj\"].mean()), \"sg\")\n",
    "\n",
    "    for s, grp in cal2.groupby([\"Adj Strategy\"]):\n",
    "        alpha_s[s] = (float(grp[\"omega_adj\"].mean()), \"s\")\n",
    "\n",
    "    alpha_g = (float(cal2[\"omega_adj\"].mean()), \"g\")\n",
    "\n",
    "    # Sigma by (strategy, grade)\n",
    "    sigma_sg = {}\n",
    "    sigma_s = {}\n",
    "\n",
    "    cal2[\"omega_resid\"] = cal2[\"omega_adj\"] - cal2.groupby([\"Adj Strategy\", \"Grade\"])[\"omega_adj\"].transform(\"mean\")\n",
    "\n",
    "    for (s, g), grp in cal2.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "        if len(grp) < 20:\n",
    "            continue\n",
    "        sig = float(grp[\"omega_resid\"].std(ddof=1))\n",
    "        if not np.isfinite(sig) or sig <= 0:\n",
    "            continue\n",
    "        sigma_sg[(s, g)] = (sig, \"sg\")\n",
    "\n",
    "    for s, grp in cal2.groupby([\"Adj Strategy\"]):\n",
    "        sig = float(grp[\"omega_adj\"].std(ddof=1))\n",
    "        if np.isfinite(sig) and sig > 0:\n",
    "            sigma_s[s] = (sig, \"s\")\n",
    "\n",
    "    sigma_g = float(cal2[\"omega_adj\"].std(ddof=1))\n",
    "    if not np.isfinite(sigma_g) or sigma_g <= 0:\n",
    "        sigma_g = 0.05\n",
    "    sigma_g = (sigma_g, \"g\")\n",
    "\n",
    "    def get_alpha(strategy: str, grade: str, age_bucket: str) -> Tuple[float, str]:\n",
    "        k = (strategy, grade, age_bucket)\n",
    "        if k in alpha_sga:\n",
    "            return alpha_sga[k]\n",
    "        k2 = (strategy, grade)\n",
    "        if k2 in alpha_sg:\n",
    "            return alpha_sg[k2]\n",
    "        if strategy in alpha_s:\n",
    "            return alpha_s[strategy]\n",
    "        return alpha_g\n",
    "\n",
    "    def get_sigma(strategy: str, grade: str) -> Tuple[float, str]:\n",
    "        k = (strategy, grade)\n",
    "        if k in sigma_sg:\n",
    "            return sigma_sg[k]\n",
    "        if strategy in sigma_s:\n",
    "            return sigma_s[strategy]\n",
    "        return sigma_g\n",
    "\n",
    "    return get_betas, get_alpha, get_sigma\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# NAV Logic inline (no file outputs)\n",
    "# -----------------------------\n",
    "\n",
    "def run_nav_logic_inline(\n",
    "    data: pd.DataFrame,\n",
    "    msci_hist: pd.DataFrame,\n",
    "    msci_future: pd.DataFrame,\n",
    "    start_qe: pd.Timestamp,\n",
    "    data_dir: str,\n",
    "    alpha_level: float = 0.10,\n",
    "    min_clusters_for_inference: int = 8,\n",
    "    seed: int = 1234,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Keep methodology aligned with NAV Logic.ipynb\n",
    "    try:\n",
    "        from scipy import stats  # noqa: F401\n",
    "    except Exception as e:\n",
    "        raise ImportError(\"scipy is required for NAV Logic inline runs.\") from e\n",
    "\n",
    "    NAV_COL = \"NAV Adjusted EUR\"\n",
    "    DRAW_COL = \"Adj Drawdown EUR\"\n",
    "    REPAY_COL = \"Adj Repayment EUR\"\n",
    "    SIZE_COL = \"Target Fund Size\"\n",
    "\n",
    "    NAV_EPS = 100.0\n",
    "    OMEGA_CLIP = 0.8\n",
    "    GRADE_OMEGA_BIAS = {\"A\": 0.005, \"B\": 0.0, \"C\": -0.005, \"D\": -0.01}\n",
    "\n",
    "    MIN_FUNDS_BETA = 10\n",
    "    MIN_OBS_BETA = 80\n",
    "    MIN_FUNDS_ALPHA_BUCKET = 6\n",
    "    MIN_OBS_ALPHA_BUCKET = 60\n",
    "    SIGMA_SHRINK_K = 120.0\n",
    "    DRAW_EPS = 1000.0\n",
    "    SIZE_EPS = 1e6\n",
    "    MIN_OBS_RATIO = 50\n",
    "\n",
    "    df = data.copy()\n",
    "    df[\"quarter_end\"] = pd.to_datetime(df[\"quarter_end\"]).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    df = df.sort_values([\"FundID\", \"quarter_end\"]).reset_index(drop=True)\n",
    "\n",
    "    required_cols = [\n",
    "        \"FundID\", \"quarter_end\",\n",
    "        NAV_COL, DRAW_COL, REPAY_COL,\n",
    "        \"Adj Strategy\", \"Grade\",\n",
    "        SIZE_COL, \"Fund_Age_Quarters\",\n",
    "        \"Planned end date with add. years as per legal doc\",\n",
    "    ]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in data for NAV Logic inline: {missing}\")\n",
    "\n",
    "    df[\"planned_end_qe\"] = pd.to_datetime(\n",
    "        df[\"Planned end date with add. years as per legal doc\"],\n",
    "        errors=\"coerce\"\n",
    "    ).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "\n",
    "    df[NAV_COL] = pd.to_numeric(df[NAV_COL], errors=\"coerce\")\n",
    "    for c in [DRAW_COL, REPAY_COL, SIZE_COL, \"Fund_Age_Quarters\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # MSCI history (ensure lag exists)\n",
    "    msci_hist = msci_hist.copy()\n",
    "    msci_hist[\"quarter_end\"] = pd.to_datetime(msci_hist[\"quarter_end\"]).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    if \"msci_ret_q_lag1\" not in msci_hist.columns:\n",
    "        msci_hist[\"msci_ret_q_lag1\"] = msci_hist[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "    # MSCI future map (single path)\n",
    "    msci_future = msci_future.copy()\n",
    "    msci_future[\"quarter_end\"] = pd.to_datetime(msci_future[\"quarter_end\"]).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    if \"msci_ret_q_lag1\" not in msci_future.columns:\n",
    "        msci_future[\"msci_ret_q_lag1\"] = msci_future[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "    msci_future_map = {1: msci_future}\n",
    "    future_qe_max = msci_future[\"quarter_end\"].iloc[-1]\n",
    "\n",
    "    # Planned end overrun by strategy (history-based)\n",
    "    last_obs = df.groupby(\"FundID\")[\"quarter_end\"].max().rename(\"last_qe\")\n",
    "    fund_static = df.sort_values([\"FundID\", \"quarter_end\"]).groupby(\"FundID\").tail(1).copy()\n",
    "    fund_static = fund_static.merge(last_obs, on=\"FundID\", how=\"left\")\n",
    "\n",
    "    def quarters_diff(a: pd.Timestamp, b: pd.Timestamp) -> float:\n",
    "        if pd.isna(a) or pd.isna(b):\n",
    "            return np.nan\n",
    "        return float(pd.Period(a, freq=\"Q\").ordinal - pd.Period(b, freq=\"Q\").ordinal)\n",
    "\n",
    "    fund_static[\"overrun_q\"] = fund_static.apply(\n",
    "        lambda r: max(quarters_diff(r[\"last_qe\"], r[\"planned_end_qe\"]), 0.0)\n",
    "        if pd.notna(r[\"planned_end_qe\"]) else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    fund_static[\"ever_overran\"] = fund_static[\"overrun_q\"].fillna(0) > 0\n",
    "    ever_overran_map = fund_static.set_index(\"FundID\")[\"ever_overran\"]\n",
    "    overran_only = fund_static.loc[fund_static[\"overrun_q\"].notna() & (fund_static[\"overrun_q\"] > 0)].copy()\n",
    "    avg_overrun_by_strategy = overran_only.groupby(\"Adj Strategy\")[\"overrun_q\"].mean().clip(lower=0.0)\n",
    "\n",
    "    # Build omega from history for calibration\n",
    "    df[\"nav_prev\"] = df.groupby(\"FundID\")[NAV_COL].shift(1)\n",
    "    df[\"flow_net\"] = df[DRAW_COL] - df[REPAY_COL]\n",
    "    m = df[\"nav_prev\"].abs() > NAV_EPS\n",
    "    df[\"omega\"] = np.nan\n",
    "    df.loc[m, \"omega\"] = ((df.loc[m, NAV_COL] - df.loc[m, \"nav_prev\"]) - df.loc[m, \"flow_net\"]) / df.loc[m, \"nav_prev\"]\n",
    "    df[\"omega\"] = df[\"omega\"].clip(lower=-OMEGA_CLIP, upper=OMEGA_CLIP)\n",
    "\n",
    "    cal = df.merge(msci_hist, on=\"quarter_end\", how=\"left\")\n",
    "    cal = cal.dropna(subset=[\"omega\", \"msci_ret_q\", \"msci_ret_q_lag1\"]).copy()\n",
    "    cal[\"AgeBucket\"] = pd.cut(cal[\"Fund_Age_Quarters\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "    cal = cal[[\"FundID\", \"Adj Strategy\", \"Grade\", \"AgeBucket\", \"omega\", \"msci_ret_q\", \"msci_ret_q_lag1\"]].copy()\n",
    "    if cal.empty:\n",
    "        raise ValueError(\"NAV Logic inline: no calibration rows after filtering.\")\n",
    "\n",
    "    from scipy import stats\n",
    "\n",
    "    def ols_cluster_robust(df_in, y_col, x_cols, cluster_col):\n",
    "        d = df_in.dropna(subset=[y_col] + x_cols + [cluster_col]).copy()\n",
    "        n = len(d)\n",
    "        if n == 0:\n",
    "            return None\n",
    "\n",
    "        y = d[y_col].to_numpy(float)\n",
    "        X = np.column_stack([np.ones(n)] + [d[c].to_numpy(float) for c in x_cols])\n",
    "        k = X.shape[1]\n",
    "\n",
    "        XtX = X.T @ X\n",
    "        XtX_inv = np.linalg.pinv(XtX)\n",
    "        beta = XtX_inv @ (X.T @ y)\n",
    "\n",
    "        u = y - X @ beta\n",
    "        clusters = d[cluster_col].to_numpy()\n",
    "        uniq = pd.unique(clusters)\n",
    "        G = len(uniq)\n",
    "        df_dof = G - 1\n",
    "        if G <= 1:\n",
    "            return None\n",
    "\n",
    "        meat = np.zeros((k, k), dtype=float)\n",
    "        for g in uniq:\n",
    "            mask = (clusters == g)\n",
    "            Xg = X[mask, :]\n",
    "            ug = u[mask]\n",
    "            Xgu = Xg.T @ ug\n",
    "            meat += np.outer(Xgu, Xgu)\n",
    "\n",
    "        V = XtX_inv @ meat @ XtX_inv\n",
    "        scale = (G / (G - 1)) * ((n - 1) / max(n - k, 1))\n",
    "        V *= scale\n",
    "\n",
    "        se = np.sqrt(np.diag(V))\n",
    "        tstats = beta / se\n",
    "        pvals = 2.0 * (1.0 - stats.t.cdf(np.abs(tstats), df=df_dof))\n",
    "\n",
    "        names = [\"alpha\"] + x_cols\n",
    "        return {\n",
    "            \"coef\": pd.Series(beta, index=names),\n",
    "            \"se\": pd.Series(se, index=names),\n",
    "            \"t\": pd.Series(tstats, index=names),\n",
    "            \"p\": pd.Series(pvals, index=names),\n",
    "            \"n_obs\": int(n),\n",
    "            \"n_clusters\": int(G),\n",
    "            \"df_dof\": int(df_dof),\n",
    "        }\n",
    "\n",
    "    def cluster_mean_stats(df_in, y_col, cluster_col):\n",
    "        res = ols_cluster_robust(df_in, y_col=y_col, x_cols=[], cluster_col=cluster_col)\n",
    "        if res is None:\n",
    "            return None\n",
    "        return {\n",
    "            \"alpha\": float(res[\"coef\"][\"alpha\"]),\n",
    "            \"se_alpha\": float(res[\"se\"][\"alpha\"]),\n",
    "            \"t_alpha\": float(res[\"t\"][\"alpha\"]),\n",
    "            \"p_alpha\": float(res[\"p\"][\"alpha\"]),\n",
    "            \"n_obs\": res[\"n_obs\"],\n",
    "            \"n_funds\": res[\"n_clusters\"],\n",
    "            \"df\": res[\"df_dof\"],\n",
    "        }\n",
    "\n",
    "    # Betas\n",
    "    beta_rows_sg = []\n",
    "    for (s, g), grp in cal.groupby([\"Adj Strategy\", \"Grade\"], dropna=False):\n",
    "        res = ols_cluster_robust(grp, \"omega\", [\"msci_ret_q\", \"msci_ret_q_lag1\"], \"FundID\")\n",
    "        if res is None:\n",
    "            continue\n",
    "        n_funds = res[\"n_clusters\"]\n",
    "        usable = (n_funds >= min_clusters_for_inference)\n",
    "\n",
    "        b0 = float(res[\"coef\"][\"msci_ret_q\"])\n",
    "        b1 = float(res[\"coef\"][\"msci_ret_q_lag1\"])\n",
    "        p0 = float(res[\"p\"][\"msci_ret_q\"])\n",
    "        p1 = float(res[\"p\"][\"msci_ret_q_lag1\"])\n",
    "        use_beta = bool(usable and ((p0 < alpha_level) or (p1 < alpha_level)))\n",
    "\n",
    "        beta_rows_sg.append({\n",
    "            \"Adj Strategy\": s, \"Grade\": g,\n",
    "            \"b0\": b0, \"b1\": b1,\n",
    "            \"p_b0\": p0, \"p_b1\": p1,\n",
    "            \"n_obs\": res[\"n_obs\"], \"n_funds\": n_funds,\n",
    "            \"use_beta\": use_beta\n",
    "        })\n",
    "    beta_sg = pd.DataFrame(beta_rows_sg)\n",
    "\n",
    "    beta_rows_s = []\n",
    "    for s, grp in cal.groupby([\"Adj Strategy\"], dropna=False):\n",
    "        res = ols_cluster_robust(grp, \"omega\", [\"msci_ret_q\", \"msci_ret_q_lag1\"], \"FundID\")\n",
    "        if res is None:\n",
    "            continue\n",
    "        n_funds = res[\"n_clusters\"]\n",
    "        usable = (n_funds >= min_clusters_for_inference)\n",
    "\n",
    "        b0 = float(res[\"coef\"][\"msci_ret_q\"])\n",
    "        b1 = float(res[\"coef\"][\"msci_ret_q_lag1\"])\n",
    "        p0 = float(res[\"p\"][\"msci_ret_q\"])\n",
    "        p1 = float(res[\"p\"][\"msci_ret_q_lag1\"])\n",
    "        use_beta = bool(usable and ((p0 < alpha_level) or (p1 < alpha_level)))\n",
    "\n",
    "        beta_rows_s.append({\n",
    "            \"Adj Strategy\": s, \"b0\": b0, \"b1\": b1,\n",
    "            \"p_b0\": p0, \"p_b1\": p1,\n",
    "            \"n_obs\": res[\"n_obs\"], \"n_funds\": n_funds,\n",
    "            \"use_beta\": use_beta\n",
    "        })\n",
    "    beta_s = pd.DataFrame(beta_rows_s)\n",
    "\n",
    "    res_g = ols_cluster_robust(cal, \"omega\", [\"msci_ret_q\", \"msci_ret_q_lag1\"], \"FundID\")\n",
    "    if res_g is None:\n",
    "        raise ValueError(\"NAV Logic inline: global beta regression failed.\")\n",
    "    b0_g = float(res_g[\"coef\"][\"msci_ret_q\"])\n",
    "    b1_g = float(res_g[\"coef\"][\"msci_ret_q_lag1\"])\n",
    "\n",
    "    beta_sg_use = beta_sg.loc[beta_sg[\"use_beta\"]].set_index([\"Adj Strategy\", \"Grade\"])[[\"b0\", \"b1\"]].to_dict(\"index\")\n",
    "    beta_s_use = beta_s.loc[beta_s[\"use_beta\"]].set_index([\"Adj Strategy\"])[[\"b0\", \"b1\"]].to_dict(\"index\")\n",
    "\n",
    "    def get_betas(strategy, grade):\n",
    "        k = (strategy, grade)\n",
    "        if k in beta_sg_use:\n",
    "            d = beta_sg_use[k]\n",
    "            return float(d[\"b0\"]), float(d[\"b1\"]), \"sg_sig\"\n",
    "        if strategy in beta_s_use:\n",
    "            d = beta_s_use[strategy]\n",
    "            return float(d[\"b0\"]), float(d[\"b1\"]), \"s_sig\"\n",
    "        return float(b0_g), float(b1_g), \"global\"\n",
    "\n",
    "    # Alpha\n",
    "    cal2 = cal.copy()\n",
    "    b0_used = []\n",
    "    b1_used = []\n",
    "    for _, r in cal2.iterrows():\n",
    "        b0, b1, _ = get_betas(r[\"Adj Strategy\"], r[\"Grade\"])\n",
    "        b0_used.append(b0); b1_used.append(b1)\n",
    "    cal2[\"b0_used\"] = b0_used\n",
    "    cal2[\"b1_used\"] = b1_used\n",
    "    cal2[\"omega_adj\"] = cal2[\"omega\"] - cal2[\"b0_used\"]*cal2[\"msci_ret_q\"] - cal2[\"b1_used\"]*cal2[\"msci_ret_q_lag1\"]\n",
    "\n",
    "    alpha_rows_sga = []\n",
    "    for (s, g, a), grp in cal2.groupby([\"Adj Strategy\",\"Grade\",\"AgeBucket\"], dropna=False):\n",
    "        st = cluster_mean_stats(grp, \"omega_adj\", \"FundID\")\n",
    "        if st is None:\n",
    "            continue\n",
    "        use_alpha = bool((st[\"n_funds\"] >= min_clusters_for_inference) and (st[\"p_alpha\"] < alpha_level))\n",
    "        alpha_rows_sga.append({\"Adj Strategy\": s, \"Grade\": g, \"AgeBucket\": a, **st, \"use_alpha\": use_alpha})\n",
    "    alpha_sga = pd.DataFrame(alpha_rows_sga)\n",
    "\n",
    "    alpha_rows_sg = []\n",
    "    for (s, g), grp in cal2.groupby([\"Adj Strategy\",\"Grade\"], dropna=False):\n",
    "        st = cluster_mean_stats(grp, \"omega_adj\", \"FundID\")\n",
    "        if st is None:\n",
    "            continue\n",
    "        use_alpha = bool((st[\"n_funds\"] >= min_clusters_for_inference) and (st[\"p_alpha\"] < alpha_level))\n",
    "        alpha_rows_sg.append({\"Adj Strategy\": s, \"Grade\": g, **st, \"use_alpha\": use_alpha})\n",
    "    alpha_sg = pd.DataFrame(alpha_rows_sg)\n",
    "\n",
    "    alpha_rows_s = []\n",
    "    for s, grp in cal2.groupby([\"Adj Strategy\"], dropna=False):\n",
    "        st = cluster_mean_stats(grp, \"omega_adj\", \"FundID\")\n",
    "        if st is None:\n",
    "            continue\n",
    "        use_alpha = bool((st[\"n_funds\"] >= min_clusters_for_inference) and (st[\"p_alpha\"] < alpha_level))\n",
    "        alpha_rows_s.append({\"Adj Strategy\": s, **st, \"use_alpha\": use_alpha})\n",
    "    alpha_s = pd.DataFrame(alpha_rows_s)\n",
    "\n",
    "    st_g = cluster_mean_stats(cal2, \"omega_adj\", \"FundID\")\n",
    "    alpha_global = float(st_g[\"alpha\"]) if st_g else 0.0\n",
    "\n",
    "    alpha_sga_use = alpha_sga.loc[alpha_sga[\"use_alpha\"]].set_index([\"Adj Strategy\",\"Grade\",\"AgeBucket\"])[\"alpha\"].to_dict()\n",
    "    alpha_sg_use  = alpha_sg.loc[alpha_sg[\"use_alpha\"]].set_index([\"Adj Strategy\",\"Grade\"])[\"alpha\"].to_dict()\n",
    "    alpha_s_use   = alpha_s.loc[alpha_s[\"use_alpha\"]].set_index([\"Adj Strategy\"])[\"alpha\"].to_dict()\n",
    "\n",
    "    def get_alpha(strategy, grade, age_bucket):\n",
    "        k = (strategy, grade, age_bucket)\n",
    "        if k in alpha_sga_use:\n",
    "            return float(alpha_sga_use[k]), \"sga_sig\"\n",
    "        k2 = (strategy, grade)\n",
    "        if k2 in alpha_sg_use:\n",
    "            return float(alpha_sg_use[k2]), \"sg_sig\"\n",
    "        if strategy in alpha_s_use:\n",
    "            return float(alpha_s_use[strategy]), \"s_sig\"\n",
    "        return float(alpha_global), \"global\"\n",
    "\n",
    "    # Sigma\n",
    "    resid = []\n",
    "    for _, r in cal.iterrows():\n",
    "        b0, b1, _ = get_betas(r[\"Adj Strategy\"], r[\"Grade\"])\n",
    "        a, _ = get_alpha(r[\"Adj Strategy\"], r[\"Grade\"], r[\"AgeBucket\"])\n",
    "        pred = a + b0*r[\"msci_ret_q\"] + b1*r[\"msci_ret_q_lag1\"]\n",
    "        resid.append(float(r[\"omega\"] - pred))\n",
    "\n",
    "    cal_res = cal.copy()\n",
    "    cal_res[\"resid\"] = resid\n",
    "\n",
    "    sigma_sg = (\n",
    "        cal_res.groupby([\"Adj Strategy\",\"Grade\"], dropna=False)\n",
    "               .agg(n_obs=(\"resid\",\"size\"),\n",
    "                    sigma=(\"resid\", lambda x: float(np.std(x, ddof=1)) if len(x) > 2 else 0.10))\n",
    "               .reset_index()\n",
    "    )\n",
    "    sigma_global = float(np.std(cal_res[\"resid\"], ddof=1))\n",
    "    sigma_global = max(sigma_global, 0.02)\n",
    "\n",
    "    sigma_sg_map = sigma_sg.set_index([\"Adj Strategy\",\"Grade\"])[[\"sigma\",\"n_obs\"]].to_dict(\"index\")\n",
    "\n",
    "    def get_sigma(strategy, grade):\n",
    "        k = (strategy, grade)\n",
    "        if k in sigma_sg_map:\n",
    "            s = float(sigma_sg_map[k][\"sigma\"])\n",
    "            n = float(sigma_sg_map[k][\"n_obs\"])\n",
    "            w = n / (n + SIGMA_SHRINK_K)\n",
    "            return float(w*s + (1.0-w)*sigma_global), \"sg_shrunk\"\n",
    "        return float(sigma_global), \"global\"\n",
    "\n",
    "    # NAV_start imputation\n",
    "    hist_upto = df.loc[df[\"quarter_end\"] <= start_qe].copy()\n",
    "    if hist_upto.empty:\n",
    "        raise ValueError(\"NAV Logic inline: no data at or before start quarter.\")\n",
    "\n",
    "    hist_upto = hist_upto.sort_values([\"FundID\",\"quarter_end\"])\n",
    "    base_rows = hist_upto.groupby(\"FundID\").tail(1).copy()\n",
    "\n",
    "    base_rows[\"ever_overran\"] = base_rows[\"FundID\"].map(ever_overran_map).fillna(False)\n",
    "\n",
    "    caps = []\n",
    "    for _, r in base_rows.iterrows():\n",
    "        planned = r[\"planned_end_qe\"]\n",
    "        if pd.isna(planned):\n",
    "            caps.append(future_qe_max)\n",
    "            continue\n",
    "        if bool(r[\"ever_overran\"]):\n",
    "            avg_over = float(avg_overrun_by_strategy.get(r[\"Adj Strategy\"], 0.0))\n",
    "            caps.append(add_quarters(planned, avg_over))\n",
    "        else:\n",
    "            caps.append(planned)\n",
    "    base_rows[\"cap_qe\"] = caps\n",
    "    base_rows[\"AgeBucket\"] = pd.cut(base_rows[\"Fund_Age_Quarters\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "\n",
    "    hist_upto[\"draw_cum\"] = hist_upto.groupby(\"FundID\")[DRAW_COL].cumsum()\n",
    "    if \"draw_cum\" not in base_rows.columns:\n",
    "        base_rows = base_rows.merge(\n",
    "            hist_upto.groupby(\"FundID\")[\"draw_cum\"].last().reset_index(),\n",
    "            on=\"FundID\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "    tmp = hist_upto.copy()\n",
    "    tmp[\"AgeBucket\"] = pd.cut(tmp[\"Fund_Age_Quarters\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "\n",
    "    tmp[\"ratio_nav_draw\"] = np.where(\n",
    "        (tmp[NAV_COL].notna()) & (tmp[NAV_COL].abs() > NAV_EPS) & (tmp[\"draw_cum\"] > DRAW_EPS),\n",
    "        tmp[NAV_COL] / tmp[\"draw_cum\"],\n",
    "        np.nan\n",
    "    )\n",
    "    tmp[\"ratio_nav_size\"] = np.where(\n",
    "        (tmp[NAV_COL].notna()) & (tmp[NAV_COL].abs() > NAV_EPS) & (tmp[SIZE_COL] > SIZE_EPS),\n",
    "        tmp[NAV_COL] / tmp[SIZE_COL],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    tmp[\"log_ratio_nav_draw\"] = np.log(tmp[\"ratio_nav_draw\"])\n",
    "    tmp[\"log_ratio_nav_size\"] = np.log(tmp[\"ratio_nav_size\"])\n",
    "    tmp.loc[~np.isfinite(tmp[\"log_ratio_nav_draw\"]), \"log_ratio_nav_draw\"] = np.nan\n",
    "    tmp.loc[~np.isfinite(tmp[\"log_ratio_nav_size\"]), \"log_ratio_nav_size\"] = np.nan\n",
    "\n",
    "    ratio_key = [\"Adj Strategy\",\"Grade\",\"AgeBucket\"]\n",
    "\n",
    "    def fit_lognorm(df_in: pd.DataFrame, col: str) -> pd.Series:\n",
    "        g = df_in[col].dropna()\n",
    "        if len(g) < MIN_OBS_RATIO:\n",
    "            return pd.Series({\"mu\": np.nan, \"sig\": np.nan, \"n\": len(g)})\n",
    "        return pd.Series({\"mu\": float(g.mean()), \"sig\": float(g.std(ddof=1)), \"n\": len(g)})\n",
    "\n",
    "    ratio_draw = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_draw\")).reset_index()\n",
    "    ratio_size = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_size\")).reset_index()\n",
    "\n",
    "    gdraw = ratio_draw.dropna(subset=[\"mu\",\"sig\"])\n",
    "    gsize = ratio_size.dropna(subset=[\"mu\",\"sig\"])\n",
    "    fallback_draw = {\"mu\": float(gdraw[\"mu\"].median()) if len(gdraw) else 0.0,\n",
    "                     \"sig\": float(gdraw[\"sig\"].median()) if len(gdraw) else 0.75}\n",
    "    fallback_size = {\"mu\": float(gsize[\"mu\"].median()) if len(gsize) else -2.0,\n",
    "                     \"sig\": float(gsize[\"sig\"].median()) if len(gsize) else 0.75}\n",
    "\n",
    "    ratio_draw_map = ratio_draw.set_index(ratio_key)[[\"mu\",\"sig\",\"n\"]].to_dict(\"index\")\n",
    "    ratio_size_map = ratio_size.set_index(ratio_key)[[\"mu\",\"sig\",\"n\"]].to_dict(\"index\")\n",
    "\n",
    "    def lookup_ratio(map_, strategy, grade, age_bucket, fallback):\n",
    "        k = (strategy, grade, age_bucket)\n",
    "        if k in map_:\n",
    "            d = map_[k]\n",
    "            if pd.notna(d[\"mu\"]) and pd.notna(d[\"sig\"]) and d[\"n\"] >= MIN_OBS_RATIO:\n",
    "                return float(d[\"mu\"]), float(d[\"sig\"]), \"bucket\"\n",
    "        return float(fallback[\"mu\"]), float(fallback[\"sig\"]), \"global\"\n",
    "\n",
    "    rng_init = np.random.default_rng(2025)\n",
    "    base_rows[\"NAV_start\"] = base_rows[NAV_COL]\n",
    "    base_rows[\"NAV_start_source\"] = \"observed\"\n",
    "\n",
    "    for idx, r in base_rows.iterrows():\n",
    "        nav_obs = r[\"NAV_start\"]\n",
    "        if pd.notna(nav_obs) and abs(nav_obs) > NAV_EPS:\n",
    "            continue\n",
    "\n",
    "        draw_cum = r.get(\"draw_cum\", 0.0)\n",
    "        size = r.get(SIZE_COL, 0.0)\n",
    "        draw_cum = 0.0 if pd.isna(draw_cum) else float(draw_cum)\n",
    "        size = 0.0 if pd.isna(size) else float(size)\n",
    "\n",
    "        strategy = r[\"Adj Strategy\"]\n",
    "        grade = r.get(\"AssignedGrade\", r[\"Grade\"])\n",
    "        if pd.isna(grade):\n",
    "            grade = r[\"Grade\"]\n",
    "        age_bucket = r[\"AgeBucket\"]\n",
    "\n",
    "        if draw_cum > DRAW_EPS:\n",
    "            mu, sig, src = lookup_ratio(ratio_draw_map, strategy, grade, age_bucket, fallback_draw)\n",
    "            ratio = float(np.exp(mu + sig * rng_init.standard_normal()))\n",
    "            ratio = float(np.clip(ratio, 0.05, 5.0))\n",
    "            base_rows.at[idx, \"NAV_start\"] = ratio * draw_cum\n",
    "            base_rows.at[idx, \"NAV_start_source\"] = f\"imputed_draw_{src}\"\n",
    "        else:\n",
    "            base_rows.at[idx, \"NAV_start\"] = 0.0\n",
    "            base_rows.at[idx, \"NAV_start_source\"] = \"imputed_zero_nodraw\"\n",
    "\n",
    "    base_rows[\"NAV_start\"] = pd.to_numeric(base_rows[\"NAV_start\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # Grade transitions (yearly)\n",
    "    GRADE_STATES = [\"A\",\"B\",\"C\",\"D\"]\n",
    "    p1_all_path = os.path.join(data_dir, \"grade_transition_1y_all.csv\")\n",
    "    p1_pe_path  = os.path.join(data_dir, \"grade_transition_1y_pe.csv\")\n",
    "    p1_vc_path  = os.path.join(data_dir, \"grade_transition_1y_vc.csv\")\n",
    "    P1_ALL = pd.read_csv(p1_all_path, index_col=0) if os.path.exists(p1_all_path) else None\n",
    "    P1_PE  = pd.read_csv(p1_pe_path, index_col=0) if os.path.exists(p1_pe_path) else None\n",
    "    P1_VC  = pd.read_csv(p1_vc_path, index_col=0) if os.path.exists(p1_vc_path) else None\n",
    "\n",
    "    def _row_norm_df(P):\n",
    "        P = P.reindex(index=GRADE_STATES, columns=GRADE_STATES).fillna(0.0).clip(lower=0.0)\n",
    "        rs = P.sum(axis=1).replace(0.0, 1.0)\n",
    "        return P.div(rs, axis=0)\n",
    "\n",
    "    if P1_ALL is not None: P1_ALL = _row_norm_df(P1_ALL)\n",
    "    if P1_PE  is not None: P1_PE  = _row_norm_df(P1_PE)\n",
    "    if P1_VC  is not None: P1_VC  = _row_norm_df(P1_VC)\n",
    "\n",
    "    def build_yearly_transition_from_data(df_in, strategy=None):\n",
    "        d = df_in[[\"FundID\",\"quarter_end\",\"Grade\",\"Adj Strategy\"]].copy()\n",
    "        if strategy is not None:\n",
    "            d = d[d[\"Adj Strategy\"] == strategy]\n",
    "        d = d.dropna(subset=[\"FundID\",\"quarter_end\",\"Grade\"])\n",
    "        d[\"Grade\"] = d[\"Grade\"].astype(str).str.strip()\n",
    "        d = d[d[\"Grade\"].isin(GRADE_STATES)]\n",
    "        d = d.sort_values([\"FundID\",\"quarter_end\"])\n",
    "\n",
    "        transitions = []\n",
    "        for _, g in d.groupby(\"FundID\", sort=False):\n",
    "            grades = g[\"Grade\"].tolist()\n",
    "            if len(grades) < 5:\n",
    "                continue\n",
    "            yearly = grades[::4]\n",
    "            if len(yearly) < 2:\n",
    "                continue\n",
    "            transitions.extend(zip(yearly[:-1], yearly[1:]))\n",
    "\n",
    "        if not transitions:\n",
    "            counts = pd.DataFrame(0.0, index=GRADE_STATES, columns=GRADE_STATES)\n",
    "            probs = pd.DataFrame(np.eye(4), index=GRADE_STATES, columns=GRADE_STATES)\n",
    "            return counts, probs, 0\n",
    "\n",
    "        counts = pd.crosstab(\n",
    "            [a for a, _ in transitions],\n",
    "            [b for _, b in transitions]\n",
    "        ).reindex(index=GRADE_STATES, columns=GRADE_STATES, fill_value=0).astype(float)\n",
    "\n",
    "        probs = counts.div(counts.sum(axis=1).replace(0.0, 1.0), axis=0)\n",
    "        return counts, probs, len(transitions)\n",
    "\n",
    "    all_counts, all_probs, all_n = build_yearly_transition_from_data(df, strategy=None)\n",
    "    pe_counts, pe_probs, pe_n = build_yearly_transition_from_data(df, strategy=\"Private Equity\")\n",
    "    vc_counts, vc_probs, vc_n = build_yearly_transition_from_data(df, strategy=\"Venture Capital\")\n",
    "\n",
    "    def get_transition_matrix(strategy):\n",
    "        if strategy == \"Private Equity\" and P1_PE is not None:\n",
    "            return P1_PE, \"PE_1Y\"\n",
    "        if strategy == \"Venture Capital\" and P1_VC is not None:\n",
    "            return P1_VC, \"VC_1Y\"\n",
    "        if P1_ALL is not None:\n",
    "            return P1_ALL, \"ALL_1Y\"\n",
    "        if strategy == \"Private Equity\" and pe_n > 0:\n",
    "            return pe_probs, \"PE_DATA\"\n",
    "        if strategy == \"Venture Capital\" and vc_n > 0:\n",
    "            return vc_probs, \"VC_DATA\"\n",
    "        if all_n > 0:\n",
    "            return all_probs, \"ALL_DATA\"\n",
    "        return pd.DataFrame(np.eye(4), index=GRADE_STATES, columns=GRADE_STATES), \"IDENTITY\"\n",
    "\n",
    "    def sample_next_grade(curr_grade, P_df, rng):\n",
    "        if curr_grade not in GRADE_STATES:\n",
    "            curr_grade = \"D\"\n",
    "        row = P_df.loc[curr_grade].values.astype(float)\n",
    "        return str(rng.choice(GRADE_STATES, p=row))\n",
    "\n",
    "    # Projection loop (omega only)\n",
    "    omega_rows = []\n",
    "    sim_ids = [1]\n",
    "    for sim_id in sim_ids:\n",
    "        rng = np.random.default_rng(seed + int(sim_id))\n",
    "        msci_future_use = msci_future_map[sim_id]\n",
    "        for _, r in base_rows.iterrows():\n",
    "            fund_id = r[\"FundID\"]\n",
    "            age0 = int(r[\"Fund_Age_Quarters\"]) if pd.notna(r[\"Fund_Age_Quarters\"]) else 0\n",
    "            strategy = r[\"Adj Strategy\"]\n",
    "            grade = r[\"Grade\"] if pd.notna(r[\"Grade\"]) else \"D\"\n",
    "            cap_qe = r[\"cap_qe\"]\n",
    "            if pd.isna(cap_qe):\n",
    "                cap_qe = msci_future_use[\"quarter_end\"].iloc[-1]\n",
    "\n",
    "            for step, (qe, msci_r, msci_r_lag1) in enumerate(\n",
    "                zip(msci_future_use[\"quarter_end\"], msci_future_use[\"msci_ret_q\"], msci_future_use[\"msci_ret_q_lag1\"]),\n",
    "                start=1\n",
    "            ):\n",
    "                if qe > cap_qe:\n",
    "                    break\n",
    "\n",
    "                msci_r_lag1 = 0.0 if pd.isna(msci_r_lag1) else float(msci_r_lag1)\n",
    "                age = age0 + step\n",
    "                age_bucket = pd.cut(pd.Series([age]), bins=AGE_BINS_Q, labels=AGE_LABELS).iloc[0]\n",
    "\n",
    "                prev_grade = grade\n",
    "                if step % 4 == 0:\n",
    "                    P, _ = get_transition_matrix(strategy)\n",
    "                    grade = sample_next_grade(grade, P, rng)\n",
    "\n",
    "                b0, b1, _ = get_betas(strategy, grade)\n",
    "                alpha, _ = get_alpha(strategy, grade, age_bucket)\n",
    "                sigma, _ = get_sigma(strategy, grade)\n",
    "\n",
    "                eps = rng.standard_normal()\n",
    "                omega = alpha + b0*float(msci_r) + b1*msci_r_lag1 + sigma*eps\n",
    "                omega += float(GRADE_OMEGA_BIAS.get(grade, 0.0))\n",
    "                if not np.isfinite(omega):\n",
    "                    omega = 0.0\n",
    "                omega = float(np.clip(omega, -OMEGA_CLIP, OMEGA_CLIP))\n",
    "\n",
    "                omega_rows.append({\n",
    "                    \"sim_id\": int(sim_id),\n",
    "                    \"FundID\": fund_id,\n",
    "                    \"quarter_end\": qe,\n",
    "                    \"step_q\": step,\n",
    "                    \"msci_ret_q\": float(msci_r),\n",
    "                    \"msci_ret_q_lag1\": float(msci_r_lag1),\n",
    "                    \"omega\": float(omega),\n",
    "                    \"Fund_Age_Quarters\": int(age),\n",
    "                    \"Adj Strategy\": strategy,\n",
    "                    \"Grade_prev\": prev_grade,\n",
    "                    \"Grade\": grade,\n",
    "                    \"AgeBucket\": age_bucket,\n",
    "                    \"cap_qe\": cap_qe,\n",
    "                })\n",
    "\n",
    "    omega_proj = pd.DataFrame(omega_rows)\n",
    "    navstart = base_rows[[\n",
    "        \"FundID\",\"Adj Strategy\",\"Grade\",\"Fund_Age_Quarters\",\"NAV_start\",\"NAV_start_source\",\"cap_qe\"\n",
    "    ]].copy()\n",
    "\n",
    "    return omega_proj, navstart\n",
    "\n",
    "# -----------------------------\n",
    "# NAV Logic inputs (optional)\n",
    "# -----------------------------\n",
    "\n",
    "def find_omega_file(data_dir: str, start_qe: Optional[pd.Timestamp] = None,\n",
    "                    end_qe: Optional[pd.Timestamp] = None) -> str:\n",
    "    cands = glob.glob(os.path.join(data_dir, \"omega_projection_sota_*.parquet\")) + \\\n",
    "            glob.glob(os.path.join(data_dir, \"omega_projection_sota_*.csv\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No omega_projection_sota_* file found. Run NAV Logic first.\")\n",
    "\n",
    "    if start_qe is None or end_qe is None:\n",
    "        cands.sort(key=os.path.getmtime, reverse=True)\n",
    "        return cands[0]\n",
    "\n",
    "    best_path = None\n",
    "    best_overlap = -1\n",
    "    best_mtime = -1\n",
    "    ranges = []\n",
    "\n",
    "    for p in cands:\n",
    "        try:\n",
    "            if p.lower().endswith(\".parquet\"):\n",
    "                df = pd.read_parquet(p, columns=[\"quarter_end\"])\n",
    "            else:\n",
    "                df = pd.read_csv(p, usecols=[\"quarter_end\"])\n",
    "            q = pd.to_datetime(df[\"quarter_end\"], errors=\"coerce\").dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "            q = q.dropna()\n",
    "            if q.empty:\n",
    "                continue\n",
    "            qmin = q.min()\n",
    "            qmax = q.max()\n",
    "            ranges.append((p, qmin, qmax))\n",
    "\n",
    "            ov_start = max(start_qe, qmin)\n",
    "            ov_end = min(end_qe, qmax)\n",
    "            if ov_end < ov_start:\n",
    "                overlap = -1\n",
    "            else:\n",
    "                overlap = len(pd.period_range(ov_start, ov_end, freq=\"Q\"))\n",
    "\n",
    "            mtime = os.path.getmtime(p)\n",
    "            if overlap > best_overlap or (overlap == best_overlap and mtime > best_mtime):\n",
    "                best_overlap = overlap\n",
    "                best_mtime = mtime\n",
    "                best_path = p\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if best_path is None or best_overlap <= 0:\n",
    "        msg = \"No omega_projection_sota_* file overlaps the test window.\"\n",
    "        if ranges:\n",
    "            msg += \" Available ranges:\\n\" + \"\\n\".join([f\"- {os.path.basename(p)}: {a.date()} to {b.date()}\" for p, a, b in ranges])\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    return best_path\n",
    "\n",
    "\n",
    "def find_navstart_file(data_dir: str, year: int, quarter: str) -> str:\n",
    "    cands = [\n",
    "        os.path.join(data_dir, f\"nav_start_sota_{year}_{quarter}.parquet\"),\n",
    "        os.path.join(data_dir, f\"nav_start_sota_{year}_{quarter}.csv\"),\n",
    "    ]\n",
    "    for p in cands:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    c2 = glob.glob(os.path.join(data_dir, \"nav_start_sota_*.parquet\")) + \\\n",
    "         glob.glob(os.path.join(data_dir, \"nav_start_sota_*.csv\"))\n",
    "    if not c2:\n",
    "        raise FileNotFoundError(\"No nav_start_sota_* file found. Run NAV Logic first.\")\n",
    "    c2.sort(key=os.path.getmtime, reverse=True)\n",
    "    return c2[0]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main backtest\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    t0 = time.perf_counter()\n",
    "    year = int(input(\"Enter year (e.g. 2025): \").strip())\n",
    "    quarter = input(\"Enter quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "    train_year = int(input(\"Train end year (e.g. 2018): \").strip())\n",
    "    train_quarter = input(\"Train end quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "    test_year = input(\"Test end year (blank => max in data): \").strip()\n",
    "    test_quarter = \"\"\n",
    "    if test_year:\n",
    "        test_year = int(test_year)\n",
    "        test_quarter = input(\"Test end quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "    n_sims = int(input(\"MC simulations [500]: \").strip() or \"500\")\n",
    "    seed = int(input(\"Random seed [1234]: \").strip() or \"1234\")\n",
    "    rho_event = float(input(\"Copula correlation events rho_event [0.25]: \").strip() or \"0.25\")\n",
    "    rho_size = float(input(\"Copula correlation sizes rho_size [0.15]: \").strip() or \"0.15\")\n",
    "    scenario_uncond = input(\"Unconditional scenario (bullish/neutral/bearish) [neutral]: \").strip().lower() or \"neutral\"\n",
    "    tilt_strength = float(input(\"Unconditional tilt strength [1.2]: \").strip() or \"1.2\")\n",
    "\n",
    "    rho_event = float(np.clip(rho_event, 0.0, 0.999))\n",
    "    rho_size = float(np.clip(rho_size, 0.0, 0.999))\n",
    "\n",
    "    BASE_DIR = os.environ.get(\n",
    "        \"EQUITY_BASE_DIR\",\n",
    "        os.path.join(\"C:\", \"Users\", os.environ.get(\"USERNAME\", \"\"), \"Documents\", \"Equity\")\n",
    "    )\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        BASE_DIR = os.path.abspath(os.getcwd())\n",
    "\n",
    "    HOME = os.path.join(BASE_DIR, f\"{year}_{quarter}\")\n",
    "    DATA_DIR = os.path.join(HOME, \"data\")\n",
    "\n",
    "    data_path_parquet = os.path.join(DATA_DIR, \"data.parquet\")\n",
    "    data_path_csv = os.path.join(DATA_DIR, \"data.csv\")\n",
    "    kmp_path_parquet = os.path.join(DATA_DIR, \"kmp.parquet\")\n",
    "    kmp_path_csv = os.path.join(DATA_DIR, \"kmp.csv\")\n",
    "\n",
    "    if os.path.exists(data_path_parquet):\n",
    "        data = pd.read_parquet(data_path_parquet)\n",
    "    elif os.path.exists(data_path_csv):\n",
    "        data = pd.read_csv(data_path_csv)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Missing data.parquet or data.csv in {DATA_DIR}\")\n",
    "\n",
    "    if os.path.exists(kmp_path_parquet):\n",
    "        kmp = pd.read_parquet(kmp_path_parquet)\n",
    "    elif os.path.exists(kmp_path_csv):\n",
    "        kmp = pd.read_csv(kmp_path_csv)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Missing kmp.parquet or kmp.csv\")\n",
    "\n",
    "    # normalize column names (trim/collapse spaces) to avoid hidden KeyErrors\n",
    "    def _norm_col(c):\n",
    "        if not isinstance(c, str):\n",
    "            return c\n",
    "        return \" \".join(c.strip().split())\n",
    "\n",
    "    data.columns = [_norm_col(c) for c in data.columns]\n",
    "    kmp.columns = [_norm_col(c) for c in kmp.columns]\n",
    "\n",
    "    req = [\n",
    "        \"FundID\", \"Adj Strategy\", \"Grade\", \"Fund_Age_Quarters\",\n",
    "        \"Year of Transaction Date\", \"Quarter of Transaction Date\",\n",
    "        \"Adj Drawdown EUR\", \"Adj Repayment EUR\",\n",
    "        \"NAV Adjusted EUR\", \"Recallable\",\n",
    "        \"Planned end date with add. years as per legal doc\",\n",
    "    ]\n",
    "    missing = [c for c in req if c not in data.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in data: {missing}\")\n",
    "\n",
    "    # Commitment column aliases (some datasets use different naming)\n",
    "    def _norm_key(s: str) -> str:\n",
    "        return \" \".join(s.strip().lower().replace(\"_\", \" \").split())\n",
    "\n",
    "    col_by_key = {_norm_key(c): c for c in data.columns if isinstance(c, str)}\n",
    "\n",
    "    commit_level_col = None\n",
    "    commit_flow_col = None\n",
    "    for c in [\"Commitment_Level\", \"Commitment Level\", \"commitment level\"]:\n",
    "        key = _norm_key(c)\n",
    "        if key in col_by_key:\n",
    "            commit_level_col = col_by_key[key]\n",
    "            break\n",
    "    for c in [\"Commitment EUR\", \"Commitment\", \"commitment eur\", \"commitment\"]:\n",
    "        key = _norm_key(c)\n",
    "        if key in col_by_key:\n",
    "            commit_flow_col = col_by_key[key]\n",
    "            break\n",
    "    if commit_level_col is None and commit_flow_col is None:\n",
    "        raise ValueError(\"Missing commitment column: expected one of Commitment_Level / Commitment Level / Commitment EUR / Commitment\")\n",
    "\n",
    "    # Clean numeric\n",
    "    num_cols = [\"Adj Drawdown EUR\", \"Adj Repayment EUR\", \"NAV Adjusted EUR\", \"Recallable\", \"Fund_Age_Quarters\"]\n",
    "    if commit_level_col is not None:\n",
    "        num_cols.append(commit_level_col)\n",
    "    if commit_flow_col is not None:\n",
    "        num_cols.append(commit_flow_col)\n",
    "    for c in num_cols:\n",
    "        data[c] = pd.to_numeric(data[c], errors=\"coerce\")\n",
    "\n",
    "    data[\"Adj Drawdown EUR\"] = data[\"Adj Drawdown EUR\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"Adj Repayment EUR\"] = data[\"Adj Repayment EUR\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"Recallable\"] = data[\"Recallable\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"NAV Adjusted EUR\"] = data[\"NAV Adjusted EUR\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"Fund_Age_Quarters\"] = pd.to_numeric(data[\"Fund_Age_Quarters\"], errors=\"coerce\")\n",
    "\n",
    "    q_year = pd.to_numeric(data[\"Year of Transaction Date\"], errors=\"coerce\")\n",
    "    q_qtr = pd.to_numeric(data[\"Quarter of Transaction Date\"], errors=\"coerce\")\n",
    "    if q_year.isna().any() or q_qtr.isna().any():\n",
    "        raise ValueError(\"Year/Quarter of Transaction Date contains non-numeric values.\")\n",
    "\n",
    "    data[\"quarter_end\"] = pd.PeriodIndex(\n",
    "        q_year.astype(\"int64\").astype(str) + \"Q\" + q_qtr.astype(\"int64\").astype(str),\n",
    "        freq=\"Q\"\n",
    "    ).to_timestamp(\"Q\")\n",
    "    data = data.sort_values([\"FundID\", \"quarter_end\"]).reset_index(drop=True)\n",
    "\n",
    "    # First closing date (age baseline) if available; fallback to first observed quarter_end\n",
    "    first_close_col = None\n",
    "    for key, col in col_by_key.items():\n",
    "        if \"first closing\" in key:\n",
    "            first_close_col = col\n",
    "            break\n",
    "    if first_close_col is not None:\n",
    "        data[\"first_close_qe\"] = pd.to_datetime(data[first_close_col], errors=\"coerce\").dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    else:\n",
    "        data[\"first_close_qe\"] = pd.NaT\n",
    "    fc_map = data.groupby(\"FundID\")[\"first_close_qe\"].min()\n",
    "    fallback_fc = data.groupby(\"FundID\")[\"quarter_end\"].min()\n",
    "    fc_map = fc_map.fillna(fallback_fc)\n",
    "    data[\"first_close_qe\"] = data[\"FundID\"].map(fc_map)\n",
    "    # Age in quarters since first close (Q2 for vintage handled upstream in data prep)\n",
    "    p_qe = pd.PeriodIndex(data[\"quarter_end\"], freq=\"Q\")\n",
    "    p_fc = pd.PeriodIndex(data[\"first_close_qe\"], freq=\"Q\")\n",
    "    data[\"age_q_fc\"] = (p_qe.astype(\"int64\") - p_fc.astype(\"int64\")).astype(int)\n",
    "    data.loc[data[\"age_q_fc\"] < 0, \"age_q_fc\"] = 0\n",
    "    age_from_fund = pd.to_numeric(data[\"Fund_Age_Quarters\"], errors=\"coerce\")\n",
    "    if str(AGE_SOURCE).lower() in {\"fund_age\", \"fund_age_quarters\", \"fund\"}:\n",
    "        data[\"age_q_model\"] = age_from_fund\n",
    "        data.loc[data[\"age_q_model\"].isna(), \"age_q_model\"] = data.loc[data[\"age_q_model\"].isna(), \"age_q_fc\"]\n",
    "    else:\n",
    "        data[\"age_q_model\"] = data[\"age_q_fc\"]\n",
    "    data[\"age_q_model\"] = pd.to_numeric(data[\"age_q_model\"], errors=\"coerce\").fillna(0.0)\n",
    "    data[\"Fund_Age_Quarters\"] = data[\"Fund_Age_Quarters\"].fillna(0.0)\n",
    "\n",
    "    train_end_qe = quarter_end_from_year_quarter(train_year, train_quarter)\n",
    "    test_start_qe = add_quarters(train_end_qe, 1)\n",
    "\n",
    "    if test_year:\n",
    "        test_end_qe = quarter_end_from_year_quarter(test_year, test_quarter)\n",
    "    else:\n",
    "        test_end_qe = data[\"quarter_end\"].max()\n",
    "\n",
    "    if test_end_qe < test_start_qe:\n",
    "        raise ValueError(\"Test end is before test start. Check dates.\")\n",
    "\n",
    "    test_quarters = quarter_range(test_start_qe, test_end_qe)\n",
    "    if not test_quarters:\n",
    "        raise ValueError(\"No test quarters found. Check dates.\")\n",
    "\n",
    "    # Optional: load NAV Logic omega + nav_start for aligned NAV path\n",
    "    omega_df = None\n",
    "    navstart = None\n",
    "    omega_map = {}\n",
    "    grade_map = {}\n",
    "    age_map = {}\n",
    "    strategy_map = {}\n",
    "    msci_map_sim = {}\n",
    "    msci_stats_by_sim = {}\n",
    "    sim_ids = None\n",
    "    nav_start_by_fund = {}\n",
    "    nav_cap_by_fund = {}\n",
    "    nav_grade_by_fund = {}\n",
    "    nav_age_by_fund = {}\n",
    "    nav_strategy_by_fund = {}\n",
    "    draw_cum_hist = {}\n",
    "\n",
    "    if USE_NAV_PROJECTIONS:\n",
    "        if RUN_NAV_LOGIC_INLINE:\n",
    "            # Load MSCI (quarterly) for inline NAV Logic\n",
    "            msci_path = os.path.join(DATA_DIR, \"msci.xlsx\")\n",
    "            if not os.path.exists(msci_path):\n",
    "                msci_path = os.path.join(DATA_DIR, \"MSCI.xlsx\")\n",
    "            if not os.path.exists(msci_path):\n",
    "                raise FileNotFoundError(\"Missing msci.xlsx / MSCI.xlsx in DATA_DIR\")\n",
    "            msci_q = load_msci_quarterly(msci_path)\n",
    "            msci_q = msci_q.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "            msci_q[\"msci_ret_q_lag1\"] = msci_q[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "            # Build MSCI history + future for NAV Logic\n",
    "            start_qe = train_end_qe\n",
    "            msci_hist_inline = msci_q[msci_q[\"quarter_end\"] <= start_qe].copy()\n",
    "            last_hist_ret = msci_hist_inline[\"msci_ret_q\"].tail(1)\n",
    "            last_hist_ret_val = float(last_hist_ret.iloc[0]) if len(last_hist_ret) else 0.0\n",
    "            if NAV_LOGIC_MSCI_MODE == \"unconditional\":\n",
    "                rng_nav = np.random.default_rng(seed)\n",
    "                msci_future = simulate_msci_path(\n",
    "                    msci_q[msci_q[\"quarter_end\"] <= start_qe],\n",
    "                    start_qe=start_qe,\n",
    "                    n_quarters=len(test_quarters),\n",
    "                    scenario=scenario_uncond,\n",
    "                    tilt_strength=tilt_strength,\n",
    "                    rng=rng_nav,\n",
    "                )\n",
    "                msci_future = msci_future.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "            else:\n",
    "                msci_future = msci_q[(msci_q[\"quarter_end\"] > start_qe) &\n",
    "                                     (msci_q[\"quarter_end\"] <= test_end_qe)].copy()\n",
    "                if len(msci_future) != len(test_quarters):\n",
    "                    raise ValueError(\"MSCI history does not fully cover the backtest window.\")\n",
    "                msci_future = msci_future.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "\n",
    "            msci_future[\"msci_ret_q_lag1\"] = msci_future[\"msci_ret_q\"].shift(1)\n",
    "            if len(msci_future):\n",
    "                msci_future.loc[0, \"msci_ret_q_lag1\"] = last_hist_ret_val\n",
    "            msci_future[\"msci_ret_q_lag1\"] = msci_future[\"msci_ret_q_lag1\"].fillna(0.0)\n",
    "\n",
    "            omega_df, navstart = run_nav_logic_inline(\n",
    "                data=data,\n",
    "                msci_hist=msci_hist_inline,\n",
    "                msci_future=msci_future,\n",
    "                start_qe=start_qe,\n",
    "                data_dir=DATA_DIR,\n",
    "                alpha_level=NAV_LOGIC_ALPHA_LEVEL,\n",
    "                min_clusters_for_inference=NAV_LOGIC_MIN_CLUSTERS,\n",
    "                seed=seed,\n",
    "            )\n",
    "        else:\n",
    "            omega_path = find_omega_file(DATA_DIR, test_start_qe, test_end_qe)\n",
    "            navstart_path = find_navstart_file(DATA_DIR, train_year, train_quarter)\n",
    "            print(\"Using omega file:\", omega_path)\n",
    "            print(\"Using nav_start file:\", navstart_path)\n",
    "\n",
    "            omega_df = pd.read_parquet(omega_path) if omega_path.lower().endswith(\".parquet\") else pd.read_csv(omega_path)\n",
    "            navstart = pd.read_parquet(navstart_path) if navstart_path.lower().endswith(\".parquet\") else pd.read_csv(navstart_path)\n",
    "\n",
    "        need_omega = {\"FundID\", \"quarter_end\", \"omega\"}\n",
    "        if not need_omega.issubset(omega_df.columns):\n",
    "            raise ValueError(f\"omega_projection must contain columns: {need_omega}\")\n",
    "        need_ns = {\"FundID\", \"NAV_start\", \"cap_qe\"}\n",
    "        if not need_ns.issubset(navstart.columns):\n",
    "            raise ValueError(f\"nav_start must contain columns: {need_ns}\")\n",
    "\n",
    "        omega_df = omega_df.copy()\n",
    "        omega_df[\"quarter_end\"] = pd.to_datetime(omega_df[\"quarter_end\"]).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "        omega_df[\"omega\"] = pd.to_numeric(omega_df[\"omega\"], errors=\"coerce\").fillna(0.0)\n",
    "        if \"msci_ret_q\" in omega_df.columns:\n",
    "            omega_df[\"msci_ret_q\"] = pd.to_numeric(omega_df[\"msci_ret_q\"], errors=\"coerce\").fillna(0.0)\n",
    "        if \"Fund_Age_Quarters\" in omega_df.columns:\n",
    "            omega_df[\"Fund_Age_Quarters\"] = pd.to_numeric(omega_df[\"Fund_Age_Quarters\"], errors=\"coerce\")\n",
    "        if \"Grade\" in omega_df.columns:\n",
    "            omega_df[\"Grade\"] = omega_df[\"Grade\"].astype(str).str.strip()\n",
    "            omega_df.loc[~omega_df[\"Grade\"].isin(GRADE_STATES), \"Grade\"] = \"D\"\n",
    "        if \"sim_id\" not in omega_df.columns:\n",
    "            omega_df[\"sim_id\"] = 1\n",
    "        omega_df[\"sim_id\"] = pd.to_numeric(omega_df[\"sim_id\"], errors=\"coerce\").fillna(1).astype(int)\n",
    "\n",
    "        # require omega to fully cover the test window\n",
    "        omega_min = omega_df[\"quarter_end\"].min()\n",
    "        omega_max = omega_df[\"quarter_end\"].max()\n",
    "        if omega_min > test_start_qe or omega_max < test_end_qe:\n",
    "            raise ValueError(\n",
    "                \"omega_projection does not fully cover the test window. \"\n",
    "                f\"omega range: {omega_min.date()} to {omega_max.date()}, \"\n",
    "                f\"test window: {test_start_qe.date()} to {test_end_qe.date()}. \"\n",
    "                \"Run NAV Logic for the backtest window and re-run.\"\n",
    "            )\n",
    "\n",
    "        # restrict to test window\n",
    "        omega_df = omega_df[(omega_df[\"quarter_end\"] >= test_start_qe) &\n",
    "                            (omega_df[\"quarter_end\"] <= test_end_qe)].copy()\n",
    "\n",
    "        # ensure omega has every quarter in the test window\n",
    "        omega_quarters = set(omega_df[\"quarter_end\"].unique())\n",
    "        missing_q = [qe for qe in test_quarters if qe not in omega_quarters]\n",
    "        if missing_q:\n",
    "            miss = \", \".join([d.strftime(\"%Y-%m-%d\") for d in missing_q[:8]])\n",
    "            extra = \"\" if len(missing_q) <= 8 else f\" (+{len(missing_q) - 8} more)\"\n",
    "            raise ValueError(\n",
    "                \"omega_projection is missing quarters inside the test window: \"\n",
    "                f\"{miss}{extra}. Align omega projection or adjust test dates.\"\n",
    "            )\n",
    "\n",
    "        sim_ids = sorted(omega_df[\"sim_id\"].unique().tolist())\n",
    "\n",
    "        navstart = navstart.copy()\n",
    "        navstart[\"NAV_start\"] = pd.to_numeric(navstart[\"NAV_start\"], errors=\"coerce\").fillna(0.0).clip(lower=0.0)\n",
    "        navstart[\"cap_qe\"] = pd.to_datetime(navstart[\"cap_qe\"], errors=\"coerce\")\n",
    "\n",
    "        nav_start_by_fund = navstart.set_index(\"FundID\")[\"NAV_start\"].to_dict()\n",
    "        nav_cap_by_fund = navstart.set_index(\"FundID\")[\"cap_qe\"].to_dict()\n",
    "        if \"Grade\" in navstart.columns:\n",
    "            nav_grade_by_fund = navstart.set_index(\"FundID\")[\"Grade\"].astype(str).to_dict()\n",
    "        if \"Fund_Age_Quarters\" in navstart.columns:\n",
    "            nav_age_by_fund = pd.to_numeric(navstart.set_index(\"FundID\")[\"Fund_Age_Quarters\"], errors=\"coerce\").to_dict()\n",
    "        if \"Adj Strategy\" in navstart.columns:\n",
    "            nav_strategy_by_fund = navstart.set_index(\"FundID\")[\"Adj Strategy\"].astype(str).to_dict()\n",
    "\n",
    "        for sim_id, g in omega_df.groupby(\"sim_id\"):\n",
    "            key = list(zip(g[\"FundID\"], g[\"quarter_end\"]))\n",
    "            omega_map[sim_id] = dict(zip(key, g[\"omega\"]))\n",
    "            if \"Adj Strategy\" in g.columns:\n",
    "                strategy_map[sim_id] = dict(zip(key, g[\"Adj Strategy\"].astype(str)))\n",
    "            if \"Grade\" in g.columns:\n",
    "                grade_map[sim_id] = dict(zip(key, g[\"Grade\"]))\n",
    "            if \"Fund_Age_Quarters\" in g.columns:\n",
    "                age_map[sim_id] = dict(zip(key, g[\"Fund_Age_Quarters\"]))\n",
    "            if \"msci_ret_q\" in g.columns:\n",
    "                msci_map_sim[sim_id] = dict(zip(g[\"quarter_end\"], g[\"msci_ret_q\"]))\n",
    "\n",
    "        if \"msci_ret_q\" in omega_df.columns:\n",
    "            msci_stats_by_sim = omega_df.groupby(\"sim_id\")[\"msci_ret_q\"].agg([\"mean\", \"std\"]).to_dict(\"index\")\n",
    "\n",
    "        # historical drawdowns up to first projection quarter (for DD_cum_commit init)\n",
    "        draw_cum_hist = (data[data[\"quarter_end\"] <= test_start_qe]\n",
    "                         .groupby(\"FundID\")[\"Adj Drawdown EUR\"].sum()\n",
    "                         .to_dict())\n",
    "\n",
    "    if USE_NAV_PROJECTIONS and not draw_cum_hist:\n",
    "        draw_cum_hist = (data[data[\"quarter_end\"] <= test_start_qe]\n",
    "                         .groupby(\"FundID\")[\"Adj Drawdown EUR\"].sum()\n",
    "                         .to_dict())\n",
    "\n",
    "    # MSCI data (load if not already loaded for inline NAV Logic)\n",
    "    if \"msci_q\" not in locals():\n",
    "        msci_path = os.path.join(DATA_DIR, \"msci.xlsx\")\n",
    "        if not os.path.exists(msci_path):\n",
    "            msci_path = os.path.join(DATA_DIR, \"MSCI.xlsx\")\n",
    "        if not os.path.exists(msci_path):\n",
    "            raise FileNotFoundError(\"Missing msci.xlsx / MSCI.xlsx in DATA_DIR\")\n",
    "\n",
    "        msci_q = load_msci_quarterly(msci_path)\n",
    "        msci_q = msci_q.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "        msci_q[\"msci_ret_q_lag1\"] = msci_q[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "    # Train/test splits (initial)\n",
    "    train = data[data[\"quarter_end\"] <= train_end_qe].copy()\n",
    "    test = data[data[\"quarter_end\"] >= test_start_qe].copy()\n",
    "\n",
    "    if train.empty or test.empty:\n",
    "        raise ValueError(\"Train or test split is empty. Adjust dates.\")\n",
    "\n",
    "    # Commitment proxy (full history)\n",
    "    if commit_level_col is not None:\n",
    "        data[\"Commitment_Level\"] = data[commit_level_col].fillna(0.0)\n",
    "    else:\n",
    "        data[\"Commitment_Level\"] = data.groupby(\"FundID\")[commit_flow_col].cumsum().fillna(0.0)\n",
    "    fund_commit = data.groupby(\"FundID\")[\"Commitment_Level\"].max().fillna(0.0).to_dict()\n",
    "    # Refresh train/test to include Commitment_Level\n",
    "    train = data[data[\"quarter_end\"] <= train_end_qe].copy()\n",
    "    test = data[data[\"quarter_end\"] >= test_start_qe].copy()\n",
    "    if train.empty or test.empty:\n",
    "        raise ValueError(\"Train or test split is empty after commitment prep. Adjust dates.\")\n",
    "\n",
    "    # Funds in test window\n",
    "    test_funds = test[\"FundID\"].unique().tolist()\n",
    "    if USE_NAV_PROJECTIONS:\n",
    "        nav_funds = set(nav_start_by_fund.keys())\n",
    "        omega_funds = set(omega_df[\"FundID\"].unique()) if omega_df is not None else set()\n",
    "        test_funds = [fid for fid in test_funds if fid in nav_funds and fid in omega_funds]\n",
    "        if not test_funds:\n",
    "            raise ValueError(\"No overlap between test funds and NAV Logic projection inputs.\")\n",
    "        if sim_ids:\n",
    "            if len(sim_ids) > 1:\n",
    "                n_sims = len(sim_ids)\n",
    "                print(f\"Using {n_sims} NAV Logic sim_id(s) from omega projections.\")\n",
    "            else:\n",
    "                print(f\"Using single NAV Logic omega path; cashflow sims = {n_sims}.\")\n",
    "\n",
    "    # Planned end date (cap)\n",
    "    data[\"planned_end_qe\"] = pd.to_datetime(\n",
    "        data[\"Planned end date with add. years as per legal doc\"],\n",
    "        errors=\"coerce\"\n",
    "    ).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "\n",
    "    cap_by_fund = (data.dropna(subset=[\"planned_end_qe\"])\n",
    "                   .sort_values([\"FundID\", \"planned_end_qe\"])\n",
    "                   .groupby(\"FundID\")[\"planned_end_qe\"].last().to_dict())\n",
    "    if USE_NAV_PROJECTIONS and nav_cap_by_fund:\n",
    "        for fid, cap in nav_cap_by_fund.items():\n",
    "            if pd.notna(cap):\n",
    "                cap_by_fund[fid] = cap\n",
    "\n",
    "    # Age buckets\n",
    "    data[\"AgeBucket\"] = pd.cut(data[\"age_q_model\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "    if \"AgeBucket\" not in train.columns:\n",
    "        train[\"AgeBucket\"] = pd.cut(train[\"age_q_model\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "    if \"AgeBucket\" not in test.columns:\n",
    "        test[\"AgeBucket\"] = pd.cut(test[\"age_q_model\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "\n",
    "    # Calibration bucketing (optionally collapse age buckets)\n",
    "    if CALIBRATION_BUCKET_MODE == \"strategy_grade\":\n",
    "        train[\"AgeBucketCalib\"] = \"ALL\"\n",
    "    else:\n",
    "        train[\"AgeBucketCalib\"] = train[\"AgeBucket\"].astype(str)\n",
    "\n",
    "    # Build MSCI lookup for conditional path\n",
    "    msci_map = msci_q.set_index(\"quarter_end\")[\"msci_ret_q\"].to_dict()\n",
    "    msci_lag_map = msci_q.set_index(\"quarter_end\")[\"msci_ret_q_lag1\"].to_dict()\n",
    "    msci_hist = msci_q[msci_q[\"quarter_end\"] <= train_end_qe].copy()\n",
    "    msci_mu_all = float(msci_hist[\"msci_ret_q\"].mean()) if len(msci_hist) else 0.0\n",
    "    msci_sigma_all = float(msci_hist[\"msci_ret_q\"].std(ddof=1)) if len(msci_hist) > 1 else 1.0\n",
    "    msci_sigma_all = max(msci_sigma_all, 1e-6)\n",
    "\n",
    "    # Ensure MSCI covers test quarters for conditional\n",
    "    for qe in test_quarters:\n",
    "        if qe not in msci_map:\n",
    "            raise ValueError(f\"Missing MSCI return for quarter {qe} in MSCI file.\")\n",
    "\n",
    "    # =============================\n",
    "    # Calibrate omega model on train\n",
    "    # =============================\n",
    "    train = train.copy()\n",
    "    train[\"nav_prev\"] = train.groupby(\"FundID\")[\"NAV Adjusted EUR\"].shift(1)\n",
    "    train[\"flow_net\"] = train[\"Adj Drawdown EUR\"] - train[\"Adj Repayment EUR\"]\n",
    "    m = train[\"nav_prev\"].fillna(0.0) > 0\n",
    "    train[\"omega\"] = np.nan\n",
    "    train.loc[m, \"omega\"] = ((train.loc[m, \"NAV Adjusted EUR\"] - train.loc[m, \"nav_prev\"]) - train.loc[m, \"flow_net\"]) / train.loc[m, \"nav_prev\"]\n",
    "    train[\"omega\"] = train[\"omega\"].clip(lower=-OMEGA_CLIP, upper=OMEGA_CLIP)\n",
    "\n",
    "    # attach MSCI to train\n",
    "    train[\"msci_ret_q\"] = train[\"quarter_end\"].map(msci_map)\n",
    "    train[\"msci_ret_q_lag1\"] = train[\"quarter_end\"].map(msci_lag_map)\n",
    "\n",
    "    cal = train.dropna(subset=[\"omega\", \"msci_ret_q\", \"msci_ret_q_lag1\"]).copy()\n",
    "    cal[\"AgeBucket\"] = cal[\"AgeBucket\"].astype(str)\n",
    "    if cal.empty:\n",
    "        raise ValueError(\"No omega calibration data after filtering.\")\n",
    "\n",
    "    get_betas, get_alpha, get_sigma = build_omega_models(cal)\n",
    "\n",
    "    # =============================\n",
    "    # Calibrate cashflow model on train\n",
    "    # =============================\n",
    "    # investment period calibration by strategy\n",
    "    ip_by_strategy = {}\n",
    "    df_ip = train[(train[\"Adj Drawdown EUR\"] > 0) & train[\"Adj Strategy\"].notna() & train[\"age_q_model\"].notna()].copy()\n",
    "    if len(df_ip):\n",
    "        df_ip[\"age_q\"] = pd.to_numeric(df_ip[\"age_q_model\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "        df_ip = df_ip[df_ip[\"age_q\"].notna() & (df_ip[\"age_q\"] >= 0)]\n",
    "        for strat, g in df_ip.groupby(\"Adj Strategy\", dropna=False):\n",
    "            s = g.groupby(\"age_q\")[\"Adj Drawdown EUR\"].sum().sort_index()\n",
    "            total = float(s.sum())\n",
    "            if total <= 0:\n",
    "                continue\n",
    "            cum = s.cumsum()\n",
    "            thr = IP_CUM_PCTL * total\n",
    "            ip_q = int(cum.index[cum.values >= thr][0])\n",
    "            ip_q = int(np.clip(ip_q, IP_Q_MIN, IP_Q_MAX))\n",
    "            ip_by_strategy[strat] = ip_q\n",
    "\n",
    "    # hazard dataset\n",
    "    haz = train.copy()\n",
    "    haz[\"age_q\"] = pd.to_numeric(haz[\"age_q_model\"], errors=\"coerce\").round()\n",
    "    haz = haz[haz[\"age_q\"].notna()].copy()\n",
    "    haz[\"age_q\"] = haz[\"age_q\"].astype(int)\n",
    "    haz[\"log_nav_prev\"] = np.log1p(haz[\"nav_prev\"].abs().fillna(0.0))\n",
    "    haz[\"ip_q\"] = haz[\"Adj Strategy\"].map(ip_by_strategy).fillna(IP_Q_DEFAULT).astype(int)\n",
    "    draw_haz = haz.copy()\n",
    "    if ENFORCE_IP_LIMITS:\n",
    "        draw_haz = haz[haz[\"age_q\"] <= haz[\"ip_q\"]].copy()\n",
    "\n",
    "    X_draw = build_feature_matrix(draw_haz, include_nav=False)\n",
    "    X_rep = build_feature_matrix(haz, include_nav=True)\n",
    "\n",
    "    cont_draw = [\"age_q\", \"age_q2\"]\n",
    "    cont_rep = [\"age_q\", \"age_q2\", \"log_nav_prev\"]\n",
    "\n",
    "    X_draw, draw_means, draw_stds = standardize_X(X_draw, cont_draw)\n",
    "    X_rep, rep_means, rep_stds = standardize_X(X_rep, cont_rep)\n",
    "\n",
    "    Y_draw = (draw_haz[\"Adj Drawdown EUR\"] > 0).astype(int).to_numpy(dtype=float)\n",
    "    Y_rep = (haz[\"Adj Repayment EUR\"] > 0).astype(int).to_numpy(dtype=float)\n",
    "\n",
    "    beta_draw = None\n",
    "    beta_rep = None\n",
    "    try:\n",
    "        if USE_HAZARD_MODELS and len(X_draw) and len(Y_draw):\n",
    "            beta_draw = fit_logit(X_draw.to_numpy(), Y_draw)\n",
    "        if USE_HAZARD_MODELS and len(X_rep) and len(Y_rep):\n",
    "            beta_rep = fit_logit(X_rep.to_numpy(), Y_rep)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: hazard model fit failed, falling back to group means:\", e)\n",
    "        beta_draw = None\n",
    "        beta_rep = None\n",
    "\n",
    "    hazard_meta = {\n",
    "        \"draw_cols\": list(X_draw.columns),\n",
    "        \"rep_cols\": list(X_rep.columns),\n",
    "        \"draw_means\": draw_means, \"draw_stds\": draw_stds,\n",
    "        \"rep_means\": rep_means, \"rep_stds\": rep_stds,\n",
    "    }\n",
    "\n",
    "    # cap proxy for draw ratios\n",
    "    if \"Commitment_Level\" not in train.columns:\n",
    "        if commit_level_col is not None and commit_level_col in train.columns:\n",
    "            train[\"Commitment_Level\"] = train[commit_level_col].fillna(0.0)\n",
    "        elif commit_flow_col is not None and commit_flow_col in train.columns:\n",
    "            train[\"Commitment_Level\"] = train.groupby(\"FundID\")[commit_flow_col].cumsum().fillna(0.0)\n",
    "        else:\n",
    "            raise ValueError(\"Commitment_Level missing in train and no usable commitment column found.\")\n",
    "    cap_proxy_col = \"Capacity\" if \"Capacity\" in train.columns else None\n",
    "    if cap_proxy_col is None:\n",
    "        print(\"WARNING: data has no 'Capacity' column; draw calibration uses Commitment_Level proxy.\")\n",
    "    train[\"cap_proxy\"] = pd.to_numeric(train[cap_proxy_col], errors=\"coerce\").fillna(0.0) if cap_proxy_col else train[\"Commitment_Level\"].fillna(0.0)\n",
    "    train[\"draw_event\"] = (train[\"Adj Drawdown EUR\"] > 0).astype(int)\n",
    "    train[\"rep_event\"] = (train[\"Adj Repayment EUR\"] > 0).astype(int)\n",
    "\n",
    "    train[\"draw_ratio\"] = np.where(train[\"cap_proxy\"] > CAP_EPS, train[\"Adj Drawdown EUR\"] / train[\"cap_proxy\"], np.nan)\n",
    "    train.loc[train[\"draw_ratio\"] <= 0, \"draw_ratio\"] = np.nan\n",
    "\n",
    "    train[\"rep_ratio\"] = np.where(train[\"nav_prev\"].abs() > NAV_EPS, train[\"Adj Repayment EUR\"] / train[\"nav_prev\"].abs(), np.nan)\n",
    "    train.loc[train[\"rep_ratio\"] <= 0, \"rep_ratio\"] = np.nan\n",
    "\n",
    "    train[\"rc_given_rep_event\"] = ((train[\"Adj Repayment EUR\"] > 0) & (train[\"Recallable\"] > 0)).astype(int)\n",
    "    train[\"rc_ratio_given_rep\"] = np.where(train[\"Adj Repayment EUR\"] > 0, train[\"Recallable\"] / train[\"Adj Repayment EUR\"], np.nan)\n",
    "    train.loc[train[\"rc_ratio_given_rep\"] <= 0, \"rc_ratio_given_rep\"] = np.nan\n",
    "\n",
    "    # Calibration tables\n",
    "    group_keys = [\"Adj Strategy\", \"Grade\", \"AgeBucketCalib\"]\n",
    "    rows = []\n",
    "    for (s, g, a), grp in train.groupby(group_keys, dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows.append({\n",
    "            \"Adj Strategy\": s, \"Grade\": g, \"AgeBucket\": a,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal = pd.DataFrame(rows)\n",
    "\n",
    "    # strategy fallback\n",
    "    rows_s = []\n",
    "    for s, grp in train.groupby([\"Adj Strategy\"], dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows_s.append({\n",
    "            \"Adj Strategy\": s,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal_s = pd.DataFrame(rows_s)\n",
    "\n",
    "    # strategy + grade fallback\n",
    "    rows_sg = []\n",
    "    for (s, g), grp in train.groupby([\"Adj Strategy\", \"Grade\"], dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows_sg.append({\n",
    "            \"Adj Strategy\": s, \"Grade\": g,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal_sg = pd.DataFrame(rows_sg)\n",
    "\n",
    "    # strategy + age fallback\n",
    "    rows_sa = []\n",
    "    for (s, a), grp in train.groupby([\"Adj Strategy\", \"AgeBucketCalib\"], dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows_sa.append({\n",
    "            \"Adj Strategy\": s, \"AgeBucket\": a,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal_sa = pd.DataFrame(rows_sa)\n",
    "\n",
    "    global_p_draw = float(train[\"draw_event\"].mean())\n",
    "    global_p_rep = float(train[\"rep_event\"].mean())\n",
    "    rep_all = train[train[\"Adj Repayment EUR\"] > 0]\n",
    "    global_p_rc_given_rep = float(rep_all[\"rc_given_rep_event\"].mean()) if len(rep_all) else 0.0\n",
    "\n",
    "    stats_g_draw = fit_lognormal_stats(train[\"draw_ratio\"], train[\"FundID\"])\n",
    "    stats_g_rep = fit_lognormal_stats(train[\"rep_ratio\"], train[\"FundID\"])\n",
    "    stats_g_rc = fit_lognormal_stats(rep_all[\"rc_ratio_given_rep\"], rep_all[\"FundID\"]) if len(rep_all) else {\n",
    "        \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "    }\n",
    "\n",
    "    def lookup_params(strategy, grade, age_bucket) -> Dict[str, float]:\n",
    "        age_bucket_calib = \"ALL\" if CALIBRATION_BUCKET_MODE == \"strategy_grade\" else age_bucket\n",
    "        m = (cal[\"Adj Strategy\"].eq(strategy)) & (cal[\"Grade\"].eq(grade)) & (cal[\"AgeBucket\"].eq(age_bucket_calib))\n",
    "        child = cal[m].iloc[0].to_dict() if m.any() else {}\n",
    "\n",
    "        ss = cal_s[cal_s[\"Adj Strategy\"].eq(strategy)]\n",
    "        parent_s = ss.iloc[0].to_dict() if len(ss) else {}\n",
    "\n",
    "        ssg = cal_sg[(cal_sg[\"Adj Strategy\"].eq(strategy)) & (cal_sg[\"Grade\"].eq(grade))]\n",
    "        parent_sg = ssg.iloc[0].to_dict() if len(ssg) else {}\n",
    "\n",
    "        ssa = cal_sa[(cal_sa[\"Adj Strategy\"].eq(strategy)) & (cal_sa[\"AgeBucket\"].eq(age_bucket_calib))]\n",
    "        parent_sa = ssa.iloc[0].to_dict() if len(ssa) else {}\n",
    "\n",
    "        p_s = float(np.clip(parent_s.get(\"p_draw\", global_p_draw), 0.0, 1.0))\n",
    "        p_sg = float(np.clip(parent_sg.get(\"p_draw\", p_s), 0.0, 1.0))\n",
    "        p_sa = float(np.clip(parent_sa.get(\"p_draw\", p_s), 0.0, 1.0))\n",
    "        p_draw_parent = _combine_p(p_sg, parent_sg.get(\"n_obs\", 0), parent_sg.get(\"n_funds\", 0),\n",
    "                                   p_sa, parent_sa.get(\"n_obs\", 0), parent_sa.get(\"n_funds\", 0), p_s)\n",
    "        p_draw = _blend_p(child.get(\"p_draw\", p_draw_parent), child.get(\"n_obs\", 0), child.get(\"n_funds\", 0), p_draw_parent)\n",
    "\n",
    "        p_s = float(np.clip(parent_s.get(\"p_rep\", global_p_rep), 0.0, 1.0))\n",
    "        p_sg = float(np.clip(parent_sg.get(\"p_rep\", p_s), 0.0, 1.0))\n",
    "        p_sa = float(np.clip(parent_sa.get(\"p_rep\", p_s), 0.0, 1.0))\n",
    "        p_rep_parent = _combine_p(p_sg, parent_sg.get(\"n_obs\", 0), parent_sg.get(\"n_funds\", 0),\n",
    "                                  p_sa, parent_sa.get(\"n_obs\", 0), parent_sa.get(\"n_funds\", 0), p_s)\n",
    "        p_rep = _blend_p(child.get(\"p_rep\", p_rep_parent), child.get(\"n_obs\", 0), child.get(\"n_funds\", 0), p_rep_parent)\n",
    "\n",
    "        p_s = float(np.clip(parent_s.get(\"p_rc_given_rep\", global_p_rc_given_rep), 0.0, 1.0))\n",
    "        p_sg = float(np.clip(parent_sg.get(\"p_rc_given_rep\", p_s), 0.0, 1.0))\n",
    "        p_sa = float(np.clip(parent_sa.get(\"p_rc_given_rep\", p_s), 0.0, 1.0))\n",
    "        p_rc_parent = _combine_p(p_sg, parent_sg.get(\"n_rep\", 0), parent_sg.get(\"n_funds_rep\", 0),\n",
    "                                 p_sa, parent_sa.get(\"n_rep\", 0), parent_sa.get(\"n_funds_rep\", 0), p_s)\n",
    "        p_rc = _blend_p(child.get(\"p_rc_given_rep\", p_rc_parent), child.get(\"n_rep\", 0), child.get(\"n_funds_rep\", 0), p_rc_parent)\n",
    "\n",
    "        mu_draw_s, sig_draw_s = _blend(\n",
    "            parent_s.get(\"mu_draw\", stats_g_draw[\"mu\"]), parent_s.get(\"sig_draw\", stats_g_draw[\"sig\"]),\n",
    "            parent_s.get(\"n_draw\", 0), parent_s.get(\"n_funds_draw\", 0), parent_s.get(\"ks_pass_draw\", False),\n",
    "            stats_g_draw[\"mu\"], stats_g_draw[\"sig\"], stats_g_draw[\"n\"], stats_g_draw[\"n_funds\"], stats_g_draw[\"ks_pass\"]\n",
    "        )\n",
    "        mu_rep_s, sig_rep_s = _blend(\n",
    "            parent_s.get(\"mu_rep\", stats_g_rep[\"mu\"]), parent_s.get(\"sig_rep\", stats_g_rep[\"sig\"]),\n",
    "            parent_s.get(\"n_rep\", 0), parent_s.get(\"n_funds_rep\", 0), parent_s.get(\"ks_pass_rep\", False),\n",
    "            stats_g_rep[\"mu\"], stats_g_rep[\"sig\"], stats_g_rep[\"n\"], stats_g_rep[\"n_funds\"], stats_g_rep[\"ks_pass\"]\n",
    "        )\n",
    "        mu_rc_s, sig_rc_s = _blend(\n",
    "            parent_s.get(\"mu_rc\", stats_g_rc[\"mu\"]), parent_s.get(\"sig_rc\", stats_g_rc[\"sig\"]),\n",
    "            parent_s.get(\"n_rc\", 0), parent_s.get(\"n_funds_rc\", 0), parent_s.get(\"ks_pass_rc\", False),\n",
    "            stats_g_rc[\"mu\"], stats_g_rc[\"sig\"], stats_g_rc[\"n\"], stats_g_rc[\"n_funds\"], stats_g_rc[\"ks_pass\"]\n",
    "        )\n",
    "\n",
    "        mu_draw_sg, sig_draw_sg = _blend(\n",
    "            parent_sg.get(\"mu_draw\", mu_draw_s), parent_sg.get(\"sig_draw\", sig_draw_s),\n",
    "            parent_sg.get(\"n_draw\", 0), parent_sg.get(\"n_funds_draw\", 0), parent_sg.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_s, sig_draw_s, parent_s.get(\"n_draw\", 0), parent_s.get(\"n_funds_draw\", 0), parent_s.get(\"ks_pass_draw\", False)\n",
    "        )\n",
    "        mu_rep_sg, sig_rep_sg = _blend(\n",
    "            parent_sg.get(\"mu_rep\", mu_rep_s), parent_sg.get(\"sig_rep\", sig_rep_s),\n",
    "            parent_sg.get(\"n_rep\", 0), parent_sg.get(\"n_funds_rep\", 0), parent_sg.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_s, sig_rep_s, parent_s.get(\"n_rep\", 0), parent_s.get(\"n_funds_rep\", 0), parent_s.get(\"ks_pass_rep\", False)\n",
    "        )\n",
    "        mu_rc_sg, sig_rc_sg = _blend(\n",
    "            parent_sg.get(\"mu_rc\", mu_rc_s), parent_sg.get(\"sig_rc\", sig_rc_s),\n",
    "            parent_sg.get(\"n_rc\", 0), parent_sg.get(\"n_funds_rc\", 0), parent_sg.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_s, sig_rc_s, parent_s.get(\"n_rc\", 0), parent_s.get(\"n_funds_rc\", 0), parent_s.get(\"ks_pass_rc\", False)\n",
    "        )\n",
    "\n",
    "        mu_draw_sa, sig_draw_sa = _blend(\n",
    "            parent_sa.get(\"mu_draw\", mu_draw_s), parent_sa.get(\"sig_draw\", sig_draw_s),\n",
    "            parent_sa.get(\"n_draw\", 0), parent_sa.get(\"n_funds_draw\", 0), parent_sa.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_s, sig_draw_s, parent_s.get(\"n_draw\", 0), parent_s.get(\"n_funds_draw\", 0), parent_s.get(\"ks_pass_draw\", False)\n",
    "        )\n",
    "        mu_rep_sa, sig_rep_sa = _blend(\n",
    "            parent_sa.get(\"mu_rep\", mu_rep_s), parent_sa.get(\"sig_rep\", sig_rep_s),\n",
    "            parent_sa.get(\"n_rep\", 0), parent_sa.get(\"n_funds_rep\", 0), parent_sa.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_s, sig_rep_s, parent_s.get(\"n_rep\", 0), parent_s.get(\"n_funds_rep\", 0), parent_s.get(\"ks_pass_rep\", False)\n",
    "        )\n",
    "        mu_rc_sa, sig_rc_sa = _blend(\n",
    "            parent_sa.get(\"mu_rc\", mu_rc_s), parent_sa.get(\"sig_rc\", sig_rc_s),\n",
    "            parent_sa.get(\"n_rc\", 0), parent_sa.get(\"n_funds_rc\", 0), parent_sa.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_s, sig_rc_s, parent_s.get(\"n_rc\", 0), parent_s.get(\"n_funds_rc\", 0), parent_s.get(\"ks_pass_rc\", False)\n",
    "        )\n",
    "\n",
    "        mu_draw_p, sig_draw_p = _combine_mu_sig(\n",
    "            mu_draw_sg, sig_draw_sg, parent_sg.get(\"n_draw\", 0), parent_sg.get(\"n_funds_draw\", 0), parent_sg.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_sa, sig_draw_sa, parent_sa.get(\"n_draw\", 0), parent_sa.get(\"n_funds_draw\", 0), parent_sa.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_s, sig_draw_s\n",
    "        )\n",
    "        mu_rep_p, sig_rep_p = _combine_mu_sig(\n",
    "            mu_rep_sg, sig_rep_sg, parent_sg.get(\"n_rep\", 0), parent_sg.get(\"n_funds_rep\", 0), parent_sg.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_sa, sig_rep_sa, parent_sa.get(\"n_rep\", 0), parent_sa.get(\"n_funds_rep\", 0), parent_sa.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_s, sig_rep_s\n",
    "        )\n",
    "        mu_rc_p, sig_rc_p = _combine_mu_sig(\n",
    "            mu_rc_sg, sig_rc_sg, parent_sg.get(\"n_rc\", 0), parent_sg.get(\"n_funds_rc\", 0), parent_sg.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_sa, sig_rc_sa, parent_sa.get(\"n_rc\", 0), parent_sa.get(\"n_funds_rc\", 0), parent_sa.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_s, sig_rc_s\n",
    "        )\n",
    "\n",
    "        mu_draw, sig_draw = _blend(\n",
    "            child.get(\"mu_draw\", mu_draw_p), child.get(\"sig_draw\", sig_draw_p),\n",
    "            child.get(\"n_draw\", 0), child.get(\"n_funds_draw\", 0), child.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_p, sig_draw_p, 0, 0, True\n",
    "        )\n",
    "        mu_rep, sig_rep = _blend(\n",
    "            child.get(\"mu_rep\", mu_rep_p), child.get(\"sig_rep\", sig_rep_p),\n",
    "            child.get(\"n_rep\", 0), child.get(\"n_funds_rep\", 0), child.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_p, sig_rep_p, 0, 0, True\n",
    "        )\n",
    "        mu_rc, sig_rc = _blend(\n",
    "            child.get(\"mu_rc\", mu_rc_p), child.get(\"sig_rc\", sig_rc_p),\n",
    "            child.get(\"n_rc\", 0), child.get(\"n_funds_rc\", 0), child.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_p, sig_rc_p, 0, 0, True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"p_draw\": p_draw,\n",
    "            \"p_rep\": p_rep,\n",
    "            \"p_rc_given_rep\": p_rc,\n",
    "            \"mu_draw\": float(mu_draw), \"sig_draw\": float(sig_draw),\n",
    "            \"mu_rep\": float(mu_rep), \"sig_rep\": float(sig_rep),\n",
    "            \"mu_rc\": float(mu_rc), \"sig_rc\": float(sig_rc),\n",
    "        }\n",
    "\n",
    "    # =============================\n",
    "    # Drawdown scaling calibration (censored funds, by strategy+grade)\n",
    "    # =============================\n",
    "    draw_scale_sg = {}\n",
    "    draw_scale_s = {}\n",
    "    draw_scale_g = 1.0\n",
    "\n",
    "    def build_cum_draw_obs(df: pd.DataFrame, fund_commit: dict) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for fid, g in df.groupby(\"FundID\"):\n",
    "            C = float(fund_commit.get(fid, 0.0) or 0.0)\n",
    "            if not np.isfinite(C) or C <= 0:\n",
    "                continue\n",
    "            g2 = g.sort_values(\"age_q_fc\")\n",
    "            g2 = (g2.groupby(\"age_q_fc\", as_index=False)\n",
    "                    .agg(draw=(\"Adj Drawdown EUR\", \"sum\"),\n",
    "                         **{\"Adj Strategy\": (\"Adj Strategy\", \"last\"),\n",
    "                            \"Grade\": (\"Grade\", \"last\")}))\n",
    "            g2[\"cum_draw\"] = g2[\"draw\"].cumsum()\n",
    "            g2[\"ratio\"] = g2[\"cum_draw\"] / C\n",
    "            g2[\"Adj Strategy\"] = g2[\"Adj Strategy\"].fillna(\"Unknown\")\n",
    "            g2[\"Grade\"] = g2[\"Grade\"].fillna(\"D\").astype(str).str.strip()\n",
    "            g2[\"FundID\"] = fid\n",
    "            rows.append(g2[[\"FundID\", \"Adj Strategy\", \"Grade\", \"age_q_fc\", \"ratio\"]])\n",
    "        if not rows:\n",
    "            return pd.DataFrame(columns=[\"FundID\", \"Adj Strategy\", \"Grade\", \"age_q_fc\", \"ratio\"])\n",
    "        return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    def expected_draw_increment(strategy: str, grade: str, age_q: int) -> float:\n",
    "        age_bucket = make_age_bucket_q(age_q)\n",
    "        ip_q = int(ip_by_strategy.get(strategy, IP_Q_DEFAULT))\n",
    "        draw_mult = 1.0\n",
    "        if USE_DRAW_AGE_SHAPE and ip_q > 0:\n",
    "            if ENFORCE_IP_LIMITS and age_q > ip_q:\n",
    "                draw_mult = 0.0\n",
    "            else:\n",
    "                frac = float(age_q) / float(ip_q)\n",
    "                draw_mult = max(DRAW_AGE_MIN_MULT, (1.0 - frac) ** DRAW_AGE_DECAY_POWER)\n",
    "\n",
    "        params = lookup_params(strategy, grade, age_bucket)\n",
    "        if USE_HAZARD_MODELS and beta_draw is not None:\n",
    "            Xr = build_feature_row(strategy, grade, age_q, 0.0, False,\n",
    "                                   hazard_meta[\"draw_cols\"], hazard_meta[\"draw_means\"], hazard_meta[\"draw_stds\"])\n",
    "            p_draw_base = float(_sigmoid(Xr @ beta_draw)[0])\n",
    "        else:\n",
    "            p_draw_base = float(params.get(\"p_draw\", 0.0))\n",
    "\n",
    "        grade_key = grade if grade in GRADE_DRAW_P_MULT else \"D\"\n",
    "        p_draw_adj = p_draw_base * draw_mult * float(GRADE_DRAW_P_MULT.get(grade_key, 1.0))\n",
    "        p_draw_adj = min(p_draw_adj, 1.0)\n",
    "\n",
    "        mu = float(params.get(\"mu_draw\", 0.0))\n",
    "        sig = float(params.get(\"sig_draw\", SIGMA_FLOOR))\n",
    "        mean_ratio = float(np.exp(mu + 0.5 * sig * sig))\n",
    "        mean_ratio = min(mean_ratio * float(GRADE_DRAW_SIZE_MULT.get(grade_key, 1.0)), 1.0)\n",
    "        return float(p_draw_adj * mean_ratio)\n",
    "\n",
    "    def baseline_curve(strategy: str, grade: str, ages: List[int]) -> np.ndarray:\n",
    "        ages_sorted = sorted(set(int(a) for a in ages))\n",
    "        out = []\n",
    "        cum = 0.0\n",
    "        for a in ages_sorted:\n",
    "            cum += expected_draw_increment(strategy, grade, a)\n",
    "            out.append(cum)\n",
    "        return np.array(out, dtype=float), ages_sorted\n",
    "\n",
    "    def fit_scale_for_group(grp: pd.DataFrame, target_col: str) -> Tuple[float, float]:\n",
    "        ages = grp[\"age_q_fc\"].astype(int).tolist()\n",
    "        base, ages_sorted = baseline_curve(grp[\"Adj Strategy\"].iloc[0], grp[\"Grade\"].iloc[0], ages)\n",
    "        g2 = grp.set_index(\"age_q_fc\").loc[ages_sorted]\n",
    "        target = g2[target_col].to_numpy(dtype=float)\n",
    "        weights = g2[\"n_funds\"].to_numpy(dtype=float)\n",
    "        denom = float(np.sum(weights * base * base))\n",
    "        if denom <= 0:\n",
    "            return 1.0, float(\"inf\")\n",
    "        scale_raw = float(np.sum(weights * target * base) / denom)\n",
    "        n_funds = float(g2[\"n_funds\"].max())\n",
    "        w_shrink = n_funds / (n_funds + SHRINK_FUNDS)\n",
    "        scale = 1.0 + w_shrink * (scale_raw - 1.0)\n",
    "        sse = float(np.sum(weights * (scale * base - target) ** 2))\n",
    "        return max(scale, 0.0), sse\n",
    "\n",
    "    if USE_DRAWDOWN_CALIBRATION:\n",
    "        obs = build_cum_draw_obs(train, fund_commit)\n",
    "        if len(obs):\n",
    "            curves_sg = (obs.groupby([\"Adj Strategy\", \"Grade\", \"age_q_fc\"])\n",
    "                            .agg(mean_ratio=(\"ratio\", \"mean\"),\n",
    "                                 median_ratio=(\"ratio\", \"median\"),\n",
    "                                 n_funds=(\"FundID\", \"nunique\"))\n",
    "                            .reset_index())\n",
    "            curves_s = (obs.groupby([\"Adj Strategy\", \"age_q_fc\"])\n",
    "                           .agg(mean_ratio=(\"ratio\", \"mean\"),\n",
    "                                median_ratio=(\"ratio\", \"median\"),\n",
    "                                n_funds=(\"FundID\", \"nunique\"))\n",
    "                           .reset_index())\n",
    "            # strategy+grade\n",
    "            for (s, g), grp in curves_sg.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "                g2 = grp[grp[\"n_funds\"] >= DRAW_CALIB_MIN_FUNDS]\n",
    "                if len(g2) < DRAW_CALIB_MIN_AGES:\n",
    "                    continue\n",
    "                scale_mean, sse_mean = fit_scale_for_group(g2, \"mean_ratio\")\n",
    "                scale_med, sse_med = fit_scale_for_group(g2, \"median_ratio\")\n",
    "                if DRAW_CALIB_TARGET == \"mean\":\n",
    "                    draw_scale_sg[(s, g)] = scale_mean\n",
    "                elif DRAW_CALIB_TARGET == \"median\":\n",
    "                    draw_scale_sg[(s, g)] = scale_med\n",
    "                else:\n",
    "                    draw_scale_sg[(s, g)] = scale_mean if sse_mean <= sse_med else scale_med\n",
    "\n",
    "            # strategy fallback: weighted average of grade-level scales\n",
    "            for s, grp in curves_sg.groupby([\"Adj Strategy\"]):\n",
    "                scales = []\n",
    "                for g in grp[\"Grade\"].unique():\n",
    "                    key = (s, g)\n",
    "                    if key in draw_scale_sg:\n",
    "                        n_funds = float(grp[grp[\"Grade\"] == g][\"n_funds\"].max())\n",
    "                        scales.append((draw_scale_sg[key], n_funds))\n",
    "                if scales:\n",
    "                    wsum = sum(w for _, w in scales)\n",
    "                    if wsum > 0:\n",
    "                        draw_scale_s[s] = sum(scale * w for scale, w in scales) / wsum\n",
    "\n",
    "            # global fallback: weighted average of strategy scales\n",
    "            if draw_scale_s:\n",
    "                wsum = 0.0\n",
    "                tot = 0.0\n",
    "                for s, scale in draw_scale_s.items():\n",
    "                    n_funds = float(curves_s[curves_s[\"Adj Strategy\"] == s][\"n_funds\"].max())\n",
    "                    if not np.isfinite(n_funds) or n_funds <= 0:\n",
    "                        continue\n",
    "                    wsum += n_funds\n",
    "                    tot += scale * n_funds\n",
    "                if wsum > 0:\n",
    "                    draw_scale_g = tot / wsum\n",
    "\n",
    "            print(f\"Drawdown calibration: sg_scales={len(draw_scale_sg)}, \"\n",
    "                  f\"s_scales={len(draw_scale_s)}, global_scale={round(draw_scale_g, 4)} \"\n",
    "                  f\"(target={DRAW_CALIB_TARGET})\")\n",
    "\n",
    "    # Runoff calibration\n",
    "    runoff_mult_by_strategy = {}\n",
    "    if USE_RUNOFF_CALIBRATION:\n",
    "        tail = train[train[\"AgeBucket\"].isin([\"15-20y\", \"20y+\"])].copy()\n",
    "        mid = train[train[\"AgeBucket\"].isin([\"6-8y\", \"8-10y\", \"10-15y\"])].copy()\n",
    "        for s in train[\"Adj Strategy\"].dropna().unique():\n",
    "            t = tail[tail[\"Adj Strategy\"] == s]\n",
    "            m = mid[mid[\"Adj Strategy\"] == s]\n",
    "            if len(t) and len(m) and t[\"rep_ratio\"].notna().any() and m[\"rep_ratio\"].notna().any():\n",
    "                num = t[\"rep_ratio\"].mean()\n",
    "                den = m[\"rep_ratio\"].mean()\n",
    "                if den > 0:\n",
    "                    runoff_mult_by_strategy[s] = float(np.clip(num / den, RUNOFF_MULT_MIN, RUNOFF_MULT_MAX))\n",
    "\n",
    "    # =============================\n",
    "    # Recallable soft limits\n",
    "    # =============================\n",
    "    kmp_needed = [\"FundID\", \"Recallable_Percentage_Decimal\", \"Expiration_Quarters\"]\n",
    "    missing_k = [c for c in kmp_needed if c not in kmp.columns]\n",
    "    if missing_k:\n",
    "        raise ValueError(f\"Missing columns in kmp: {missing_k}\")\n",
    "\n",
    "    kmp2 = kmp[kmp_needed].copy()\n",
    "    kmp2[\"Recallable_Percentage_Decimal\"] = pd.to_numeric(kmp2[\"Recallable_Percentage_Decimal\"], errors=\"coerce\")\n",
    "    kmp2[\"Expiration_Quarters\"] = pd.to_numeric(kmp2[\"Expiration_Quarters\"], errors=\"coerce\")\n",
    "    kmp2 = kmp2.set_index(\"FundID\")\n",
    "\n",
    "    tmp_rho = (\n",
    "        data.groupby(\"FundID\", as_index=False)\n",
    "        .agg(sum_rc=(\"Recallable\", \"sum\"), C_last=(\"Commitment_Level\", \"max\"))\n",
    "    )\n",
    "    tmp_rho[\"rho_emp\"] = np.where(tmp_rho[\"C_last\"] > 0, tmp_rho[\"sum_rc\"] / tmp_rho[\"C_last\"], np.nan)\n",
    "    rho_emp = tmp_rho.set_index(\"FundID\")[\"rho_emp\"].to_dict()\n",
    "\n",
    "    def soft_params(strategy: str) -> Tuple[float, int]:\n",
    "        s = data[data[\"Adj Strategy\"].eq(strategy)]\n",
    "        if len(s):\n",
    "            rho = float(np.nanquantile(s[\"Recallable\"].fillna(0.0), SOFT_RHO_PCTL))\n",
    "            rho = float(np.clip(rho, 0.0, 0.9))\n",
    "        else:\n",
    "            rho = 0.0\n",
    "        return rho, SOFT_EXPIRY_FALLBACK\n",
    "\n",
    "    def get_rho_E(fid: str, strategy: str) -> Tuple[float, int]:\n",
    "        if fid in kmp2.index:\n",
    "            r = kmp2.loc[fid]\n",
    "            rho = float(r.get(\"Recallable_Percentage_Decimal\", np.nan))\n",
    "            E = int(r.get(\"Expiration_Quarters\", np.nan)) if pd.notna(r.get(\"Expiration_Quarters\", np.nan)) else SOFT_EXPIRY_FALLBACK\n",
    "            if not np.isfinite(rho):\n",
    "                rho = rho_emp.get(fid, np.nan)\n",
    "            if not np.isfinite(rho):\n",
    "                rho, _ = soft_params(strategy)\n",
    "            return float(np.clip(rho, 0.0, 0.9)), int(E)\n",
    "        rho = rho_emp.get(fid, np.nan)\n",
    "        if not np.isfinite(rho):\n",
    "            rho, E = soft_params(strategy)\n",
    "        else:\n",
    "            _, E = soft_params(strategy)\n",
    "        return float(np.clip(rho, 0.0, 0.9)), int(E)\n",
    "\n",
    "    # =============================\n",
    "    # Build initial states at test start\n",
    "    # =============================\n",
    "    fund_states = {}\n",
    "    fund_start_qe = {}\n",
    "    fund_bucket = {}\n",
    "\n",
    "    # Build transition matrices\n",
    "    all_counts, all_probs, all_n = build_yearly_transition_from_data(train, strategy=None)\n",
    "    strat_probs = {}\n",
    "    strat_n = {}\n",
    "    for s in train[\"Adj Strategy\"].dropna().unique():\n",
    "        _, probs_s, n_s = build_yearly_transition_from_data(train, strategy=s)\n",
    "        strat_probs[s] = probs_s\n",
    "        strat_n[s] = n_s\n",
    "\n",
    "    def get_transition_matrix(strategy: str) -> pd.DataFrame:\n",
    "        if strategy in strat_probs and strat_n.get(strategy, 0) >= 30:\n",
    "            return strat_probs[strategy]\n",
    "        return all_probs\n",
    "\n",
    "    # Pre-build actual fund history for replay\n",
    "    data_by_fund = {fid: g.copy() for fid, g in data.groupby(\"FundID\")}\n",
    "\n",
    "    for fid in test_funds:\n",
    "        hist = data_by_fund.get(fid)\n",
    "        if hist is None or hist.empty:\n",
    "            continue\n",
    "        hist = hist.sort_values(\"quarter_end\")\n",
    "        hist_pre = hist[hist[\"quarter_end\"] <= train_end_qe]\n",
    "        if hist_pre.empty:\n",
    "            continue\n",
    "\n",
    "        last = hist_pre.iloc[-1]\n",
    "        strategy = nav_strategy_by_fund.get(fid, str(last.get(\"Adj Strategy\") or \"Unknown\")) if USE_NAV_PROJECTIONS else str(last.get(\"Adj Strategy\") or \"Unknown\")\n",
    "        grade0 = nav_grade_by_fund.get(fid, str(last.get(\"Grade\") or \"D\")).strip() if USE_NAV_PROJECTIONS else str(last.get(\"Grade\") or \"D\").strip()\n",
    "        if grade0 not in GRADE_STATES:\n",
    "            grade0 = \"D\"\n",
    "        age0_src = nav_age_by_fund.get(fid, None) if USE_NAV_PROJECTIONS else None\n",
    "        if age0_src is None or pd.isna(age0_src):\n",
    "            age0_src = last.get(\"age_q_model\") or 0.0\n",
    "        age0 = int(round(float(age0_src)))\n",
    "        nav0 = float(nav_start_by_fund.get(fid, last.get(\"NAV Adjusted EUR\") or 0.0)) if USE_NAV_PROJECTIONS else float(last.get(\"NAV Adjusted EUR\") or 0.0)\n",
    "\n",
    "        fund_start_qe[fid] = hist[\"quarter_end\"].iloc[0]\n",
    "        start_qe = fund_start_qe[fid]\n",
    "\n",
    "        # initialize recallables and DD_cum_commit\n",
    "        C = float(fund_commit.get(fid, 0.0) or 0.0)\n",
    "        rho, E = get_rho_E(fid, strategy)\n",
    "        ledger = RecallableLedger(rho=rho, expiry_quarters=E, commitment=C)\n",
    "        dd_cum_commit = 0.0\n",
    "\n",
    "        if USE_NAV_PROJECTIONS:\n",
    "            draw_hist = float(draw_cum_hist.get(fid, 0.0) or 0.0)\n",
    "            dd_cum_commit = min(draw_hist, C)\n",
    "        else:\n",
    "            # replay history to reconstruct DD_commit and recallables\n",
    "            for _, row in hist_pre.iterrows():\n",
    "                qe = row[\"quarter_end\"]\n",
    "                step = quarter_diff(qe, start_qe)\n",
    "                draw = float(row.get(\"Adj Drawdown EUR\") or 0.0)\n",
    "                rep = float(row.get(\"Adj Repayment EUR\") or 0.0)\n",
    "                rc = float(row.get(\"Recallable\") or 0.0)\n",
    "                if rep > 0 and rc > 0:\n",
    "                    ledger.add_recallable(step, rc, enforce_cap=True)\n",
    "                if draw > 0:\n",
    "                    cons = ledger.consume_for_drawdown(step, draw)\n",
    "                    dd_cum_commit += cons[\"use_commitment\"]\n",
    "\n",
    "        # bucket (based on start grade/age)\n",
    "        age_bucket0 = make_age_bucket_q(age0)\n",
    "        if REPORT_BUCKET_MODE == \"strategy\":\n",
    "            bucket_key = (strategy, \"ALL\", \"ALL\")\n",
    "        elif REPORT_BUCKET_MODE == \"strategy_grade\":\n",
    "            bucket_key = (strategy, grade0, \"ALL\")\n",
    "        else:\n",
    "            bucket_key = (strategy, grade0, str(age_bucket0))\n",
    "        fund_bucket[fid] = bucket_key\n",
    "\n",
    "        fund_states[fid] = {\n",
    "            \"strategy\": strategy,\n",
    "            \"grade\": grade0,\n",
    "            \"age0\": age0,\n",
    "            \"nav\": nav0,\n",
    "            \"dd_commit\": dd_cum_commit,\n",
    "            \"ledger\": ledger,\n",
    "            \"commitment\": C,\n",
    "            \"cap_qe\": cap_by_fund.get(fid, pd.NaT),\n",
    "        }\n",
    "\n",
    "    # bucket index mapping\n",
    "    bucket_keys = sorted(set(fund_bucket.values()))\n",
    "    bucket_index = {b: i for i, b in enumerate(bucket_keys)}\n",
    "\n",
    "    # =============================\n",
    "    # Actual portfolio series (test)\n",
    "    # =============================\n",
    "    T = len(test_quarters)\n",
    "    B = len(bucket_keys)\n",
    "\n",
    "    actual_draw = np.zeros(T)\n",
    "    actual_rep = np.zeros(T)\n",
    "    actual_nav = np.zeros(T)\n",
    "\n",
    "    actual_draw_b = np.zeros((T, B))\n",
    "    actual_rep_b = np.zeros((T, B))\n",
    "    actual_nav_b = np.zeros((T, B))\n",
    "\n",
    "    # Build per-fund actual grid\n",
    "    for fid in fund_states.keys():\n",
    "        hist = data_by_fund[fid].copy().sort_values(\"quarter_end\")\n",
    "        # collapse any duplicate quarter_end rows before aligning to grid\n",
    "        hist_q = (hist.groupby(\"quarter_end\", as_index=True)\n",
    "                  .agg({\n",
    "                      \"Adj Drawdown EUR\": \"sum\",\n",
    "                      \"Adj Repayment EUR\": \"sum\",\n",
    "                      \"NAV Adjusted EUR\": \"last\",\n",
    "                  }))\n",
    "        # grid for test quarters\n",
    "        grid = pd.DataFrame(index=pd.Index(test_quarters, name=\"quarter_end\"))\n",
    "        grid[\"Draw\"] = hist_q[\"Adj Drawdown EUR\"]\n",
    "        grid[\"Rep\"] = hist_q[\"Adj Repayment EUR\"]\n",
    "        grid[\"NAV\"] = hist_q[\"NAV Adjusted EUR\"]\n",
    "\n",
    "        # Fill missing: Draw/Rep = 0, NAV = ffill from last known (including pre-test)\n",
    "        grid[\"Draw\"] = grid[\"Draw\"].fillna(0.0)\n",
    "        grid[\"Rep\"] = grid[\"Rep\"].fillna(0.0)\n",
    "\n",
    "        # seed NAV from last known before test start\n",
    "        nav_seed = hist_q.loc[hist_q.index <= train_end_qe, \"NAV Adjusted EUR\"]\n",
    "        nav_seed = float(nav_seed.iloc[-1]) if len(nav_seed) else 0.0\n",
    "        grid[\"NAV\"] = grid[\"NAV\"].ffill().fillna(nav_seed)\n",
    "\n",
    "        bkey = fund_bucket[fid]\n",
    "        bidx = bucket_index[bkey]\n",
    "\n",
    "        actual_draw += grid[\"Draw\"].to_numpy(dtype=float)\n",
    "        actual_rep += grid[\"Rep\"].to_numpy(dtype=float)\n",
    "        actual_nav += grid[\"NAV\"].to_numpy(dtype=float)\n",
    "\n",
    "        actual_draw_b[:, bidx] += grid[\"Draw\"].to_numpy(dtype=float)\n",
    "        actual_rep_b[:, bidx] += grid[\"Rep\"].to_numpy(dtype=float)\n",
    "        actual_nav_b[:, bidx] += grid[\"NAV\"].to_numpy(dtype=float)\n",
    "\n",
    "    # =============================\n",
    "    # Simulation runner\n",
    "    # =============================\n",
    "\n",
    "    def run_backtest(scenario: str, conditional: bool) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        sim_draw = np.zeros((n_sims, T))\n",
    "        sim_rep = np.zeros((n_sims, T))\n",
    "        sim_nav = np.zeros((n_sims, T))\n",
    "\n",
    "        sim_draw_b = np.zeros((n_sims, T, B))\n",
    "        sim_rep_b = np.zeros((n_sims, T, B))\n",
    "        sim_nav_b = np.zeros((n_sims, T, B))\n",
    "\n",
    "        fund_ids = list(fund_states.keys())\n",
    "        n_funds = len(fund_ids)\n",
    "        fund_index = {fid: i for i, fid in enumerate(fund_ids)}\n",
    "\n",
    "        omega_key = None\n",
    "        if USE_NAV_PROJECTIONS and sim_ids:\n",
    "            if len(sim_ids) == 1:\n",
    "                sim_id_list = list(range(n_sims))\n",
    "                omega_key = sim_ids[0]\n",
    "            else:\n",
    "                sim_id_list = sim_ids\n",
    "        else:\n",
    "            sim_id_list = list(range(n_sims))\n",
    "\n",
    "        for s_idx, sim_id in enumerate(sim_id_list):\n",
    "            rng = np.random.default_rng(seed + s_idx)\n",
    "            omega_sim_id = omega_key if omega_key is not None else sim_id\n",
    "\n",
    "            # MSCI path: conditional uses actual MSCI; unconditional may use NAV Logic or simulated\n",
    "            if conditional:\n",
    "                msci_series = pd.Series([msci_map[qe] for qe in test_quarters],\n",
    "                                        index=pd.Index(test_quarters, name=\"quarter_end\"))\n",
    "                msci_mu = msci_mu_all\n",
    "                msci_sigma = msci_sigma_all\n",
    "            else:\n",
    "                if USE_NAV_PROJECTIONS and omega_sim_id in msci_map_sim:\n",
    "                    msci_series = pd.Series([float(msci_map_sim[omega_sim_id].get(qe, 0.0)) for qe in test_quarters],\n",
    "                                            index=pd.Index(test_quarters, name=\"quarter_end\"))\n",
    "                    stats = msci_stats_by_sim.get(omega_sim_id, {})\n",
    "                    msci_mu = float(stats.get(\"mean\", msci_mu_all))\n",
    "                    msci_sigma = float(stats.get(\"std\", msci_sigma_all))\n",
    "                else:\n",
    "                    msci_path = simulate_msci_path(msci_q[msci_q[\"quarter_end\"] <= train_end_qe],\n",
    "                                                   start_qe=train_end_qe,\n",
    "                                                   n_quarters=T,\n",
    "                                                   scenario=scenario,\n",
    "                                                   tilt_strength=tilt_strength,\n",
    "                                                   rng=rng)\n",
    "                    msci_path = msci_path.set_index(\"quarter_end\")\n",
    "                    msci_series = msci_path[\"msci_ret_q\"]\n",
    "                    msci_mu = msci_mu_all\n",
    "                    msci_sigma = msci_sigma_all\n",
    "\n",
    "            if not np.isfinite(msci_sigma) or msci_sigma <= 0:\n",
    "                msci_sigma = 1e-6\n",
    "\n",
    "            # Prepare per-quarter copula uniforms\n",
    "            U_by_q = {}\n",
    "            for qe in test_quarters:\n",
    "                U_by_q[qe] = {\n",
    "                    \"draw_event\": one_factor_uniforms(n_funds, rng, rho_event),\n",
    "                    \"draw_size\": one_factor_uniforms(n_funds, rng, rho_size),\n",
    "                    \"rep_event\": one_factor_uniforms(n_funds, rng, rho_event),\n",
    "                    \"rep_size\": one_factor_uniforms(n_funds, rng, rho_size),\n",
    "                    \"rc_event\": one_factor_uniforms(n_funds, rng, rho_event),\n",
    "                    \"rc_size\": one_factor_uniforms(n_funds, rng, rho_size),\n",
    "                }\n",
    "\n",
    "            # initialize fund states for this sim\n",
    "            sim_state = {}\n",
    "            for fid in fund_ids:\n",
    "                st0 = fund_states[fid]\n",
    "                sim_state[fid] = {\n",
    "                    \"strategy\": st0[\"strategy\"],\n",
    "                    \"grade\": st0[\"grade\"],\n",
    "                    \"age0\": st0[\"age0\"],\n",
    "                    \"nav\": float(st0[\"nav\"]),\n",
    "                    \"dd_commit\": float(st0[\"dd_commit\"]),\n",
    "                    \"ip_catchup_done\": False,\n",
    "                    \"ledger\": RecallableLedger(\n",
    "                        rho=st0[\"ledger\"].rho,\n",
    "                        expiry_quarters=st0[\"ledger\"].expiry_quarters,\n",
    "                        commitment=st0[\"ledger\"].commitment,\n",
    "                        buckets=[RecallableBucket(b.created_q, b.expiry_q, b.amount_remaining) for b in st0[\"ledger\"].buckets]\n",
    "                    ),\n",
    "                    \"commitment\": float(st0[\"commitment\"]),\n",
    "                    \"cap_qe\": st0[\"cap_qe\"],\n",
    "                    \"alive\": True,\n",
    "                }\n",
    "\n",
    "            for t_idx, qe in enumerate(test_quarters):\n",
    "                msci_r = float(msci_series.get(qe, 0.0))\n",
    "                msci_r_lag1 = float(msci_series.get(test_quarters[t_idx - 1], 0.0)) if t_idx > 0 else float(msci_lag_map.get(qe, 0.0) or 0.0)\n",
    "\n",
    "                msci_z = (msci_r - msci_mu) / msci_sigma\n",
    "                msci_z = float(np.clip(msci_z, -MSCI_Z_CLIP, MSCI_Z_CLIP))\n",
    "                msci_z_eff = max(msci_z, 0.0) if MSCI_REP_POS_ONLY else msci_z\n",
    "\n",
    "                U = U_by_q[qe]\n",
    "\n",
    "                for fid in fund_ids:\n",
    "                    st = sim_state[fid]\n",
    "                    if not st[\"alive\"]:\n",
    "                        continue\n",
    "\n",
    "                    age_q = int(st[\"age0\"] + t_idx)\n",
    "                    if USE_NAV_PROJECTIONS and omega_sim_id in age_map:\n",
    "                        age_q = age_map[omega_sim_id].get((fid, qe), age_q)\n",
    "                        age_q = int(round(float(age_q)))\n",
    "                    age_bucket = make_age_bucket_q(age_q)\n",
    "\n",
    "                    # annual grade transition (disabled when using NAV projections)\n",
    "                    if not USE_NAV_PROJECTIONS:\n",
    "                        if t_idx > 0 and t_idx % 4 == 0:\n",
    "                            P = get_transition_matrix(st[\"strategy\"])\n",
    "                            st[\"grade\"] = sample_next_grade(st[\"grade\"], P, rng)\n",
    "\n",
    "                    grade = st[\"grade\"]\n",
    "                    if USE_NAV_PROJECTIONS and omega_sim_id in grade_map:\n",
    "                        grade = grade_map[omega_sim_id].get((fid, qe), grade)\n",
    "                        st[\"grade\"] = grade\n",
    "\n",
    "                    strategy = st[\"strategy\"]\n",
    "                    if USE_NAV_PROJECTIONS and omega_sim_id in strategy_map:\n",
    "                        strategy = strategy_map[omega_sim_id].get((fid, qe), strategy)\n",
    "                        st[\"strategy\"] = strategy\n",
    "\n",
    "                    # omega\n",
    "                    if USE_NAV_PROJECTIONS:\n",
    "                        omega = float(omega_map.get(omega_sim_id, {}).get((fid, qe), 0.0))\n",
    "                    else:\n",
    "                        a, b0, b1 = get_betas(strategy, grade)\n",
    "                        alpha, _ = get_alpha(strategy, grade, str(age_bucket))\n",
    "                        sigma, _ = get_sigma(strategy, grade)\n",
    "                        eps = rng.standard_normal()\n",
    "                        omega = alpha + b0 * msci_r + b1 * msci_r_lag1 + sigma * eps\n",
    "                        omega += float(GRADE_OMEGA_BIAS.get(grade, 0.0))\n",
    "                        omega = float(np.clip(omega, -OMEGA_CLIP, OMEGA_CLIP))\n",
    "\n",
    "                    # capacity\n",
    "                    ledger = st[\"ledger\"]\n",
    "                    start_qe = fund_start_qe[fid]\n",
    "                    if USE_NAV_PROJECTIONS:\n",
    "                        step = t_idx + 1\n",
    "                    else:\n",
    "                        step = quarter_diff(qe, start_qe)\n",
    "                    rc_avail_pre = ledger.available(step)\n",
    "                    remaining_commit_pre = max(st[\"commitment\"] - st[\"dd_commit\"], 0.0)\n",
    "                    capacity_pre = remaining_commit_pre + rc_avail_pre\n",
    "\n",
    "                    params = lookup_params(strategy, grade, age_bucket)\n",
    "\n",
    "                    # drawdown probability\n",
    "                    ip_q = int(ip_by_strategy.get(strategy, IP_Q_DEFAULT))\n",
    "                    draw_mult = 1.0\n",
    "                    if USE_DRAW_AGE_SHAPE and ip_q > 0:\n",
    "                        if ENFORCE_IP_LIMITS and age_q > ip_q:\n",
    "                            draw_mult = 0.0\n",
    "                        else:\n",
    "                            frac = float(age_q) / float(ip_q)\n",
    "                            draw_mult = max(DRAW_AGE_MIN_MULT, (1.0 - frac) ** DRAW_AGE_DECAY_POWER)\n",
    "\n",
    "                    if USE_HAZARD_MODELS and beta_draw is not None:\n",
    "                        Xr = build_feature_row(strategy, grade, age_q, 0.0, False, hazard_meta[\"draw_cols\"], hazard_meta[\"draw_means\"], hazard_meta[\"draw_stds\"])\n",
    "                        p_draw_base = float(_sigmoid(Xr @ beta_draw)[0])\n",
    "                    else:\n",
    "                        p_draw_base = float(params.get(\"p_draw\", 0.0))\n",
    "\n",
    "                    grade_key = grade if grade in GRADE_DRAW_P_MULT else \"D\"\n",
    "                    p_draw_adj = p_draw_base * draw_mult * float(GRADE_DRAW_P_MULT.get(grade_key, 1.0))\n",
    "                    p_draw_adj = min(p_draw_adj, 1.0)\n",
    "\n",
    "                    i = fund_index[fid]\n",
    "                    draw_event = (U[\"draw_event\"][i] < p_draw_adj) and (capacity_pre > 0.0)\n",
    "                    draw_amt = 0.0\n",
    "                    use_rc = 0.0\n",
    "                    use_commit = 0.0\n",
    "\n",
    "                    if draw_event:\n",
    "                        ratio = lognormal_from_u(params[\"mu_draw\"], params[\"sig_draw\"], float(U[\"draw_size\"][i]))\n",
    "                        ratio = float(np.clip(ratio, 0.0, 1.0))\n",
    "                        ratio = min(ratio * float(GRADE_DRAW_SIZE_MULT.get(grade_key, 1.0)), 1.0)\n",
    "                        if USE_DRAWDOWN_CALIBRATION:\n",
    "                            scale = draw_scale_sg.get((strategy, grade),\n",
    "                                                      draw_scale_s.get(strategy, draw_scale_g))\n",
    "                            ratio = ratio * float(scale)\n",
    "                        ratio = float(np.clip(ratio, 0.0, 1.0))\n",
    "                        draw_amt = ratio * capacity_pre\n",
    "                        cons = ledger.consume_for_drawdown(step, draw_amt)\n",
    "                        use_rc = cons[\"use_rc\"]\n",
    "                        use_commit = cons[\"use_commitment\"]\n",
    "                        st[\"dd_commit\"] += use_commit\n",
    "\n",
    "                    # Optional: enforce full commitment call at IP end (aligns with Structural-cashflows)\n",
    "                    if ENFORCE_IP_LIMITS and (not st[\"ip_catchup_done\"]) and (age_q >= ip_q):\n",
    "                        remaining_commit_after = max(st[\"commitment\"] - st[\"dd_commit\"], 0.0)\n",
    "                        if remaining_commit_after > 0.0:\n",
    "                            draw_amt += remaining_commit_after\n",
    "                            use_commit += remaining_commit_after\n",
    "                            st[\"dd_commit\"] += remaining_commit_after\n",
    "                            draw_event = True\n",
    "                        st[\"ip_catchup_done\"] = True\n",
    "\n",
    "                    # repayment\n",
    "                    NAV_prev = float(st[\"nav\"])\n",
    "                    rep_regular = 0.0\n",
    "                    if USE_HAZARD_MODELS and beta_rep is not None:\n",
    "                        Xr = build_feature_row(strategy, grade, age_q, np.log1p(abs(NAV_prev)), True, hazard_meta[\"rep_cols\"], hazard_meta[\"rep_means\"], hazard_meta[\"rep_stds\"])\n",
    "                        p_rep_base = float(_sigmoid(Xr @ beta_rep)[0])\n",
    "                    else:\n",
    "                        p_rep_base = float(params.get(\"p_rep\", 0.0))\n",
    "\n",
    "                    grade_key = grade if grade in GRADE_P_MULT else \"D\"\n",
    "                    runoff_mult = float(runoff_mult_by_strategy.get(strategy, 1.0)) if USE_RUNOFF_CALIBRATION else 1.0\n",
    "\n",
    "                    cap_qe = st[\"cap_qe\"]\n",
    "                    if USE_NAV_PROJECTIONS:\n",
    "                        q_left = max(T - (t_idx + 1), 0)\n",
    "                    else:\n",
    "                        q_left = 9999\n",
    "                        if pd.notna(cap_qe):\n",
    "                            q_left = max(quarter_diff(cap_qe, qe), 0)\n",
    "\n",
    "                    tail_factor = 0.0\n",
    "                    if RUNOFF_Q > 0:\n",
    "                        tail_factor = float(max(0.0, (RUNOFF_Q - q_left) / RUNOFF_Q))\n",
    "\n",
    "                    p_rep_adj = 1.0 - (1.0 - p_rep_base) ** (1.0 + (REP_RAMP_P * runoff_mult) * tail_factor)\n",
    "                    p_rep_adj = min(1.0, p_rep_adj + REP_RAMP_FLOOR * tail_factor)\n",
    "                    p_rep_adj = min(1.0, p_rep_adj * float(GRADE_P_MULT.get(grade_key, 1.0)))\n",
    "                    p_rep_adj = float(np.clip(p_rep_adj, 1e-6, 1.0 - 1e-6))\n",
    "                    logit_p = np.log(p_rep_adj / (1.0 - p_rep_adj))\n",
    "                    logit_p += MSCI_REP_P_BETA * msci_z_eff\n",
    "                    p_rep_adj = float(1.0 / (1.0 + np.exp(-logit_p)))\n",
    "\n",
    "                    rep_event = (U[\"rep_event\"][i] < p_rep_adj) and (NAV_prev > NAV_EPS)\n",
    "                    if rep_event:\n",
    "                        rep_ratio = lognormal_from_u(params[\"mu_rep\"], params[\"sig_rep\"], float(U[\"rep_size\"][i]))\n",
    "                        rep_ratio = float(np.clip(rep_ratio, 0.0, 1.0))\n",
    "                        rep_ratio = min(rep_ratio * (1.0 + (REP_RAMP_SIZE * runoff_mult) * tail_factor), 1.0)\n",
    "                        rep_ratio = min(rep_ratio * float(GRADE_SIZE_MULT.get(grade_key, 1.0)), 1.0)\n",
    "                        size_mult = max(0.0, 1.0 + MSCI_REP_SIZE_BETA * msci_z_eff)\n",
    "                        rep_ratio = min(rep_ratio * size_mult, 1.0)\n",
    "                        rep_regular = rep_ratio * NAV_prev\n",
    "\n",
    "                    # recallable\n",
    "                    rc_added = 0.0\n",
    "                    rc_event = (rep_regular > 0.0) and (U[\"rc_event\"][i] < params[\"p_rc_given_rep\"])\n",
    "                    if rc_event:\n",
    "                        rc_ratio = lognormal_from_u(params[\"mu_rc\"], params[\"sig_rc\"], float(U[\"rc_size\"][i]))\n",
    "                        rc_ratio = float(np.clip(rc_ratio, 0.0, 1.0))\n",
    "                        rc_amt_raw = rc_ratio * rep_regular\n",
    "                        rc_added = ledger.add_recallable(step, rc_amt_raw, enforce_cap=True)\n",
    "\n",
    "                    # NAV update\n",
    "                    available_nav = max(NAV_prev + float(draw_amt) - float(rep_regular), 0.0)\n",
    "                    rep_terminal = 0.0\n",
    "                    if USE_FORCED_TERMINAL_REPAY and RUNOFF_Q > 0 and q_left < RUNOFF_Q:\n",
    "                        base_ratio = q_left / (q_left + 1.0)\n",
    "                        target_nav = available_nav * (base_ratio ** max(runoff_mult, 0.0))\n",
    "                        rep_terminal = max(0.0, available_nav - target_nav)\n",
    "\n",
    "                    nav_after_flow = max(available_nav - rep_terminal, 0.0)\n",
    "                    nav_after_val = nav_after_flow * (1.0 + float(omega))\n",
    "                    if not np.isfinite(nav_after_val):\n",
    "                        nav_after_val = 0.0\n",
    "                    nav_after_val = max(float(nav_after_val), 0.0)\n",
    "\n",
    "                    st[\"nav\"] = nav_after_val\n",
    "\n",
    "                    if q_left == 0 or nav_after_val <= NAV_STOP_EPS:\n",
    "                        st[\"alive\"] = False\n",
    "\n",
    "                    # aggregates\n",
    "                    bkey = fund_bucket[fid]\n",
    "                    bidx = bucket_index[bkey]\n",
    "\n",
    "                    sim_draw[s_idx, t_idx] += draw_amt\n",
    "                    sim_rep[s_idx, t_idx] += (rep_regular + rep_terminal)\n",
    "                    sim_nav[s_idx, t_idx] += nav_after_val\n",
    "\n",
    "                    sim_draw_b[s_idx, t_idx, bidx] += draw_amt\n",
    "                    sim_rep_b[s_idx, t_idx, bidx] += (rep_regular + rep_terminal)\n",
    "                    sim_nav_b[s_idx, t_idx, bidx] += nav_after_val\n",
    "\n",
    "        # build portfolio series table\n",
    "        q_end = pd.Index(test_quarters, name=\"quarter_end\")\n",
    "        portfolio_series = pd.DataFrame({\n",
    "            \"quarter_end\": q_end,\n",
    "            \"actual_draw\": actual_draw,\n",
    "            \"actual_rep\": actual_rep,\n",
    "            \"actual_nav\": actual_nav,\n",
    "            \"sim_draw_mean\": sim_draw.mean(axis=0),\n",
    "            \"sim_rep_mean\": sim_rep.mean(axis=0),\n",
    "            \"sim_nav_mean\": sim_nav.mean(axis=0),\n",
    "            \"sim_draw_p05\": np.quantile(sim_draw, 0.05, axis=0),\n",
    "            \"sim_draw_p95\": np.quantile(sim_draw, 0.95, axis=0),\n",
    "            \"sim_rep_p05\": np.quantile(sim_rep, 0.05, axis=0),\n",
    "            \"sim_rep_p95\": np.quantile(sim_rep, 0.95, axis=0),\n",
    "            \"sim_nav_p05\": np.quantile(sim_nav, 0.05, axis=0),\n",
    "            \"sim_nav_p95\": np.quantile(sim_nav, 0.95, axis=0),\n",
    "        })\n",
    "\n",
    "        # portfolio summary\n",
    "        def _metrics(sim_mean, sim_p05, sim_p95, actual):\n",
    "            err = sim_mean - actual\n",
    "            rmse = float(np.sqrt(np.mean(err ** 2)))\n",
    "            mae = float(np.mean(np.abs(err)))\n",
    "            bias = float(np.mean(err))\n",
    "            coverage = float(np.mean((actual >= sim_p05) & (actual <= sim_p95)))\n",
    "            return rmse, mae, bias, coverage\n",
    "\n",
    "        draw_rmse, draw_mae, draw_bias, draw_cov = _metrics(\n",
    "            portfolio_series[\"sim_draw_mean\"].to_numpy(),\n",
    "            portfolio_series[\"sim_draw_p05\"].to_numpy(),\n",
    "            portfolio_series[\"sim_draw_p95\"].to_numpy(),\n",
    "            portfolio_series[\"actual_draw\"].to_numpy(),\n",
    "        )\n",
    "        rep_rmse, rep_mae, rep_bias, rep_cov = _metrics(\n",
    "            portfolio_series[\"sim_rep_mean\"].to_numpy(),\n",
    "            portfolio_series[\"sim_rep_p05\"].to_numpy(),\n",
    "            portfolio_series[\"sim_rep_p95\"].to_numpy(),\n",
    "            portfolio_series[\"actual_rep\"].to_numpy(),\n",
    "        )\n",
    "        nav_rmse, nav_mae, nav_bias, nav_cov = _metrics(\n",
    "            portfolio_series[\"sim_nav_mean\"].to_numpy(),\n",
    "            portfolio_series[\"sim_nav_p05\"].to_numpy(),\n",
    "            portfolio_series[\"sim_nav_p95\"].to_numpy(),\n",
    "            portfolio_series[\"actual_nav\"].to_numpy(),\n",
    "        )\n",
    "\n",
    "        portfolio_summary = pd.DataFrame([\n",
    "            {\n",
    "                \"scenario\": scenario,\n",
    "                \"bucket\": \"PORTFOLIO\",\n",
    "                \"n_funds\": len(fund_ids),\n",
    "                \"draw_rmse\": draw_rmse, \"draw_mae\": draw_mae, \"draw_bias\": draw_bias, \"draw_cov_90\": draw_cov,\n",
    "                \"rep_rmse\": rep_rmse, \"rep_mae\": rep_mae, \"rep_bias\": rep_bias, \"rep_cov_90\": rep_cov,\n",
    "                \"nav_rmse\": nav_rmse, \"nav_mae\": nav_mae, \"nav_bias\": nav_bias, \"nav_cov_90\": nav_cov,\n",
    "            }\n",
    "        ])\n",
    "\n",
    "        # bucket summary\n",
    "        bucket_rows = []\n",
    "        for bkey, bidx in bucket_index.items():\n",
    "            sim_draw_m = sim_draw_b[:, :, bidx].mean(axis=0)\n",
    "            sim_rep_m = sim_rep_b[:, :, bidx].mean(axis=0)\n",
    "            sim_nav_m = sim_nav_b[:, :, bidx].mean(axis=0)\n",
    "\n",
    "            sim_draw_p05 = np.quantile(sim_draw_b[:, :, bidx], 0.05, axis=0)\n",
    "            sim_draw_p95 = np.quantile(sim_draw_b[:, :, bidx], 0.95, axis=0)\n",
    "\n",
    "            sim_rep_p05 = np.quantile(sim_rep_b[:, :, bidx], 0.05, axis=0)\n",
    "            sim_rep_p95 = np.quantile(sim_rep_b[:, :, bidx], 0.95, axis=0)\n",
    "\n",
    "            sim_nav_p05 = np.quantile(sim_nav_b[:, :, bidx], 0.05, axis=0)\n",
    "            sim_nav_p95 = np.quantile(sim_nav_b[:, :, bidx], 0.95, axis=0)\n",
    "\n",
    "            act_draw = actual_draw_b[:, bidx]\n",
    "            act_rep = actual_rep_b[:, bidx]\n",
    "            act_nav = actual_nav_b[:, bidx]\n",
    "\n",
    "            d_rmse, d_mae, d_bias, d_cov = _metrics(sim_draw_m, sim_draw_p05, sim_draw_p95, act_draw)\n",
    "            r_rmse, r_mae, r_bias, r_cov = _metrics(sim_rep_m, sim_rep_p05, sim_rep_p95, act_rep)\n",
    "            n_rmse, n_mae, n_bias, n_cov = _metrics(sim_nav_m, sim_nav_p05, sim_nav_p95, act_nav)\n",
    "\n",
    "            n_funds_bucket = sum(1 for f, b in fund_bucket.items() if b == bkey)\n",
    "\n",
    "            bucket_rows.append({\n",
    "                \"scenario\": scenario,\n",
    "                \"strategy\": bkey[0],\n",
    "                \"grade\": bkey[1],\n",
    "                \"age_bucket\": bkey[2],\n",
    "                \"n_funds\": n_funds_bucket,\n",
    "                \"draw_rmse\": d_rmse, \"draw_mae\": d_mae, \"draw_bias\": d_bias, \"draw_cov_90\": d_cov,\n",
    "                \"rep_rmse\": r_rmse, \"rep_mae\": r_mae, \"rep_bias\": r_bias, \"rep_cov_90\": r_cov,\n",
    "                \"nav_rmse\": n_rmse, \"nav_mae\": n_mae, \"nav_bias\": n_bias, \"nav_cov_90\": n_cov,\n",
    "            })\n",
    "\n",
    "        bucket_summary = pd.DataFrame(bucket_rows)\n",
    "        return portfolio_series, portfolio_summary, bucket_summary\n",
    "\n",
    "    # Run conditional / unconditional as configured\n",
    "    cond_series = cond_portfolio = cond_bucket = None\n",
    "    uncond_series = uncond_portfolio = uncond_bucket = None\n",
    "\n",
    "    if RUN_CONDITIONAL:\n",
    "        print(\"Running conditional backtest (actual MSCI)...\")\n",
    "        cond_series, cond_portfolio, cond_bucket = run_backtest(\"conditional\", conditional=True)\n",
    "\n",
    "    if RUN_UNCONDITIONAL:\n",
    "        print(\"Running unconditional backtest (simulated MSCI)...\")\n",
    "        uncond_series, uncond_portfolio, uncond_bucket = run_backtest(scenario_uncond, conditional=False)\n",
    "\n",
    "    # Save\n",
    "    def _yq(qe: pd.Timestamp) -> str:\n",
    "        return f\"{qe.year}_Q{qe.quarter}\"\n",
    "\n",
    "    test_end_tag = _yq(test_end_qe)\n",
    "    out_cond_series = os.path.join(DATA_DIR, f\"backtest_portfolio_series_conditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_uncond_series = os.path.join(DATA_DIR, f\"backtest_portfolio_series_unconditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_cond_port = os.path.join(DATA_DIR, f\"backtest_portfolio_summary_conditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_uncond_port = os.path.join(DATA_DIR, f\"backtest_portfolio_summary_unconditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_cond_bucket = os.path.join(DATA_DIR, f\"backtest_bucket_summary_conditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_uncond_bucket = os.path.join(DATA_DIR, f\"backtest_bucket_summary_unconditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    if RUN_CONDITIONAL and cond_series is not None:\n",
    "        cond_series.to_csv(out_cond_series, index=False)\n",
    "        cond_portfolio.to_csv(out_cond_port, index=False)\n",
    "        cond_bucket.to_csv(out_cond_bucket, index=False)\n",
    "        print(out_cond_series)\n",
    "        print(out_cond_port)\n",
    "        print(out_cond_bucket)\n",
    "    if RUN_UNCONDITIONAL and uncond_series is not None:\n",
    "        uncond_series.to_csv(out_uncond_series, index=False)\n",
    "        uncond_portfolio.to_csv(out_uncond_port, index=False)\n",
    "        uncond_bucket.to_csv(out_uncond_bucket, index=False)\n",
    "        print(out_uncond_series)\n",
    "        print(out_uncond_port)\n",
    "        print(out_uncond_bucket)\n",
    "\n",
    "    print(\"Runtime (seconds):\", round(time.perf_counter() - t0, 2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}