{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344dca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import erf, sqrt\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: time and paths\n",
    "# -----------------------------\n",
    "\n",
    "def quarter_end_from_year_quarter(year: int, quarter: str) -> pd.Timestamp:\n",
    "    q = quarter.upper().strip()\n",
    "    if q not in {\"Q1\", \"Q2\", \"Q3\", \"Q4\"}:\n",
    "        raise ValueError(\"Quarter must be one of: Q1, Q2, Q3, Q4\")\n",
    "    q_num = int(q[1])\n",
    "    return pd.Period(f\"{year}Q{q_num}\", freq=\"Q\").to_timestamp(\"Q\")\n",
    "\n",
    "\n",
    "def add_quarters(qe: pd.Timestamp, q: int) -> pd.Timestamp:\n",
    "    if pd.isna(qe):\n",
    "        return pd.NaT\n",
    "    p = pd.Period(qe, freq=\"Q\")\n",
    "    return (p + int(q)).to_timestamp(\"Q\")\n",
    "\n",
    "\n",
    "def quarter_range(start_qe: pd.Timestamp, end_qe: pd.Timestamp) -> List[pd.Timestamp]:\n",
    "    if pd.isna(start_qe) or pd.isna(end_qe):\n",
    "        return []\n",
    "    p0 = pd.Period(start_qe, freq=\"Q\")\n",
    "    p1 = pd.Period(end_qe, freq=\"Q\")\n",
    "    if p1 < p0:\n",
    "        return []\n",
    "    return [p.to_timestamp(\"Q\") for p in pd.period_range(p0, p1, freq=\"Q\")]\n",
    "\n",
    "\n",
    "def _to_period_q(x) -> pd.Period:\n",
    "    if isinstance(x, pd.Period):\n",
    "        return x.asfreq(\"Q\")\n",
    "    try:\n",
    "        return pd.Period(x, freq=\"Q\")\n",
    "    except Exception:\n",
    "        return pd.Period(pd.Timestamp(x), freq=\"Q\")\n",
    "\n",
    "\n",
    "def quarter_diff(qe: pd.Timestamp, start_qe: pd.Timestamp) -> int:\n",
    "    p = _to_period_q(qe)\n",
    "    s = _to_period_q(start_qe)\n",
    "    return int(p.ordinal - s.ordinal)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config (aligns with Structural-cashflows)\n",
    "# -----------------------------\n",
    "\n",
    "AGE_BINS_Q = [-1, 7, 15, 23, 31, 39, 59, 79, 10_000]\n",
    "AGE_LABELS = [\"0-2y\", \"2-4y\", \"4-6y\", \"6-8y\", \"8-10y\", \"10-15y\", \"15-20y\", \"20y+\"]\n",
    "\n",
    "NAV_EPS = 100.0\n",
    "NAV_STOP_EPS = 1.0\n",
    "CAP_EPS = 1.0\n",
    "\n",
    "RUNOFF_Q = 12\n",
    "REP_RAMP_P = 2.0\n",
    "REP_RAMP_SIZE = 1.0\n",
    "REP_RAMP_FLOOR = 0.05\n",
    "\n",
    "USE_RUNOFF_CALIBRATION = True\n",
    "RUNOFF_MULT_MIN = 0.5\n",
    "RUNOFF_MULT_MAX = 3.0\n",
    "\n",
    "IP_YEARS_DEFAULT = 5\n",
    "IP_Q_DEFAULT = int(IP_YEARS_DEFAULT * 4)\n",
    "IP_CUM_PCTL = 0.80\n",
    "IP_Q_MIN = 4\n",
    "IP_Q_MAX = 40\n",
    "DRAW_AGE_MIN_MULT = 0.2\n",
    "DRAW_AGE_DECAY_POWER = 1.0\n",
    "\n",
    "ENFORCE_IP_LIMITS = False\n",
    "USE_DRAW_AGE_SHAPE = False\n",
    "\n",
    "GRADE_P_MULT = {\"A\": 1.15, \"B\": 1.00, \"C\": 0.85, \"D\": 0.70}\n",
    "GRADE_SIZE_MULT = {\"A\": 1.10, \"B\": 1.00, \"C\": 0.90, \"D\": 0.80}\n",
    "\n",
    "GRADE_DRAW_P_MULT = {\"A\": 0.95, \"B\": 1.00, \"C\": 1.05, \"D\": 1.10}\n",
    "GRADE_DRAW_SIZE_MULT = {\"A\": 0.95, \"B\": 1.00, \"C\": 1.05, \"D\": 1.10}\n",
    "\n",
    "MSCI_REP_P_BETA = 0.6\n",
    "MSCI_REP_SIZE_BETA = 0.4\n",
    "MSCI_Z_CLIP = 2.0\n",
    "MSCI_REP_POS_ONLY = True\n",
    "\n",
    "SIGMA_FLOOR = 0.35\n",
    "SIGMA_CAP = 2.0\n",
    "\n",
    "MIN_LN_OBS = 30\n",
    "MIN_LN_FUNDS = 5\n",
    "KS_ALPHA = 0.05\n",
    "SHRINK_N = 100\n",
    "SHRINK_FUNDS = 10\n",
    "\n",
    "USE_HAZARD_MODELS = True\n",
    "LOGIT_L2 = 1.0\n",
    "LOGIT_MAX_ITER = 50\n",
    "LOGIT_TOL = 1e-6\n",
    "\n",
    "SOFT_RHO_PCTL = 0.95\n",
    "SOFT_EXPIRY_FALLBACK = 20\n",
    "\n",
    "GRADE_STATES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "OMEGA_CLIP = 0.8\n",
    "GRADE_OMEGA_BIAS = {\"A\": 0.005, \"B\": 0.0, \"C\": -0.005, \"D\": -0.01}\n",
    "\n",
    "# -----------------------------\n",
    "# Calibration controls\n",
    "# -----------------------------\n",
    "USE_DRAWDOWN_CALIBRATION = True\n",
    "# \"mean\", \"median\", or \"auto\" (pick lower SSE per group)\n",
    "DRAW_CALIB_TARGET = \"auto\"\n",
    "DRAW_CALIB_MIN_FUNDS = 10\n",
    "DRAW_CALIB_MIN_AGES = 8\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: math / distributions\n",
    "# -----------------------------\n",
    "\n",
    "def make_age_bucket_q(age_q: float):\n",
    "    return pd.cut(pd.Series([age_q]), bins=AGE_BINS_Q, labels=AGE_LABELS).iloc[0]\n",
    "\n",
    "\n",
    "def norm_cdf(x: float) -> float:\n",
    "    return 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
    "\n",
    "\n",
    "def one_factor_uniforms(n: int, rng: np.random.Generator, rho_mkt: float) -> np.ndarray:\n",
    "    rho_mkt = float(np.clip(rho_mkt, 0.0, 0.999))\n",
    "    Z = rng.standard_normal()\n",
    "    eps = rng.standard_normal(n)\n",
    "    X = np.sqrt(rho_mkt) * Z + np.sqrt(1.0 - rho_mkt) * eps\n",
    "    return np.array([norm_cdf(x) for x in X], dtype=float)\n",
    "\n",
    "\n",
    "def inv_norm(u: float) -> float:\n",
    "    try:\n",
    "        from scipy.special import erfinv\n",
    "        return sqrt(2.0) * float(erfinv(2.0 * u - 1.0))\n",
    "    except Exception:\n",
    "        u = float(np.clip(u, 1e-6, 1.0 - 1e-6))\n",
    "        return float(np.sign(u - 0.5) * np.sqrt(2.0) * np.sqrt(abs(np.log(1.0 - 2.0 * abs(u - 0.5)))))\n",
    "\n",
    "\n",
    "def lognormal_from_u(mu: float, sigma: float, u: float) -> float:\n",
    "    z = inv_norm(u)\n",
    "    return float(np.exp(mu + sigma * z))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Recallable ledger\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class RecallableBucket:\n",
    "    created_q: int\n",
    "    expiry_q: int\n",
    "    amount_remaining: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RecallableLedger:\n",
    "    rho: float\n",
    "    expiry_quarters: int\n",
    "    commitment: float\n",
    "    buckets: List[RecallableBucket] = field(default_factory=list)\n",
    "\n",
    "    def _rc_cap(self) -> float:\n",
    "        return max(float(self.rho), 0.0) * max(float(self.commitment), 0.0)\n",
    "\n",
    "    def drop_expired(self, q: int) -> None:\n",
    "        if int(self.expiry_quarters) <= 0:\n",
    "            self.buckets = []\n",
    "            return\n",
    "        self.buckets = [b for b in self.buckets if b.expiry_q >= q and b.amount_remaining > 0]\n",
    "\n",
    "    def available(self, q: int) -> float:\n",
    "        self.drop_expired(q)\n",
    "        return float(sum(b.amount_remaining for b in self.buckets))\n",
    "\n",
    "    def add_recallable(self, q: int, rc_amount: float, enforce_cap: bool = True) -> float:\n",
    "        self.drop_expired(q)\n",
    "        x = max(float(rc_amount or 0.0), 0.0)\n",
    "        if x <= 0.0 or int(self.expiry_quarters) <= 0:\n",
    "            return 0.0\n",
    "\n",
    "        add_amt = x\n",
    "        if enforce_cap:\n",
    "            cap = self._rc_cap()\n",
    "            cur = self.available(q)\n",
    "            room = max(cap - cur, 0.0)\n",
    "            add_amt = min(add_amt, room)\n",
    "\n",
    "        if add_amt <= 0.0:\n",
    "            return 0.0\n",
    "\n",
    "        self.buckets.append(RecallableBucket(\n",
    "            created_q=q,\n",
    "            expiry_q=q + int(self.expiry_quarters),\n",
    "            amount_remaining=float(add_amt)\n",
    "        ))\n",
    "        return float(add_amt)\n",
    "\n",
    "    def consume_for_drawdown(self, q: int, draw_amount: float) -> Dict[str, float]:\n",
    "        self.drop_expired(q)\n",
    "        need = max(float(draw_amount or 0.0), 0.0)\n",
    "        if need <= 0.0:\n",
    "            return {\"use_rc\": 0.0, \"use_commitment\": 0.0}\n",
    "\n",
    "        self.buckets.sort(key=lambda b: b.created_q)\n",
    "        use_rc = 0.0\n",
    "        for b in self.buckets:\n",
    "            if need <= 0:\n",
    "                break\n",
    "            take = min(b.amount_remaining, need)\n",
    "            b.amount_remaining -= take\n",
    "            need -= take\n",
    "            use_rc += take\n",
    "\n",
    "        self.buckets = [b for b in self.buckets if b.amount_remaining > 0]\n",
    "        use_commitment = max(float(draw_amount) - use_rc, 0.0)\n",
    "        return {\"use_rc\": float(use_rc), \"use_commitment\": float(use_commitment)}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Hazard model helpers\n",
    "# -----------------------------\n",
    "\n",
    "def _sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def build_feature_matrix(df: pd.DataFrame, include_nav: bool) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[\"Adj Strategy\"] = d[\"Adj Strategy\"].fillna(\"Unknown\")\n",
    "    d[\"Grade\"] = d[\"Grade\"].fillna(\"D\").astype(str).str.strip()\n",
    "\n",
    "    X = pd.DataFrame(index=d.index)\n",
    "    X[\"intercept\"] = 1.0\n",
    "    X[\"age_q\"] = d[\"age_q\"].astype(float)\n",
    "    X[\"age_q2\"] = (d[\"age_q\"].astype(float) ** 2)\n",
    "    if include_nav:\n",
    "        X[\"log_nav_prev\"] = d[\"log_nav_prev\"].astype(float)\n",
    "\n",
    "    strat_d = pd.get_dummies(d[\"Adj Strategy\"], prefix=\"strat\", drop_first=True)\n",
    "    grade_d = pd.get_dummies(d[\"Grade\"], prefix=\"grade\", drop_first=True)\n",
    "\n",
    "    X = pd.concat([X, strat_d, grade_d], axis=1)\n",
    "    return X\n",
    "\n",
    "\n",
    "def standardize_X(X: pd.DataFrame, cont_cols: list) -> Tuple[pd.DataFrame, dict, dict]:\n",
    "    means = {}\n",
    "    stds = {}\n",
    "    X = X.copy()\n",
    "    for c in cont_cols:\n",
    "        if c in X.columns:\n",
    "            mu = float(X[c].mean())\n",
    "            sd = float(X[c].std(ddof=1)) if len(X) > 1 else 1.0\n",
    "            if not np.isfinite(sd) or sd <= 0:\n",
    "                sd = 1.0\n",
    "            means[c] = mu\n",
    "            stds[c] = sd\n",
    "            X[c] = (X[c] - mu) / sd\n",
    "    return X, means, stds\n",
    "\n",
    "\n",
    "def apply_standardize(X: pd.DataFrame, means: dict, stds: dict) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    for c, mu in means.items():\n",
    "        if c in X.columns:\n",
    "            sd = stds.get(c, 1.0)\n",
    "            if not np.isfinite(sd) or sd <= 0:\n",
    "                sd = 1.0\n",
    "            X[c] = (X[c] - mu) / sd\n",
    "    return X\n",
    "\n",
    "\n",
    "def fit_logit(X: np.ndarray, y: np.ndarray, l2: float = LOGIT_L2, max_iter: int = LOGIT_MAX_ITER, tol: float = LOGIT_TOL) -> np.ndarray:\n",
    "    n, p = X.shape\n",
    "    beta = np.zeros(p, dtype=float)\n",
    "    I = np.eye(p)\n",
    "    for _ in range(max_iter):\n",
    "        z = X @ beta\n",
    "        p_hat = _sigmoid(z)\n",
    "        W = p_hat * (1.0 - p_hat)\n",
    "        W = np.clip(W, 1e-6, None)\n",
    "        z_adj = z + (y - p_hat) / W\n",
    "        XTW = X.T * W\n",
    "        A = XTW @ X + l2 * I\n",
    "        b = XTW @ z_adj\n",
    "        try:\n",
    "            beta_new = np.linalg.solve(A, b)\n",
    "        except Exception:\n",
    "            beta_new = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "        if np.linalg.norm(beta_new - beta) < tol:\n",
    "            beta = beta_new\n",
    "            break\n",
    "        beta = beta_new\n",
    "    return beta\n",
    "\n",
    "\n",
    "def build_feature_row(strategy: str, grade: str, age_q: int, log_nav_prev: float, include_nav: bool,\n",
    "                      cols: list, means: dict, stds: dict) -> np.ndarray:\n",
    "    row = {\n",
    "        \"Adj Strategy\": strategy,\n",
    "        \"Grade\": grade,\n",
    "        \"age_q\": float(age_q),\n",
    "        \"age_q2\": float(age_q) ** 2,\n",
    "        \"log_nav_prev\": float(log_nav_prev) if include_nav else 0.0,\n",
    "    }\n",
    "    df = pd.DataFrame([row])\n",
    "    X = build_feature_matrix(df, include_nav=include_nav)\n",
    "    X = X.reindex(columns=cols, fill_value=0.0)\n",
    "    X = apply_standardize(X, means, stds)\n",
    "    return X.to_numpy(dtype=float)\n",
    "\n",
    "\n",
    "def ks_test_normal(log_x: np.ndarray, alpha: float = KS_ALPHA) -> Tuple[float, bool]:\n",
    "    n = len(log_x)\n",
    "    if n < 2:\n",
    "        return float(\"nan\"), False\n",
    "    mu = float(np.mean(log_x))\n",
    "    sig = float(np.std(log_x, ddof=1)) if n > 1 else 0.0\n",
    "    if not np.isfinite(sig) or sig <= 0:\n",
    "        return float(\"nan\"), False\n",
    "\n",
    "    x = np.sort(log_x)\n",
    "    z = (x - mu) / (sig * np.sqrt(2.0))\n",
    "    try:\n",
    "        F = 0.5 * (1.0 + np.erf(z))\n",
    "    except Exception:\n",
    "        F = 0.5 * (1.0 + np.vectorize(erf)(z))\n",
    "    i = np.arange(1, n + 1)\n",
    "    d_plus = np.max(i / n - F)\n",
    "    d_minus = np.max(F - (i - 1) / n)\n",
    "    D = float(max(d_plus, d_minus))\n",
    "\n",
    "    dcrit = float(np.sqrt(-0.5 * np.log(alpha / 2.0) / n))\n",
    "    return D, bool(D <= dcrit)\n",
    "\n",
    "\n",
    "def fit_lognormal_stats(x: pd.Series, fund_ids: pd.Series) -> Dict[str, float]:\n",
    "    g = x.dropna()\n",
    "    g = g[g > 0]\n",
    "    n_obs = int(len(g))\n",
    "    if n_obs == 0:\n",
    "        return {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR,\n",
    "            \"n\": 0, \"n_funds\": 0,\n",
    "            \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "\n",
    "    n_funds = int(fund_ids.loc[g.index].nunique()) if fund_ids is not None else 0\n",
    "\n",
    "    lx = np.log(g.to_numpy(dtype=float))\n",
    "    mu = float(np.mean(lx))\n",
    "    sig = float(np.std(lx, ddof=1)) if n_obs > 1 else SIGMA_FLOOR\n",
    "    sig = float(np.clip(max(sig, SIGMA_FLOOR), SIGMA_FLOOR, SIGMA_CAP))\n",
    "\n",
    "    ks_D, ks_pass = (float(\"nan\"), False)\n",
    "    if n_obs >= MIN_LN_OBS and n_funds >= MIN_LN_FUNDS:\n",
    "        ks_D, ks_pass = ks_test_normal(lx, alpha=KS_ALPHA)\n",
    "\n",
    "    return {\n",
    "        \"mu\": mu, \"sig\": sig,\n",
    "        \"n\": n_obs, \"n_funds\": n_funds,\n",
    "        \"ks_D\": ks_D, \"ks_pass\": ks_pass,\n",
    "    }\n",
    "\n",
    "\n",
    "def _weight(n_obs: float, n_funds: float, ks_pass: bool) -> float:\n",
    "    if not ks_pass:\n",
    "        return 0.0\n",
    "    if n_obs is None or n_obs <= 0 or n_funds is None or n_funds <= 0:\n",
    "        return 0.0\n",
    "    w = (n_obs / (n_obs + SHRINK_N)) * (n_funds / (n_funds + SHRINK_FUNDS))\n",
    "    return float(np.clip(w, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _weight_h(n_obs: float, n_funds: float) -> float:\n",
    "    if n_obs is None or n_obs <= 0 or n_funds is None or n_funds <= 0:\n",
    "        return 0.0\n",
    "    w = (n_obs / (n_obs + SHRINK_N)) * (n_funds / (n_funds + SHRINK_FUNDS))\n",
    "    return float(np.clip(w, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _blend_p(p_c: float, n_c: float, nf_c: float, p_p: float) -> float:\n",
    "    w = _weight_h(n_c, nf_c)\n",
    "    return float(np.clip(w * float(p_c) + (1.0 - w) * float(p_p), 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _combine_p(p_sg, n_sg, nf_sg, p_sa, n_sa, nf_sa, p_s):\n",
    "    w_sg = _weight_h(n_sg, nf_sg)\n",
    "    w_sa = _weight_h(n_sa, nf_sa)\n",
    "    tot = w_sg + w_sa\n",
    "    if tot > 0:\n",
    "        p_mid = (w_sg * float(p_sg) + w_sa * float(p_sa)) / tot\n",
    "        return float(np.clip(tot * p_mid + (1.0 - tot) * float(p_s), 0.0, 1.0))\n",
    "    return float(np.clip(float(p_s), 0.0, 1.0))\n",
    "\n",
    "\n",
    "def _combine_mu_sig(mu_sg, sig_sg, n_sg, nf_sg, ks_sg,\n",
    "                    mu_sa, sig_sa, n_sa, nf_sa, ks_sa,\n",
    "                    mu_s, sig_s):\n",
    "    w_sg = _weight(n_sg, nf_sg, ks_sg)\n",
    "    w_sa = _weight(n_sa, nf_sa, ks_sa)\n",
    "    tot = w_sg + w_sa\n",
    "    if tot > 0:\n",
    "        mu_mid = (w_sg * float(mu_sg) + w_sa * float(mu_sa)) / tot\n",
    "        sig_mid = (w_sg * float(sig_sg) + w_sa * float(sig_sa)) / tot\n",
    "        mu = tot * mu_mid + (1.0 - tot) * float(mu_s)\n",
    "        sig = tot * sig_mid + (1.0 - tot) * float(sig_s)\n",
    "    else:\n",
    "        mu = float(mu_s)\n",
    "        sig = float(sig_s)\n",
    "    sig = float(np.clip(max(sig, SIGMA_FLOOR), SIGMA_FLOOR, SIGMA_CAP))\n",
    "    return mu, sig\n",
    "\n",
    "\n",
    "def _blend(mu_c, sig_c, n_c, nf_c, ks_c, mu_p, sig_p, n_p, nf_p, ks_p):\n",
    "    w = _weight(n_c, nf_c, ks_c)\n",
    "    mu = w * float(mu_c) + (1.0 - w) * float(mu_p)\n",
    "    sig = w * float(sig_c) + (1.0 - w) * float(sig_p)\n",
    "    sig = float(np.clip(max(sig, SIGMA_FLOOR), SIGMA_FLOOR, SIGMA_CAP))\n",
    "    return mu, sig\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MSCI model (simplified from msci_projection)\n",
    "# -----------------------------\n",
    "\n",
    "def load_msci_quarterly(msci_xlsx_path: str) -> pd.DataFrame:\n",
    "    msci = pd.read_excel(msci_xlsx_path)\n",
    "    if \"Date\" not in msci.columns or \"SCXP Index\" not in msci.columns:\n",
    "        raise ValueError(\"MSCI file must contain columns: 'Date' and 'SCXP Index'\")\n",
    "    msci = msci[[\"Date\", \"SCXP Index\"]].copy()\n",
    "    msci[\"Date\"] = pd.to_datetime(msci[\"Date\"], errors=\"coerce\")\n",
    "    msci[\"SCXP Index\"] = pd.to_numeric(msci[\"SCXP Index\"], errors=\"coerce\")\n",
    "    msci = msci.dropna(subset=[\"Date\", \"SCXP Index\"]).sort_values(\"Date\")\n",
    "    msci[\"quarter_end\"] = msci[\"Date\"].dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    q = (msci.groupby(\"quarter_end\", as_index=False)[\"SCXP Index\"]\n",
    "         .last()\n",
    "         .rename(columns={\"SCXP Index\": \"index_level\"})\n",
    "         .sort_values(\"quarter_end\")\n",
    "         .reset_index(drop=True))\n",
    "    q[\"msci_ret_q\"] = q[\"index_level\"].pct_change()\n",
    "    q = q.dropna(subset=[\"msci_ret_q\"]).reset_index(drop=True)\n",
    "    return q\n",
    "\n",
    "\n",
    "def label_regimes_by_quantiles(q_returns: pd.Series, low_q=0.33, high_q=0.67) -> pd.Series:\n",
    "    q_low = q_returns.quantile(low_q)\n",
    "    q_high = q_returns.quantile(high_q)\n",
    "    regime = pd.Series(index=q_returns.index, dtype=\"object\")\n",
    "    regime[q_returns <= q_low] = \"bear\"\n",
    "    regime[q_returns >= q_high] = \"bull\"\n",
    "    regime[(q_returns > q_low) & (q_returns < q_high)] = \"flat\"\n",
    "    return regime\n",
    "\n",
    "\n",
    "def estimate_transition_matrix(regimes: pd.Series, states=(\"bear\", \"flat\", \"bull\"), laplace=1.0) -> pd.DataFrame:\n",
    "    states = list(states)\n",
    "    counts = pd.DataFrame(0.0, index=states, columns=states)\n",
    "    r = regimes.dropna().tolist()\n",
    "    for a, b in zip(r[:-1], r[1:]):\n",
    "        if a in states and b in states:\n",
    "            counts.loc[a, b] += 1.0\n",
    "    counts = counts + laplace\n",
    "    P = counts.div(counts.sum(axis=1), axis=0)\n",
    "    return P\n",
    "\n",
    "\n",
    "def estimate_regime_params(df_q: pd.DataFrame, states=(\"bear\", \"flat\", \"bull\")) -> pd.DataFrame:\n",
    "    overall_sigma = float(df_q[\"msci_ret_q\"].std(ddof=1))\n",
    "    overall_sigma = max(overall_sigma, 1e-6)\n",
    "    out = []\n",
    "    for s in states:\n",
    "        sub = df_q.loc[df_q[\"regime\"] == s, \"msci_ret_q\"].dropna()\n",
    "        mu = float(sub.mean()) if len(sub) else 0.0\n",
    "        sigma = float(sub.std(ddof=1)) if len(sub) > 1 else overall_sigma\n",
    "        sigma = max(sigma, 1e-6)\n",
    "        out.append((s, mu, sigma))\n",
    "    return pd.DataFrame(out, columns=[\"regime\", \"mu_q\", \"sigma_q\"]).set_index(\"regime\")\n",
    "\n",
    "\n",
    "def apply_persistence_tilt(P: pd.DataFrame, scenario: str, k: float = 1.2) -> pd.DataFrame:\n",
    "    scenario = scenario.lower().strip()\n",
    "    if scenario not in {\"bullish\", \"neutral\", \"bearish\"}:\n",
    "        raise ValueError(\"scenario must be one of: bullish, neutral, bearish\")\n",
    "    if scenario == \"neutral\":\n",
    "        return P.copy()\n",
    "    target = \"bull\" if scenario == \"bullish\" else \"bear\"\n",
    "    P2 = P.copy()\n",
    "    for s in P2.index:\n",
    "        P2.loc[s, target] *= k\n",
    "    P2.loc[target, target] *= k\n",
    "    P2 = P2.div(P2.sum(axis=1), axis=0)\n",
    "    return P2\n",
    "\n",
    "\n",
    "def simulate_markov_regimes(P: pd.DataFrame, start_state: str, n_steps: int, rng: np.random.Generator) -> list:\n",
    "    states = list(P.index)\n",
    "    if start_state not in states:\n",
    "        start_state = \"flat\" if \"flat\" in states else states[0]\n",
    "    path = [start_state]\n",
    "    for _ in range(n_steps):\n",
    "        cur = path[-1]\n",
    "        probs = P.loc[cur].values.astype(float)\n",
    "        nxt = rng.choice(states, p=probs)\n",
    "        path.append(nxt)\n",
    "    return path[1:]\n",
    "\n",
    "\n",
    "def simulate_msci_path(df_q_hist: pd.DataFrame, start_qe: pd.Timestamp, n_quarters: int,\n",
    "                       scenario: str, tilt_strength: float, rng: np.random.Generator) -> pd.DataFrame:\n",
    "    df = df_q_hist.copy()\n",
    "    df[\"regime\"] = label_regimes_by_quantiles(df[\"msci_ret_q\"], low_q=0.33, high_q=0.67)\n",
    "    P = estimate_transition_matrix(df[\"regime\"], laplace=1.0)\n",
    "    params = estimate_regime_params(df)\n",
    "    P_tilted = apply_persistence_tilt(P, scenario=scenario, k=tilt_strength)\n",
    "    df_reg = df.loc[df[\"quarter_end\"] <= start_qe].dropna(subset=[\"regime\"])\n",
    "    start_regime = df_reg[\"regime\"].iloc[-1] if not df_reg.empty else \"flat\"\n",
    "    future_qe = quarter_range(add_quarters(start_qe, 1), add_quarters(start_qe, n_quarters))\n",
    "    regime_path = simulate_markov_regimes(P_tilted, start_regime, n_quarters, rng)\n",
    "    rows = []\n",
    "    for qe, s in zip(future_qe, regime_path):\n",
    "        mu = float(params.loc[s, \"mu_q\"])\n",
    "        sig = float(params.loc[s, \"sigma_q\"])\n",
    "        r = mu + sig * rng.standard_normal()\n",
    "        rows.append({\"quarter_end\": qe, \"msci_ret_q\": r, \"regime\": s})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Grade transitions (yearly)\n",
    "# -----------------------------\n",
    "\n",
    "def build_yearly_transition_from_data(df: pd.DataFrame, strategy: Optional[str] = None) -> Tuple[pd.DataFrame, pd.DataFrame, int]:\n",
    "    df = df.copy()\n",
    "    if strategy is not None:\n",
    "        df = df[df[\"Adj Strategy\"] == strategy].copy()\n",
    "    transitions = []\n",
    "    for _, g in df.groupby(\"FundID\"):\n",
    "        g = g.sort_values(\"quarter_end\")\n",
    "        grades = g[\"Grade\"].fillna(\"D\").astype(str).tolist()\n",
    "        if len(grades) < 5:\n",
    "            continue\n",
    "        yearly = grades[::4]\n",
    "        transitions.extend(list(zip(yearly[:-1], yearly[1:])))\n",
    "    if not transitions:\n",
    "        states = GRADE_STATES\n",
    "        counts = pd.DataFrame(1.0, index=states, columns=states)\n",
    "        probs = counts.div(counts.sum(axis=1), axis=0)\n",
    "        return counts, probs, 0\n",
    "\n",
    "    counts = pd.crosstab(\n",
    "        [a for a, _ in transitions],\n",
    "        [b for _, b in transitions]\n",
    "    ).reindex(index=GRADE_STATES, columns=GRADE_STATES, fill_value=0.0)\n",
    "    counts = counts + 1.0\n",
    "    probs = counts.div(counts.sum(axis=1), axis=0)\n",
    "    return counts, probs, len(transitions)\n",
    "\n",
    "\n",
    "def sample_next_grade(curr_grade: str, P_df: pd.DataFrame, rng: np.random.Generator) -> str:\n",
    "    if curr_grade not in GRADE_STATES:\n",
    "        curr_grade = \"D\"\n",
    "    row = P_df.loc[curr_grade].values.astype(float)\n",
    "    return str(rng.choice(GRADE_STATES, p=row))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Omega model (simplified NAV Logic)\n",
    "# -----------------------------\n",
    "\n",
    "def fit_ols_beta(y: np.ndarray, x: np.ndarray) -> Tuple[float, float, float]:\n",
    "    # x: n x 2 (r_t, r_{t-1})\n",
    "    X = np.column_stack([np.ones(len(y)), x])\n",
    "    try:\n",
    "        beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    except Exception:\n",
    "        beta = np.zeros(3, dtype=float)\n",
    "    return float(beta[0]), float(beta[1]), float(beta[2])\n",
    "\n",
    "\n",
    "def build_omega_models(cal: pd.DataFrame) -> Tuple[Dict[Tuple[str, str], Tuple[float, float, str]],\n",
    "                                                   Dict[Tuple[str, str, str], Tuple[float, str]],\n",
    "                                                   Dict[Tuple[str, str], Tuple[float, str]]]:\n",
    "    # Betas by (strategy, grade), fallback to strategy, then global\n",
    "    betas_sg = {}\n",
    "    betas_s = {}\n",
    "    betas_g = (0.0, 0.0, 0.0)\n",
    "\n",
    "    # Global\n",
    "    y = cal[\"omega\"].to_numpy(dtype=float)\n",
    "    x = cal[[\"msci_ret_q\", \"msci_ret_q_lag1\"]].to_numpy(dtype=float)\n",
    "    a_g, b0_g, b1_g = fit_ols_beta(y, x)\n",
    "    betas_g = (a_g, b0_g, b1_g)\n",
    "\n",
    "    # Strategy-level\n",
    "    for s, grp in cal.groupby(\"Adj Strategy\"):\n",
    "        y = grp[\"omega\"].to_numpy(dtype=float)\n",
    "        x = grp[[\"msci_ret_q\", \"msci_ret_q_lag1\"]].to_numpy(dtype=float)\n",
    "        a, b0, b1 = fit_ols_beta(y, x)\n",
    "        betas_s[s] = (a, b0, b1)\n",
    "\n",
    "    # Strategy+grade\n",
    "    for (s, g), grp in cal.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "        if len(grp) < 20:\n",
    "            continue\n",
    "        y = grp[\"omega\"].to_numpy(dtype=float)\n",
    "        x = grp[[\"msci_ret_q\", \"msci_ret_q_lag1\"]].to_numpy(dtype=float)\n",
    "        a, b0, b1 = fit_ols_beta(y, x)\n",
    "        betas_sg[(s, g)] = (a, b0, b1)\n",
    "\n",
    "    # Alpha by (strategy, grade, age_bucket)\n",
    "    alpha_sga = {}\n",
    "    alpha_sg = {}\n",
    "    alpha_s = {}\n",
    "\n",
    "    cal2 = cal.copy()\n",
    "    # Use best available betas to compute omega_adj\n",
    "    def get_betas(strategy: str, grade: str) -> Tuple[float, float, float]:\n",
    "        if (strategy, grade) in betas_sg:\n",
    "            return betas_sg[(strategy, grade)]\n",
    "        if strategy in betas_s:\n",
    "            return betas_s[strategy]\n",
    "        return betas_g\n",
    "\n",
    "    b0_list = []\n",
    "    b1_list = []\n",
    "    for _, r in cal2.iterrows():\n",
    "        a, b0, b1 = get_betas(r[\"Adj Strategy\"], r[\"Grade\"])\n",
    "        b0_list.append(b0)\n",
    "        b1_list.append(b1)\n",
    "    cal2[\"b0_used\"] = b0_list\n",
    "    cal2[\"b1_used\"] = b1_list\n",
    "    cal2[\"omega_adj\"] = cal2[\"omega\"] - cal2[\"b0_used\"] * cal2[\"msci_ret_q\"] - cal2[\"b1_used\"] * cal2[\"msci_ret_q_lag1\"]\n",
    "\n",
    "    for (s, g, a), grp in cal2.groupby([\"Adj Strategy\", \"Grade\", \"AgeBucket\"]):\n",
    "        if len(grp) < 10:\n",
    "            continue\n",
    "        alpha_sga[(s, g, a)] = (float(grp[\"omega_adj\"].mean()), \"sga\")\n",
    "\n",
    "    for (s, g), grp in cal2.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "        if len(grp) < 10:\n",
    "            continue\n",
    "        alpha_sg[(s, g)] = (float(grp[\"omega_adj\"].mean()), \"sg\")\n",
    "\n",
    "    for s, grp in cal2.groupby([\"Adj Strategy\"]):\n",
    "        alpha_s[s] = (float(grp[\"omega_adj\"].mean()), \"s\")\n",
    "\n",
    "    alpha_g = (float(cal2[\"omega_adj\"].mean()), \"g\")\n",
    "\n",
    "    # Sigma by (strategy, grade)\n",
    "    sigma_sg = {}\n",
    "    sigma_s = {}\n",
    "\n",
    "    cal2[\"omega_resid\"] = cal2[\"omega_adj\"] - cal2.groupby([\"Adj Strategy\", \"Grade\"])[\"omega_adj\"].transform(\"mean\")\n",
    "\n",
    "    for (s, g), grp in cal2.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "        if len(grp) < 20:\n",
    "            continue\n",
    "        sig = float(grp[\"omega_resid\"].std(ddof=1))\n",
    "        if not np.isfinite(sig) or sig <= 0:\n",
    "            continue\n",
    "        sigma_sg[(s, g)] = (sig, \"sg\")\n",
    "\n",
    "    for s, grp in cal2.groupby([\"Adj Strategy\"]):\n",
    "        sig = float(grp[\"omega_adj\"].std(ddof=1))\n",
    "        if np.isfinite(sig) and sig > 0:\n",
    "            sigma_s[s] = (sig, \"s\")\n",
    "\n",
    "    sigma_g = float(cal2[\"omega_adj\"].std(ddof=1))\n",
    "    if not np.isfinite(sigma_g) or sigma_g <= 0:\n",
    "        sigma_g = 0.05\n",
    "    sigma_g = (sigma_g, \"g\")\n",
    "\n",
    "    def get_alpha(strategy: str, grade: str, age_bucket: str) -> Tuple[float, str]:\n",
    "        k = (strategy, grade, age_bucket)\n",
    "        if k in alpha_sga:\n",
    "            return alpha_sga[k]\n",
    "        k2 = (strategy, grade)\n",
    "        if k2 in alpha_sg:\n",
    "            return alpha_sg[k2]\n",
    "        if strategy in alpha_s:\n",
    "            return alpha_s[strategy]\n",
    "        return alpha_g\n",
    "\n",
    "    def get_sigma(strategy: str, grade: str) -> Tuple[float, str]:\n",
    "        k = (strategy, grade)\n",
    "        if k in sigma_sg:\n",
    "            return sigma_sg[k]\n",
    "        if strategy in sigma_s:\n",
    "            return sigma_s[strategy]\n",
    "        return sigma_g\n",
    "\n",
    "    return get_betas, get_alpha, get_sigma\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main backtest\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    t0 = time.perf_counter()\n",
    "    year = int(input(\"Enter year (e.g. 2025): \").strip())\n",
    "    quarter = input(\"Enter quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "    train_year = int(input(\"Train end year (e.g. 2018): \").strip())\n",
    "    train_quarter = input(\"Train end quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "    test_year = input(\"Test end year (blank => max in data): \").strip()\n",
    "    test_quarter = \"\"\n",
    "    if test_year:\n",
    "        test_year = int(test_year)\n",
    "        test_quarter = input(\"Test end quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "    n_sims = int(input(\"MC simulations [500]: \").strip() or \"500\")\n",
    "    seed = int(input(\"Random seed [1234]: \").strip() or \"1234\")\n",
    "    rho_event = float(input(\"Copula correlation events rho_event [0.25]: \").strip() or \"0.25\")\n",
    "    rho_size = float(input(\"Copula correlation sizes rho_size [0.15]: \").strip() or \"0.15\")\n",
    "    scenario_uncond = input(\"Unconditional scenario (bullish/neutral/bearish) [neutral]: \").strip().lower() or \"neutral\"\n",
    "    tilt_strength = float(input(\"Unconditional tilt strength [1.2]: \").strip() or \"1.2\")\n",
    "\n",
    "    rho_event = float(np.clip(rho_event, 0.0, 0.999))\n",
    "    rho_size = float(np.clip(rho_size, 0.0, 0.999))\n",
    "\n",
    "    BASE_DIR = os.environ.get(\n",
    "        \"EQUITY_BASE_DIR\",\n",
    "        os.path.join(\"C:\", \"Users\", os.environ.get(\"USERNAME\", \"\"), \"Documents\", \"Equity\")\n",
    "    )\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        BASE_DIR = os.path.abspath(os.getcwd())\n",
    "\n",
    "    HOME = os.path.join(BASE_DIR, f\"{year}_{quarter}\")\n",
    "    DATA_DIR = os.path.join(HOME, \"data\")\n",
    "\n",
    "    data_path_parquet = os.path.join(DATA_DIR, \"data.parquet\")\n",
    "    data_path_csv = os.path.join(DATA_DIR, \"data.csv\")\n",
    "    kmp_path_parquet = os.path.join(DATA_DIR, \"kmp.parquet\")\n",
    "    kmp_path_csv = os.path.join(DATA_DIR, \"kmp.csv\")\n",
    "\n",
    "    if os.path.exists(data_path_parquet):\n",
    "        data = pd.read_parquet(data_path_parquet)\n",
    "    elif os.path.exists(data_path_csv):\n",
    "        data = pd.read_csv(data_path_csv)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Missing data.parquet or data.csv in {DATA_DIR}\")\n",
    "\n",
    "    if os.path.exists(kmp_path_parquet):\n",
    "        kmp = pd.read_parquet(kmp_path_parquet)\n",
    "    elif os.path.exists(kmp_path_csv):\n",
    "        kmp = pd.read_csv(kmp_path_csv)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Missing kmp.parquet or kmp.csv\")\n",
    "\n",
    "    # normalize column names (trim/collapse spaces) to avoid hidden KeyErrors\n",
    "    def _norm_col(c):\n",
    "        if not isinstance(c, str):\n",
    "            return c\n",
    "        return \" \".join(c.strip().split())\n",
    "\n",
    "    data.columns = [_norm_col(c) for c in data.columns]\n",
    "    kmp.columns = [_norm_col(c) for c in kmp.columns]\n",
    "\n",
    "    req = [\n",
    "        \"FundID\", \"Adj Strategy\", \"Grade\", \"Fund_Age_Quarters\",\n",
    "        \"Year of Transaction Date\", \"Quarter of Transaction Date\",\n",
    "        \"Adj Drawdown EUR\", \"Adj Repayment EUR\",\n",
    "        \"NAV Adjusted EUR\", \"Recallable\",\n",
    "        \"Planned end date with add. years as per legal doc\",\n",
    "    ]\n",
    "    missing = [c for c in req if c not in data.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in data: {missing}\")\n",
    "\n",
    "    # Commitment column aliases (some datasets use different naming)\n",
    "    def _norm_key(s: str) -> str:\n",
    "        return \" \".join(s.strip().lower().replace(\"_\", \" \").split())\n",
    "\n",
    "    col_by_key = {_norm_key(c): c for c in data.columns if isinstance(c, str)}\n",
    "\n",
    "    commit_level_col = None\n",
    "    commit_flow_col = None\n",
    "    for c in [\"Commitment_Level\", \"Commitment Level\", \"commitment level\"]:\n",
    "        key = _norm_key(c)\n",
    "        if key in col_by_key:\n",
    "            commit_level_col = col_by_key[key]\n",
    "            break\n",
    "    for c in [\"Commitment EUR\", \"Commitment\", \"commitment eur\", \"commitment\"]:\n",
    "        key = _norm_key(c)\n",
    "        if key in col_by_key:\n",
    "            commit_flow_col = col_by_key[key]\n",
    "            break\n",
    "    if commit_level_col is None and commit_flow_col is None:\n",
    "        raise ValueError(\"Missing commitment column: expected one of Commitment_Level / Commitment Level / Commitment EUR / Commitment\")\n",
    "\n",
    "    # Clean numeric\n",
    "    num_cols = [\"Adj Drawdown EUR\", \"Adj Repayment EUR\", \"NAV Adjusted EUR\", \"Recallable\", \"Fund_Age_Quarters\"]\n",
    "    if commit_level_col is not None:\n",
    "        num_cols.append(commit_level_col)\n",
    "    if commit_flow_col is not None:\n",
    "        num_cols.append(commit_flow_col)\n",
    "    for c in num_cols:\n",
    "        data[c] = pd.to_numeric(data[c], errors=\"coerce\")\n",
    "\n",
    "    data[\"Adj Drawdown EUR\"] = data[\"Adj Drawdown EUR\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"Adj Repayment EUR\"] = data[\"Adj Repayment EUR\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"Recallable\"] = data[\"Recallable\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"NAV Adjusted EUR\"] = data[\"NAV Adjusted EUR\"].fillna(0.0).clip(lower=0.0)\n",
    "    data[\"Fund_Age_Quarters\"] = data[\"Fund_Age_Quarters\"].fillna(0.0)\n",
    "\n",
    "    q_year = pd.to_numeric(data[\"Year of Transaction Date\"], errors=\"coerce\")\n",
    "    q_qtr = pd.to_numeric(data[\"Quarter of Transaction Date\"], errors=\"coerce\")\n",
    "    if q_year.isna().any() or q_qtr.isna().any():\n",
    "        raise ValueError(\"Year/Quarter of Transaction Date contains non-numeric values.\")\n",
    "\n",
    "    data[\"quarter_end\"] = pd.PeriodIndex(\n",
    "        q_year.astype(\"int64\").astype(str) + \"Q\" + q_qtr.astype(\"int64\").astype(str),\n",
    "        freq=\"Q\"\n",
    "    ).to_timestamp(\"Q\")\n",
    "    data = data.sort_values([\"FundID\", \"quarter_end\"]).reset_index(drop=True)\n",
    "\n",
    "    # First closing date (age baseline) if available; fallback to first observed quarter_end\n",
    "    first_close_col = None\n",
    "    for key, col in col_by_key.items():\n",
    "        if \"first closing\" in key:\n",
    "            first_close_col = col\n",
    "            break\n",
    "    if first_close_col is not None:\n",
    "        data[\"first_close_qe\"] = pd.to_datetime(data[first_close_col], errors=\"coerce\").dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "    else:\n",
    "        data[\"first_close_qe\"] = pd.NaT\n",
    "    fc_map = data.groupby(\"FundID\")[\"first_close_qe\"].min()\n",
    "    fallback_fc = data.groupby(\"FundID\")[\"quarter_end\"].min()\n",
    "    fc_map = fc_map.fillna(fallback_fc)\n",
    "    data[\"first_close_qe\"] = data[\"FundID\"].map(fc_map)\n",
    "    # Age in quarters since first close (Q2 for vintage handled upstream in data prep)\n",
    "    p_qe = pd.PeriodIndex(data[\"quarter_end\"], freq=\"Q\")\n",
    "    p_fc = pd.PeriodIndex(data[\"first_close_qe\"], freq=\"Q\")\n",
    "    data[\"age_q_fc\"] = (p_qe.astype(\"int64\") - p_fc.astype(\"int64\")).astype(int)\n",
    "    data.loc[data[\"age_q_fc\"] < 0, \"age_q_fc\"] = 0\n",
    "    data[\"age_q_model\"] = pd.to_numeric(data[\"age_q_fc\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    train_end_qe = quarter_end_from_year_quarter(train_year, train_quarter)\n",
    "    test_start_qe = add_quarters(train_end_qe, 1)\n",
    "\n",
    "    if test_year:\n",
    "        test_end_qe = quarter_end_from_year_quarter(test_year, test_quarter)\n",
    "    else:\n",
    "        test_end_qe = data[\"quarter_end\"].max()\n",
    "\n",
    "    if test_end_qe < test_start_qe:\n",
    "        raise ValueError(\"Test end is before test start. Check dates.\")\n",
    "\n",
    "    test_quarters = quarter_range(test_start_qe, test_end_qe)\n",
    "    if not test_quarters:\n",
    "        raise ValueError(\"No test quarters found. Check dates.\")\n",
    "\n",
    "    # MSCI data\n",
    "    msci_path = os.path.join(DATA_DIR, \"msci.xlsx\")\n",
    "    if not os.path.exists(msci_path):\n",
    "        msci_path = os.path.join(DATA_DIR, \"MSCI.xlsx\")\n",
    "    if not os.path.exists(msci_path):\n",
    "        raise FileNotFoundError(\"Missing msci.xlsx / MSCI.xlsx in DATA_DIR\")\n",
    "\n",
    "    msci_q = load_msci_quarterly(msci_path)\n",
    "    msci_q = msci_q.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "    msci_q[\"msci_ret_q_lag1\"] = msci_q[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "    # Train/test splits (initial)\n",
    "    train = data[data[\"quarter_end\"] <= train_end_qe].copy()\n",
    "    test = data[data[\"quarter_end\"] >= test_start_qe].copy()\n",
    "\n",
    "    if train.empty or test.empty:\n",
    "        raise ValueError(\"Train or test split is empty. Adjust dates.\")\n",
    "\n",
    "    # Commitment proxy (full history)\n",
    "    if commit_level_col is not None:\n",
    "        data[\"Commitment_Level\"] = data[commit_level_col].fillna(0.0)\n",
    "    else:\n",
    "        data[\"Commitment_Level\"] = data.groupby(\"FundID\")[commit_flow_col].cumsum().fillna(0.0)\n",
    "    fund_commit = data.groupby(\"FundID\")[\"Commitment_Level\"].max().fillna(0.0).to_dict()\n",
    "    # Refresh train/test to include Commitment_Level\n",
    "    train = data[data[\"quarter_end\"] <= train_end_qe].copy()\n",
    "    test = data[data[\"quarter_end\"] >= test_start_qe].copy()\n",
    "    if train.empty or test.empty:\n",
    "        raise ValueError(\"Train or test split is empty after commitment prep. Adjust dates.\")\n",
    "\n",
    "    # Funds in test window\n",
    "    test_funds = test[\"FundID\"].unique().tolist()\n",
    "\n",
    "    # Planned end date (cap)\n",
    "    data[\"planned_end_qe\"] = pd.to_datetime(\n",
    "        data[\"Planned end date with add. years as per legal doc\"],\n",
    "        errors=\"coerce\"\n",
    "    ).dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "\n",
    "    cap_by_fund = (data.dropna(subset=[\"planned_end_qe\"])\n",
    "                   .sort_values([\"FundID\", \"planned_end_qe\"])\n",
    "                   .groupby(\"FundID\")[\"planned_end_qe\"].last().to_dict())\n",
    "\n",
    "    # Age buckets\n",
    "    data[\"AgeBucket\"] = pd.cut(data[\"age_q_model\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "    if \"AgeBucket\" not in train.columns:\n",
    "        train[\"AgeBucket\"] = pd.cut(train[\"age_q_model\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "    if \"AgeBucket\" not in test.columns:\n",
    "        test[\"AgeBucket\"] = pd.cut(test[\"age_q_model\"], bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "\n",
    "    # Build MSCI lookup for conditional path\n",
    "    msci_map = msci_q.set_index(\"quarter_end\")[\"msci_ret_q\"].to_dict()\n",
    "    msci_lag_map = msci_q.set_index(\"quarter_end\")[\"msci_ret_q_lag1\"].to_dict()\n",
    "    msci_hist = msci_q[msci_q[\"quarter_end\"] <= train_end_qe].copy()\n",
    "    msci_mu_all = float(msci_hist[\"msci_ret_q\"].mean()) if len(msci_hist) else 0.0\n",
    "    msci_sigma_all = float(msci_hist[\"msci_ret_q\"].std(ddof=1)) if len(msci_hist) > 1 else 1.0\n",
    "    msci_sigma_all = max(msci_sigma_all, 1e-6)\n",
    "\n",
    "    # Ensure MSCI covers test quarters for conditional\n",
    "    for qe in test_quarters:\n",
    "        if qe not in msci_map:\n",
    "            raise ValueError(f\"Missing MSCI return for quarter {qe} in MSCI file.\")\n",
    "\n",
    "    # =============================\n",
    "    # Calibrate omega model on train\n",
    "    # =============================\n",
    "    train = train.copy()\n",
    "    train[\"nav_prev\"] = train.groupby(\"FundID\")[\"NAV Adjusted EUR\"].shift(1)\n",
    "    train[\"flow_net\"] = train[\"Adj Drawdown EUR\"] - train[\"Adj Repayment EUR\"]\n",
    "    m = train[\"nav_prev\"].fillna(0.0) > 0\n",
    "    train[\"omega\"] = np.nan\n",
    "    train.loc[m, \"omega\"] = ((train.loc[m, \"NAV Adjusted EUR\"] - train.loc[m, \"nav_prev\"]) - train.loc[m, \"flow_net\"]) / train.loc[m, \"nav_prev\"]\n",
    "    train[\"omega\"] = train[\"omega\"].clip(lower=-OMEGA_CLIP, upper=OMEGA_CLIP)\n",
    "\n",
    "    # attach MSCI to train\n",
    "    train[\"msci_ret_q\"] = train[\"quarter_end\"].map(msci_map)\n",
    "    train[\"msci_ret_q_lag1\"] = train[\"quarter_end\"].map(msci_lag_map)\n",
    "\n",
    "    cal = train.dropna(subset=[\"omega\", \"msci_ret_q\", \"msci_ret_q_lag1\"]).copy()\n",
    "    cal[\"AgeBucket\"] = cal[\"AgeBucket\"].astype(str)\n",
    "    if cal.empty:\n",
    "        raise ValueError(\"No omega calibration data after filtering.\")\n",
    "\n",
    "    get_betas, get_alpha, get_sigma = build_omega_models(cal)\n",
    "\n",
    "    # =============================\n",
    "    # Calibrate cashflow model on train\n",
    "    # =============================\n",
    "    # investment period calibration by strategy\n",
    "    ip_by_strategy = {}\n",
    "    df_ip = train[(train[\"Adj Drawdown EUR\"] > 0) & train[\"Adj Strategy\"].notna() & train[\"age_q_model\"].notna()].copy()\n",
    "    if len(df_ip):\n",
    "        df_ip[\"age_q\"] = pd.to_numeric(df_ip[\"age_q_model\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "        df_ip = df_ip[df_ip[\"age_q\"].notna() & (df_ip[\"age_q\"] >= 0)]\n",
    "        for strat, g in df_ip.groupby(\"Adj Strategy\", dropna=False):\n",
    "            s = g.groupby(\"age_q\")[\"Adj Drawdown EUR\"].sum().sort_index()\n",
    "            total = float(s.sum())\n",
    "            if total <= 0:\n",
    "                continue\n",
    "            cum = s.cumsum()\n",
    "            thr = IP_CUM_PCTL * total\n",
    "            ip_q = int(cum.index[cum.values >= thr][0])\n",
    "            ip_q = int(np.clip(ip_q, IP_Q_MIN, IP_Q_MAX))\n",
    "            ip_by_strategy[strat] = ip_q\n",
    "\n",
    "    # hazard dataset\n",
    "    haz = train.copy()\n",
    "    haz[\"age_q\"] = pd.to_numeric(haz[\"age_q_model\"], errors=\"coerce\").round()\n",
    "    haz = haz[haz[\"age_q\"].notna()].copy()\n",
    "    haz[\"age_q\"] = haz[\"age_q\"].astype(int)\n",
    "    haz[\"log_nav_prev\"] = np.log1p(haz[\"nav_prev\"].abs().fillna(0.0))\n",
    "    haz[\"ip_q\"] = haz[\"Adj Strategy\"].map(ip_by_strategy).fillna(IP_Q_DEFAULT).astype(int)\n",
    "    draw_haz = haz.copy()\n",
    "    if ENFORCE_IP_LIMITS:\n",
    "        draw_haz = haz[haz[\"age_q\"] <= haz[\"ip_q\"]].copy()\n",
    "\n",
    "    X_draw = build_feature_matrix(draw_haz, include_nav=False)\n",
    "    X_rep = build_feature_matrix(haz, include_nav=True)\n",
    "\n",
    "    cont_draw = [\"age_q\", \"age_q2\"]\n",
    "    cont_rep = [\"age_q\", \"age_q2\", \"log_nav_prev\"]\n",
    "\n",
    "    X_draw, draw_means, draw_stds = standardize_X(X_draw, cont_draw)\n",
    "    X_rep, rep_means, rep_stds = standardize_X(X_rep, cont_rep)\n",
    "\n",
    "    Y_draw = (draw_haz[\"Adj Drawdown EUR\"] > 0).astype(int).to_numpy(dtype=float)\n",
    "    Y_rep = (haz[\"Adj Repayment EUR\"] > 0).astype(int).to_numpy(dtype=float)\n",
    "\n",
    "    beta_draw = None\n",
    "    beta_rep = None\n",
    "    try:\n",
    "        if USE_HAZARD_MODELS and len(X_draw) and len(Y_draw):\n",
    "            beta_draw = fit_logit(X_draw.to_numpy(), Y_draw)\n",
    "        if USE_HAZARD_MODELS and len(X_rep) and len(Y_rep):\n",
    "            beta_rep = fit_logit(X_rep.to_numpy(), Y_rep)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: hazard model fit failed, falling back to group means:\", e)\n",
    "        beta_draw = None\n",
    "        beta_rep = None\n",
    "\n",
    "    hazard_meta = {\n",
    "        \"draw_cols\": list(X_draw.columns),\n",
    "        \"rep_cols\": list(X_rep.columns),\n",
    "        \"draw_means\": draw_means, \"draw_stds\": draw_stds,\n",
    "        \"rep_means\": rep_means, \"rep_stds\": rep_stds,\n",
    "    }\n",
    "\n",
    "    # cap proxy for draw ratios\n",
    "    if \"Commitment_Level\" not in train.columns:\n",
    "        if commit_level_col is not None and commit_level_col in train.columns:\n",
    "            train[\"Commitment_Level\"] = train[commit_level_col].fillna(0.0)\n",
    "        elif commit_flow_col is not None and commit_flow_col in train.columns:\n",
    "            train[\"Commitment_Level\"] = train.groupby(\"FundID\")[commit_flow_col].cumsum().fillna(0.0)\n",
    "        else:\n",
    "            raise ValueError(\"Commitment_Level missing in train and no usable commitment column found.\")\n",
    "    train[\"cap_proxy\"] = train[\"Commitment_Level\"].fillna(0.0)\n",
    "    train[\"draw_event\"] = (train[\"Adj Drawdown EUR\"] > 0).astype(int)\n",
    "    train[\"rep_event\"] = (train[\"Adj Repayment EUR\"] > 0).astype(int)\n",
    "\n",
    "    train[\"draw_ratio\"] = np.where(train[\"cap_proxy\"] > CAP_EPS, train[\"Adj Drawdown EUR\"] / train[\"cap_proxy\"], np.nan)\n",
    "    train.loc[train[\"draw_ratio\"] <= 0, \"draw_ratio\"] = np.nan\n",
    "\n",
    "    train[\"rep_ratio\"] = np.where(train[\"nav_prev\"] > NAV_EPS, train[\"Adj Repayment EUR\"] / train[\"nav_prev\"], np.nan)\n",
    "    train.loc[train[\"rep_ratio\"] <= 0, \"rep_ratio\"] = np.nan\n",
    "\n",
    "    train[\"rc_given_rep_event\"] = ((train[\"Adj Repayment EUR\"] > 0) & (train[\"Recallable\"] > 0)).astype(int)\n",
    "    train[\"rc_ratio_given_rep\"] = np.where(train[\"Adj Repayment EUR\"] > 0, train[\"Recallable\"] / train[\"Adj Repayment EUR\"], np.nan)\n",
    "    train.loc[train[\"rc_ratio_given_rep\"] <= 0, \"rc_ratio_given_rep\"] = np.nan\n",
    "\n",
    "    # Calibration tables\n",
    "    group_keys = [\"Adj Strategy\", \"Grade\", \"AgeBucket\"]\n",
    "    rows = []\n",
    "    for (s, g, a), grp in train.groupby(group_keys, dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows.append({\n",
    "            \"Adj Strategy\": s, \"Grade\": g, \"AgeBucket\": a,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal = pd.DataFrame(rows)\n",
    "\n",
    "    # strategy fallback\n",
    "    rows_s = []\n",
    "    for s, grp in train.groupby([\"Adj Strategy\"], dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows_s.append({\n",
    "            \"Adj Strategy\": s,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal_s = pd.DataFrame(rows_s)\n",
    "\n",
    "    # strategy + grade fallback\n",
    "    rows_sg = []\n",
    "    for (s, g), grp in train.groupby([\"Adj Strategy\", \"Grade\"], dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows_sg.append({\n",
    "            \"Adj Strategy\": s, \"Grade\": g,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal_sg = pd.DataFrame(rows_sg)\n",
    "\n",
    "    # strategy + age fallback\n",
    "    rows_sa = []\n",
    "    for (s, a), grp in train.groupby([\"Adj Strategy\", \"AgeBucket\"], dropna=False):\n",
    "        p_draw = float(grp[\"draw_event\"].mean()) if len(grp) else 0.0\n",
    "        p_rep = float(grp[\"rep_event\"].mean()) if len(grp) else 0.0\n",
    "        rep_q = grp[grp[\"Adj Repayment EUR\"] > 0]\n",
    "        p_rc_given_rep = float(rep_q[\"rc_given_rep_event\"].mean()) if len(rep_q) else 0.0\n",
    "        stats_d = fit_lognormal_stats(grp[\"draw_ratio\"], grp[\"FundID\"])\n",
    "        stats_r = fit_lognormal_stats(grp[\"rep_ratio\"], grp[\"FundID\"])\n",
    "        stats_c = fit_lognormal_stats(rep_q[\"rc_ratio_given_rep\"], rep_q[\"FundID\"]) if len(rep_q) else {\n",
    "            \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "        }\n",
    "        rows_sa.append({\n",
    "            \"Adj Strategy\": s, \"AgeBucket\": a,\n",
    "            \"p_draw\": p_draw, \"p_rep\": p_rep, \"p_rc_given_rep\": p_rc_given_rep,\n",
    "            \"mu_draw\": stats_d[\"mu\"], \"sig_draw\": stats_d[\"sig\"],\n",
    "            \"n_draw\": stats_d[\"n\"], \"n_funds_draw\": stats_d[\"n_funds\"], \"ks_draw\": stats_d[\"ks_D\"], \"ks_pass_draw\": stats_d[\"ks_pass\"],\n",
    "            \"mu_rep\": stats_r[\"mu\"], \"sig_rep\": stats_r[\"sig\"],\n",
    "            \"n_rep\": stats_r[\"n\"], \"n_funds_rep\": stats_r[\"n_funds\"], \"ks_rep\": stats_r[\"ks_D\"], \"ks_pass_rep\": stats_r[\"ks_pass\"],\n",
    "            \"mu_rc\": stats_c[\"mu\"], \"sig_rc\": stats_c[\"sig\"],\n",
    "            \"n_rc\": stats_c[\"n\"], \"n_funds_rc\": stats_c[\"n_funds\"], \"ks_rc\": stats_c[\"ks_D\"], \"ks_pass_rc\": stats_c[\"ks_pass\"],\n",
    "            \"n_obs\": int(len(grp)), \"n_funds\": int(grp[\"FundID\"].nunique())\n",
    "        })\n",
    "    cal_sa = pd.DataFrame(rows_sa)\n",
    "\n",
    "    global_p_draw = float(train[\"draw_event\"].mean())\n",
    "    global_p_rep = float(train[\"rep_event\"].mean())\n",
    "    rep_all = train[train[\"Adj Repayment EUR\"] > 0]\n",
    "    global_p_rc_given_rep = float(rep_all[\"rc_given_rep_event\"].mean()) if len(rep_all) else 0.0\n",
    "\n",
    "    stats_g_draw = fit_lognormal_stats(train[\"draw_ratio\"], train[\"FundID\"])\n",
    "    stats_g_rep = fit_lognormal_stats(train[\"rep_ratio\"], train[\"FundID\"])\n",
    "    stats_g_rc = fit_lognormal_stats(rep_all[\"rc_ratio_given_rep\"], rep_all[\"FundID\"]) if len(rep_all) else {\n",
    "        \"mu\": 0.0, \"sig\": SIGMA_FLOOR, \"n\": 0, \"n_funds\": 0, \"ks_D\": float(\"nan\"), \"ks_pass\": False,\n",
    "    }\n",
    "\n",
    "    def lookup_params(strategy, grade, age_bucket) -> Dict[str, float]:\n",
    "        m = (cal[\"Adj Strategy\"].eq(strategy)) & (cal[\"Grade\"].eq(grade)) & (cal[\"AgeBucket\"].eq(age_bucket))\n",
    "        child = cal[m].iloc[0].to_dict() if m.any() else {}\n",
    "\n",
    "        ss = cal_s[cal_s[\"Adj Strategy\"].eq(strategy)]\n",
    "        parent_s = ss.iloc[0].to_dict() if len(ss) else {}\n",
    "\n",
    "        ssg = cal_sg[(cal_sg[\"Adj Strategy\"].eq(strategy)) & (cal_sg[\"Grade\"].eq(grade))]\n",
    "        parent_sg = ssg.iloc[0].to_dict() if len(ssg) else {}\n",
    "\n",
    "        ssa = cal_sa[(cal_sa[\"Adj Strategy\"].eq(strategy)) & (cal_sa[\"AgeBucket\"].eq(age_bucket))]\n",
    "        parent_sa = ssa.iloc[0].to_dict() if len(ssa) else {}\n",
    "\n",
    "        p_s = float(np.clip(parent_s.get(\"p_draw\", global_p_draw), 0.0, 1.0))\n",
    "        p_sg = float(np.clip(parent_sg.get(\"p_draw\", p_s), 0.0, 1.0))\n",
    "        p_sa = float(np.clip(parent_sa.get(\"p_draw\", p_s), 0.0, 1.0))\n",
    "        p_draw_parent = _combine_p(p_sg, parent_sg.get(\"n_obs\", 0), parent_sg.get(\"n_funds\", 0),\n",
    "                                   p_sa, parent_sa.get(\"n_obs\", 0), parent_sa.get(\"n_funds\", 0), p_s)\n",
    "        p_draw = _blend_p(child.get(\"p_draw\", p_draw_parent), child.get(\"n_obs\", 0), child.get(\"n_funds\", 0), p_draw_parent)\n",
    "\n",
    "        p_s = float(np.clip(parent_s.get(\"p_rep\", global_p_rep), 0.0, 1.0))\n",
    "        p_sg = float(np.clip(parent_sg.get(\"p_rep\", p_s), 0.0, 1.0))\n",
    "        p_sa = float(np.clip(parent_sa.get(\"p_rep\", p_s), 0.0, 1.0))\n",
    "        p_rep_parent = _combine_p(p_sg, parent_sg.get(\"n_obs\", 0), parent_sg.get(\"n_funds\", 0),\n",
    "                                  p_sa, parent_sa.get(\"n_obs\", 0), parent_sa.get(\"n_funds\", 0), p_s)\n",
    "        p_rep = _blend_p(child.get(\"p_rep\", p_rep_parent), child.get(\"n_obs\", 0), child.get(\"n_funds\", 0), p_rep_parent)\n",
    "\n",
    "        p_s = float(np.clip(parent_s.get(\"p_rc_given_rep\", global_p_rc_given_rep), 0.0, 1.0))\n",
    "        p_sg = float(np.clip(parent_sg.get(\"p_rc_given_rep\", p_s), 0.0, 1.0))\n",
    "        p_sa = float(np.clip(parent_sa.get(\"p_rc_given_rep\", p_s), 0.0, 1.0))\n",
    "        p_rc_parent = _combine_p(p_sg, parent_sg.get(\"n_rep\", 0), parent_sg.get(\"n_funds_rep\", 0),\n",
    "                                 p_sa, parent_sa.get(\"n_rep\", 0), parent_sa.get(\"n_funds_rep\", 0), p_s)\n",
    "        p_rc = _blend_p(child.get(\"p_rc_given_rep\", p_rc_parent), child.get(\"n_rep\", 0), child.get(\"n_funds_rep\", 0), p_rc_parent)\n",
    "\n",
    "        mu_draw_s, sig_draw_s = _blend(\n",
    "            parent_s.get(\"mu_draw\", stats_g_draw[\"mu\"]), parent_s.get(\"sig_draw\", stats_g_draw[\"sig\"]),\n",
    "            parent_s.get(\"n_draw\", 0), parent_s.get(\"n_funds_draw\", 0), parent_s.get(\"ks_pass_draw\", False),\n",
    "            stats_g_draw[\"mu\"], stats_g_draw[\"sig\"], stats_g_draw[\"n\"], stats_g_draw[\"n_funds\"], stats_g_draw[\"ks_pass\"]\n",
    "        )\n",
    "        mu_rep_s, sig_rep_s = _blend(\n",
    "            parent_s.get(\"mu_rep\", stats_g_rep[\"mu\"]), parent_s.get(\"sig_rep\", stats_g_rep[\"sig\"]),\n",
    "            parent_s.get(\"n_rep\", 0), parent_s.get(\"n_funds_rep\", 0), parent_s.get(\"ks_pass_rep\", False),\n",
    "            stats_g_rep[\"mu\"], stats_g_rep[\"sig\"], stats_g_rep[\"n\"], stats_g_rep[\"n_funds\"], stats_g_rep[\"ks_pass\"]\n",
    "        )\n",
    "        mu_rc_s, sig_rc_s = _blend(\n",
    "            parent_s.get(\"mu_rc\", stats_g_rc[\"mu\"]), parent_s.get(\"sig_rc\", stats_g_rc[\"sig\"]),\n",
    "            parent_s.get(\"n_rc\", 0), parent_s.get(\"n_funds_rc\", 0), parent_s.get(\"ks_pass_rc\", False),\n",
    "            stats_g_rc[\"mu\"], stats_g_rc[\"sig\"], stats_g_rc[\"n\"], stats_g_rc[\"n_funds\"], stats_g_rc[\"ks_pass\"]\n",
    "        )\n",
    "\n",
    "        mu_draw_sg, sig_draw_sg = _blend(\n",
    "            parent_sg.get(\"mu_draw\", mu_draw_s), parent_sg.get(\"sig_draw\", sig_draw_s),\n",
    "            parent_sg.get(\"n_draw\", 0), parent_sg.get(\"n_funds_draw\", 0), parent_sg.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_s, sig_draw_s, parent_s.get(\"n_draw\", 0), parent_s.get(\"n_funds_draw\", 0), parent_s.get(\"ks_pass_draw\", False)\n",
    "        )\n",
    "        mu_rep_sg, sig_rep_sg = _blend(\n",
    "            parent_sg.get(\"mu_rep\", mu_rep_s), parent_sg.get(\"sig_rep\", sig_rep_s),\n",
    "            parent_sg.get(\"n_rep\", 0), parent_sg.get(\"n_funds_rep\", 0), parent_sg.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_s, sig_rep_s, parent_s.get(\"n_rep\", 0), parent_s.get(\"n_funds_rep\", 0), parent_s.get(\"ks_pass_rep\", False)\n",
    "        )\n",
    "        mu_rc_sg, sig_rc_sg = _blend(\n",
    "            parent_sg.get(\"mu_rc\", mu_rc_s), parent_sg.get(\"sig_rc\", sig_rc_s),\n",
    "            parent_sg.get(\"n_rc\", 0), parent_sg.get(\"n_funds_rc\", 0), parent_sg.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_s, sig_rc_s, parent_s.get(\"n_rc\", 0), parent_s.get(\"n_funds_rc\", 0), parent_s.get(\"ks_pass_rc\", False)\n",
    "        )\n",
    "\n",
    "        mu_draw_sa, sig_draw_sa = _blend(\n",
    "            parent_sa.get(\"mu_draw\", mu_draw_s), parent_sa.get(\"sig_draw\", sig_draw_s),\n",
    "            parent_sa.get(\"n_draw\", 0), parent_sa.get(\"n_funds_draw\", 0), parent_sa.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_s, sig_draw_s, parent_s.get(\"n_draw\", 0), parent_s.get(\"n_funds_draw\", 0), parent_s.get(\"ks_pass_draw\", False)\n",
    "        )\n",
    "        mu_rep_sa, sig_rep_sa = _blend(\n",
    "            parent_sa.get(\"mu_rep\", mu_rep_s), parent_sa.get(\"sig_rep\", sig_rep_s),\n",
    "            parent_sa.get(\"n_rep\", 0), parent_sa.get(\"n_funds_rep\", 0), parent_sa.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_s, sig_rep_s, parent_s.get(\"n_rep\", 0), parent_s.get(\"n_funds_rep\", 0), parent_s.get(\"ks_pass_rep\", False)\n",
    "        )\n",
    "        mu_rc_sa, sig_rc_sa = _blend(\n",
    "            parent_sa.get(\"mu_rc\", mu_rc_s), parent_sa.get(\"sig_rc\", sig_rc_s),\n",
    "            parent_sa.get(\"n_rc\", 0), parent_sa.get(\"n_funds_rc\", 0), parent_sa.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_s, sig_rc_s, parent_s.get(\"n_rc\", 0), parent_s.get(\"n_funds_rc\", 0), parent_s.get(\"ks_pass_rc\", False)\n",
    "        )\n",
    "\n",
    "        mu_draw_p, sig_draw_p = _combine_mu_sig(\n",
    "            mu_draw_sg, sig_draw_sg, parent_sg.get(\"n_draw\", 0), parent_sg.get(\"n_funds_draw\", 0), parent_sg.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_sa, sig_draw_sa, parent_sa.get(\"n_draw\", 0), parent_sa.get(\"n_funds_draw\", 0), parent_sa.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_s, sig_draw_s\n",
    "        )\n",
    "        mu_rep_p, sig_rep_p = _combine_mu_sig(\n",
    "            mu_rep_sg, sig_rep_sg, parent_sg.get(\"n_rep\", 0), parent_sg.get(\"n_funds_rep\", 0), parent_sg.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_sa, sig_rep_sa, parent_sa.get(\"n_rep\", 0), parent_sa.get(\"n_funds_rep\", 0), parent_sa.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_s, sig_rep_s\n",
    "        )\n",
    "        mu_rc_p, sig_rc_p = _combine_mu_sig(\n",
    "            mu_rc_sg, sig_rc_sg, parent_sg.get(\"n_rc\", 0), parent_sg.get(\"n_funds_rc\", 0), parent_sg.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_sa, sig_rc_sa, parent_sa.get(\"n_rc\", 0), parent_sa.get(\"n_funds_rc\", 0), parent_sa.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_s, sig_rc_s\n",
    "        )\n",
    "\n",
    "        mu_draw, sig_draw = _blend(\n",
    "            child.get(\"mu_draw\", mu_draw_p), child.get(\"sig_draw\", sig_draw_p),\n",
    "            child.get(\"n_draw\", 0), child.get(\"n_funds_draw\", 0), child.get(\"ks_pass_draw\", False),\n",
    "            mu_draw_p, sig_draw_p, 0, 0, True\n",
    "        )\n",
    "        mu_rep, sig_rep = _blend(\n",
    "            child.get(\"mu_rep\", mu_rep_p), child.get(\"sig_rep\", sig_rep_p),\n",
    "            child.get(\"n_rep\", 0), child.get(\"n_funds_rep\", 0), child.get(\"ks_pass_rep\", False),\n",
    "            mu_rep_p, sig_rep_p, 0, 0, True\n",
    "        )\n",
    "        mu_rc, sig_rc = _blend(\n",
    "            child.get(\"mu_rc\", mu_rc_p), child.get(\"sig_rc\", sig_rc_p),\n",
    "            child.get(\"n_rc\", 0), child.get(\"n_funds_rc\", 0), child.get(\"ks_pass_rc\", False),\n",
    "            mu_rc_p, sig_rc_p, 0, 0, True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"p_draw\": p_draw,\n",
    "            \"p_rep\": p_rep,\n",
    "            \"p_rc_given_rep\": p_rc,\n",
    "            \"mu_draw\": float(mu_draw), \"sig_draw\": float(sig_draw),\n",
    "            \"mu_rep\": float(mu_rep), \"sig_rep\": float(sig_rep),\n",
    "            \"mu_rc\": float(mu_rc), \"sig_rc\": float(sig_rc),\n",
    "        }\n",
    "\n",
    "    # =============================\n",
    "    # Drawdown scaling calibration (censored funds, by strategy+grade)\n",
    "    # =============================\n",
    "    draw_scale_sg = {}\n",
    "    draw_scale_s = {}\n",
    "    draw_scale_g = 1.0\n",
    "\n",
    "    def build_cum_draw_obs(df: pd.DataFrame, fund_commit: dict) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for fid, g in df.groupby(\"FundID\"):\n",
    "            C = float(fund_commit.get(fid, 0.0) or 0.0)\n",
    "            if not np.isfinite(C) or C <= 0:\n",
    "                continue\n",
    "            g2 = g.sort_values(\"age_q_fc\")\n",
    "            g2 = (g2.groupby(\"age_q_fc\", as_index=False)\n",
    "                    .agg(draw=(\"Adj Drawdown EUR\", \"sum\"),\n",
    "                         **{\"Adj Strategy\": (\"Adj Strategy\", \"last\"),\n",
    "                            \"Grade\": (\"Grade\", \"last\")}))\n",
    "            g2[\"cum_draw\"] = g2[\"draw\"].cumsum()\n",
    "            g2[\"ratio\"] = g2[\"cum_draw\"] / C\n",
    "            g2[\"Adj Strategy\"] = g2[\"Adj Strategy\"].fillna(\"Unknown\")\n",
    "            g2[\"Grade\"] = g2[\"Grade\"].fillna(\"D\").astype(str).str.strip()\n",
    "            g2[\"FundID\"] = fid\n",
    "            rows.append(g2[[\"FundID\", \"Adj Strategy\", \"Grade\", \"age_q_fc\", \"ratio\"]])\n",
    "        if not rows:\n",
    "            return pd.DataFrame(columns=[\"FundID\", \"Adj Strategy\", \"Grade\", \"age_q_fc\", \"ratio\"])\n",
    "        return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    def expected_draw_increment(strategy: str, grade: str, age_q: int) -> float:\n",
    "        age_bucket = make_age_bucket_q(age_q)\n",
    "        ip_q = int(ip_by_strategy.get(strategy, IP_Q_DEFAULT))\n",
    "        draw_mult = 1.0\n",
    "        if USE_DRAW_AGE_SHAPE and ip_q > 0:\n",
    "            if ENFORCE_IP_LIMITS and age_q > ip_q:\n",
    "                draw_mult = 0.0\n",
    "            else:\n",
    "                frac = float(age_q) / float(ip_q)\n",
    "                draw_mult = max(DRAW_AGE_MIN_MULT, (1.0 - frac) ** DRAW_AGE_DECAY_POWER)\n",
    "\n",
    "        params = lookup_params(strategy, grade, age_bucket)\n",
    "        if USE_HAZARD_MODELS and beta_draw is not None:\n",
    "            Xr = build_feature_row(strategy, grade, age_q, 0.0, False,\n",
    "                                   hazard_meta[\"draw_cols\"], hazard_meta[\"draw_means\"], hazard_meta[\"draw_stds\"])\n",
    "            p_draw_base = float(_sigmoid(Xr @ beta_draw)[0])\n",
    "        else:\n",
    "            p_draw_base = float(params.get(\"p_draw\", 0.0))\n",
    "\n",
    "        grade_key = grade if grade in GRADE_DRAW_P_MULT else \"D\"\n",
    "        p_draw_adj = p_draw_base * draw_mult * float(GRADE_DRAW_P_MULT.get(grade_key, 1.0))\n",
    "        p_draw_adj = min(p_draw_adj, 1.0)\n",
    "\n",
    "        mu = float(params.get(\"mu_draw\", 0.0))\n",
    "        sig = float(params.get(\"sig_draw\", SIGMA_FLOOR))\n",
    "        mean_ratio = float(np.exp(mu + 0.5 * sig * sig))\n",
    "        mean_ratio = min(mean_ratio * float(GRADE_DRAW_SIZE_MULT.get(grade_key, 1.0)), 1.0)\n",
    "        return float(p_draw_adj * mean_ratio)\n",
    "\n",
    "    def baseline_curve(strategy: str, grade: str, ages: List[int]) -> np.ndarray:\n",
    "        ages_sorted = sorted(set(int(a) for a in ages))\n",
    "        out = []\n",
    "        cum = 0.0\n",
    "        for a in ages_sorted:\n",
    "            cum += expected_draw_increment(strategy, grade, a)\n",
    "            out.append(cum)\n",
    "        return np.array(out, dtype=float), ages_sorted\n",
    "\n",
    "    def fit_scale_for_group(grp: pd.DataFrame, target_col: str) -> Tuple[float, float]:\n",
    "        ages = grp[\"age_q_fc\"].astype(int).tolist()\n",
    "        base, ages_sorted = baseline_curve(grp[\"Adj Strategy\"].iloc[0], grp[\"Grade\"].iloc[0], ages)\n",
    "        g2 = grp.set_index(\"age_q_fc\").loc[ages_sorted]\n",
    "        target = g2[target_col].to_numpy(dtype=float)\n",
    "        weights = g2[\"n_funds\"].to_numpy(dtype=float)\n",
    "        denom = float(np.sum(weights * base * base))\n",
    "        if denom <= 0:\n",
    "            return 1.0, float(\"inf\")\n",
    "        scale_raw = float(np.sum(weights * target * base) / denom)\n",
    "        n_funds = float(g2[\"n_funds\"].max())\n",
    "        w_shrink = n_funds / (n_funds + SHRINK_FUNDS)\n",
    "        scale = 1.0 + w_shrink * (scale_raw - 1.0)\n",
    "        sse = float(np.sum(weights * (scale * base - target) ** 2))\n",
    "        return max(scale, 0.0), sse\n",
    "\n",
    "    if USE_DRAWDOWN_CALIBRATION:\n",
    "        obs = build_cum_draw_obs(train, fund_commit)\n",
    "        if len(obs):\n",
    "            curves_sg = (obs.groupby([\"Adj Strategy\", \"Grade\", \"age_q_fc\"])\n",
    "                            .agg(mean_ratio=(\"ratio\", \"mean\"),\n",
    "                                 median_ratio=(\"ratio\", \"median\"),\n",
    "                                 n_funds=(\"FundID\", \"nunique\"))\n",
    "                            .reset_index())\n",
    "            curves_s = (obs.groupby([\"Adj Strategy\", \"age_q_fc\"])\n",
    "                           .agg(mean_ratio=(\"ratio\", \"mean\"),\n",
    "                                median_ratio=(\"ratio\", \"median\"),\n",
    "                                n_funds=(\"FundID\", \"nunique\"))\n",
    "                           .reset_index())\n",
    "            # strategy+grade\n",
    "            for (s, g), grp in curves_sg.groupby([\"Adj Strategy\", \"Grade\"]):\n",
    "                g2 = grp[grp[\"n_funds\"] >= DRAW_CALIB_MIN_FUNDS]\n",
    "                if len(g2) < DRAW_CALIB_MIN_AGES:\n",
    "                    continue\n",
    "                scale_mean, sse_mean = fit_scale_for_group(g2, \"mean_ratio\")\n",
    "                scale_med, sse_med = fit_scale_for_group(g2, \"median_ratio\")\n",
    "                if DRAW_CALIB_TARGET == \"mean\":\n",
    "                    draw_scale_sg[(s, g)] = scale_mean\n",
    "                elif DRAW_CALIB_TARGET == \"median\":\n",
    "                    draw_scale_sg[(s, g)] = scale_med\n",
    "                else:\n",
    "                    draw_scale_sg[(s, g)] = scale_mean if sse_mean <= sse_med else scale_med\n",
    "\n",
    "            # strategy fallback: weighted average of grade-level scales\n",
    "            for s, grp in curves_sg.groupby([\"Adj Strategy\"]):\n",
    "                scales = []\n",
    "                for g in grp[\"Grade\"].unique():\n",
    "                    key = (s, g)\n",
    "                    if key in draw_scale_sg:\n",
    "                        n_funds = float(grp[grp[\"Grade\"] == g][\"n_funds\"].max())\n",
    "                        scales.append((draw_scale_sg[key], n_funds))\n",
    "                if scales:\n",
    "                    wsum = sum(w for _, w in scales)\n",
    "                    if wsum > 0:\n",
    "                        draw_scale_s[s] = sum(scale * w for scale, w in scales) / wsum\n",
    "\n",
    "            # global fallback: weighted average of strategy scales\n",
    "            if draw_scale_s:\n",
    "                wsum = 0.0\n",
    "                tot = 0.0\n",
    "                for s, scale in draw_scale_s.items():\n",
    "                    n_funds = float(curves_s[curves_s[\"Adj Strategy\"] == s][\"n_funds\"].max())\n",
    "                    if not np.isfinite(n_funds) or n_funds <= 0:\n",
    "                        continue\n",
    "                    wsum += n_funds\n",
    "                    tot += scale * n_funds\n",
    "                if wsum > 0:\n",
    "                    draw_scale_g = tot / wsum\n",
    "\n",
    "            print(f\"Drawdown calibration: sg_scales={len(draw_scale_sg)}, \"\n",
    "                  f\"s_scales={len(draw_scale_s)}, global_scale={round(draw_scale_g, 4)} \"\n",
    "                  f\"(target={DRAW_CALIB_TARGET})\")\n",
    "\n",
    "    # Runoff calibration\n",
    "    runoff_mult_by_strategy = {}\n",
    "    if USE_RUNOFF_CALIBRATION:\n",
    "        tail = train[train[\"AgeBucket\"].isin([\"15-20y\", \"20y+\"])].copy()\n",
    "        mid = train[train[\"AgeBucket\"].isin([\"6-8y\", \"8-10y\", \"10-15y\"])].copy()\n",
    "        for s in train[\"Adj Strategy\"].dropna().unique():\n",
    "            t = tail[tail[\"Adj Strategy\"] == s]\n",
    "            m = mid[mid[\"Adj Strategy\"] == s]\n",
    "            if len(t) and len(m) and t[\"rep_ratio\"].notna().any() and m[\"rep_ratio\"].notna().any():\n",
    "                num = t[\"rep_ratio\"].mean()\n",
    "                den = m[\"rep_ratio\"].mean()\n",
    "                if den > 0:\n",
    "                    runoff_mult_by_strategy[s] = float(np.clip(num / den, RUNOFF_MULT_MIN, RUNOFF_MULT_MAX))\n",
    "\n",
    "    # =============================\n",
    "    # Recallable soft limits\n",
    "    # =============================\n",
    "    kmp_needed = [\"FundID\", \"Recallable_Percentage_Decimal\", \"Expiration_Quarters\"]\n",
    "    missing_k = [c for c in kmp_needed if c not in kmp.columns]\n",
    "    if missing_k:\n",
    "        raise ValueError(f\"Missing columns in kmp: {missing_k}\")\n",
    "\n",
    "    kmp2 = kmp[kmp_needed].copy()\n",
    "    kmp2[\"Recallable_Percentage_Decimal\"] = pd.to_numeric(kmp2[\"Recallable_Percentage_Decimal\"], errors=\"coerce\")\n",
    "    kmp2[\"Expiration_Quarters\"] = pd.to_numeric(kmp2[\"Expiration_Quarters\"], errors=\"coerce\")\n",
    "    kmp2 = kmp2.set_index(\"FundID\")\n",
    "\n",
    "    tmp_rho = (\n",
    "        data.groupby(\"FundID\", as_index=False)\n",
    "        .agg(sum_rc=(\"Recallable\", \"sum\"), C_last=(\"Commitment_Level\", \"max\"))\n",
    "    )\n",
    "    tmp_rho[\"rho_emp\"] = np.where(tmp_rho[\"C_last\"] > 0, tmp_rho[\"sum_rc\"] / tmp_rho[\"C_last\"], np.nan)\n",
    "    rho_emp = tmp_rho.set_index(\"FundID\")[\"rho_emp\"].to_dict()\n",
    "\n",
    "    def soft_params(strategy: str) -> Tuple[float, int]:\n",
    "        s = data[data[\"Adj Strategy\"].eq(strategy)]\n",
    "        if len(s):\n",
    "            rho = float(np.nanquantile(s[\"Recallable\"].fillna(0.0), SOFT_RHO_PCTL))\n",
    "            rho = float(np.clip(rho, 0.0, 0.9))\n",
    "        else:\n",
    "            rho = 0.0\n",
    "        return rho, SOFT_EXPIRY_FALLBACK\n",
    "\n",
    "    def get_rho_E(fid: str, strategy: str) -> Tuple[float, int]:\n",
    "        if fid in kmp2.index:\n",
    "            r = kmp2.loc[fid]\n",
    "            rho = float(r.get(\"Recallable_Percentage_Decimal\", np.nan))\n",
    "            E = int(r.get(\"Expiration_Quarters\", np.nan)) if pd.notna(r.get(\"Expiration_Quarters\", np.nan)) else SOFT_EXPIRY_FALLBACK\n",
    "            if not np.isfinite(rho):\n",
    "                rho = rho_emp.get(fid, np.nan)\n",
    "            if not np.isfinite(rho):\n",
    "                rho, _ = soft_params(strategy)\n",
    "            return float(np.clip(rho, 0.0, 0.9)), int(E)\n",
    "        rho = rho_emp.get(fid, np.nan)\n",
    "        if not np.isfinite(rho):\n",
    "            rho, E = soft_params(strategy)\n",
    "        else:\n",
    "            _, E = soft_params(strategy)\n",
    "        return float(np.clip(rho, 0.0, 0.9)), int(E)\n",
    "\n",
    "    # =============================\n",
    "    # Build initial states at test start\n",
    "    # =============================\n",
    "    fund_states = {}\n",
    "    fund_start_qe = {}\n",
    "    fund_bucket = {}\n",
    "\n",
    "    # Build transition matrices\n",
    "    all_counts, all_probs, all_n = build_yearly_transition_from_data(train, strategy=None)\n",
    "    strat_probs = {}\n",
    "    strat_n = {}\n",
    "    for s in train[\"Adj Strategy\"].dropna().unique():\n",
    "        _, probs_s, n_s = build_yearly_transition_from_data(train, strategy=s)\n",
    "        strat_probs[s] = probs_s\n",
    "        strat_n[s] = n_s\n",
    "\n",
    "    def get_transition_matrix(strategy: str) -> pd.DataFrame:\n",
    "        if strategy in strat_probs and strat_n.get(strategy, 0) >= 30:\n",
    "            return strat_probs[strategy]\n",
    "        return all_probs\n",
    "\n",
    "    # Pre-build actual fund history for replay\n",
    "    data_by_fund = {fid: g.copy() for fid, g in data.groupby(\"FundID\")}\n",
    "\n",
    "    for fid in test_funds:\n",
    "        hist = data_by_fund.get(fid)\n",
    "        if hist is None or hist.empty:\n",
    "            continue\n",
    "        hist = hist.sort_values(\"quarter_end\")\n",
    "        hist_pre = hist[hist[\"quarter_end\"] <= train_end_qe]\n",
    "        if hist_pre.empty:\n",
    "            continue\n",
    "\n",
    "        last = hist_pre.iloc[-1]\n",
    "        strategy = str(last.get(\"Adj Strategy\") or \"Unknown\")\n",
    "        grade0 = str(last.get(\"Grade\") or \"D\").strip()\n",
    "        if grade0 not in GRADE_STATES:\n",
    "            grade0 = \"D\"\n",
    "        age0 = int(round(float(last.get(\"age_q_model\") or 0.0)))\n",
    "        nav0 = float(last.get(\"NAV Adjusted EUR\") or 0.0)\n",
    "\n",
    "        fund_start_qe[fid] = hist[\"quarter_end\"].iloc[0]\n",
    "        start_qe = fund_start_qe[fid]\n",
    "\n",
    "        # replay history to reconstruct DD_commit and recallables\n",
    "        C = float(fund_commit.get(fid, 0.0) or 0.0)\n",
    "        rho, E = get_rho_E(fid, strategy)\n",
    "        ledger = RecallableLedger(rho=rho, expiry_quarters=E, commitment=C)\n",
    "        dd_cum_commit = 0.0\n",
    "\n",
    "        for _, row in hist_pre.iterrows():\n",
    "            qe = row[\"quarter_end\"]\n",
    "            step = quarter_diff(qe, start_qe)\n",
    "            draw = float(row.get(\"Adj Drawdown EUR\") or 0.0)\n",
    "            rep = float(row.get(\"Adj Repayment EUR\") or 0.0)\n",
    "            rc = float(row.get(\"Recallable\") or 0.0)\n",
    "            if rep > 0 and rc > 0:\n",
    "                ledger.add_recallable(step, rc, enforce_cap=True)\n",
    "            if draw > 0:\n",
    "                cons = ledger.consume_for_drawdown(step, draw)\n",
    "                dd_cum_commit += cons[\"use_commitment\"]\n",
    "\n",
    "        # bucket (based on start grade/age)\n",
    "        age_bucket0 = make_age_bucket_q(age0)\n",
    "        bucket_key = (strategy, grade0, str(age_bucket0))\n",
    "        fund_bucket[fid] = bucket_key\n",
    "\n",
    "        fund_states[fid] = {\n",
    "            \"strategy\": strategy,\n",
    "            \"grade\": grade0,\n",
    "            \"age0\": age0,\n",
    "            \"nav\": nav0,\n",
    "            \"dd_commit\": dd_cum_commit,\n",
    "            \"ledger\": ledger,\n",
    "            \"commitment\": C,\n",
    "            \"cap_qe\": cap_by_fund.get(fid, pd.NaT),\n",
    "        }\n",
    "\n",
    "    # bucket index mapping\n",
    "    bucket_keys = sorted(set(fund_bucket.values()))\n",
    "    bucket_index = {b: i for i, b in enumerate(bucket_keys)}\n",
    "\n",
    "    # =============================\n",
    "    # Actual portfolio series (test)\n",
    "    # =============================\n",
    "    T = len(test_quarters)\n",
    "    B = len(bucket_keys)\n",
    "\n",
    "    actual_draw = np.zeros(T)\n",
    "    actual_rep = np.zeros(T)\n",
    "    actual_nav = np.zeros(T)\n",
    "\n",
    "    actual_draw_b = np.zeros((T, B))\n",
    "    actual_rep_b = np.zeros((T, B))\n",
    "    actual_nav_b = np.zeros((T, B))\n",
    "\n",
    "    # Build per-fund actual grid\n",
    "    for fid in fund_states.keys():\n",
    "        hist = data_by_fund[fid].copy().sort_values(\"quarter_end\")\n",
    "        # collapse any duplicate quarter_end rows before aligning to grid\n",
    "        hist_q = (hist.groupby(\"quarter_end\", as_index=True)\n",
    "                  .agg({\n",
    "                      \"Adj Drawdown EUR\": \"sum\",\n",
    "                      \"Adj Repayment EUR\": \"sum\",\n",
    "                      \"NAV Adjusted EUR\": \"last\",\n",
    "                  }))\n",
    "        # grid for test quarters\n",
    "        grid = pd.DataFrame(index=pd.Index(test_quarters, name=\"quarter_end\"))\n",
    "        grid[\"Draw\"] = hist_q[\"Adj Drawdown EUR\"]\n",
    "        grid[\"Rep\"] = hist_q[\"Adj Repayment EUR\"]\n",
    "        grid[\"NAV\"] = hist_q[\"NAV Adjusted EUR\"]\n",
    "\n",
    "        # Fill missing: Draw/Rep = 0, NAV = ffill from last known (including pre-test)\n",
    "        grid[\"Draw\"] = grid[\"Draw\"].fillna(0.0)\n",
    "        grid[\"Rep\"] = grid[\"Rep\"].fillna(0.0)\n",
    "\n",
    "        # seed NAV from last known before test start\n",
    "        nav_seed = hist_q.loc[hist_q.index <= train_end_qe, \"NAV Adjusted EUR\"]\n",
    "        nav_seed = float(nav_seed.iloc[-1]) if len(nav_seed) else 0.0\n",
    "        grid[\"NAV\"] = grid[\"NAV\"].ffill().fillna(nav_seed)\n",
    "\n",
    "        bkey = fund_bucket[fid]\n",
    "        bidx = bucket_index[bkey]\n",
    "\n",
    "        actual_draw += grid[\"Draw\"].to_numpy(dtype=float)\n",
    "        actual_rep += grid[\"Rep\"].to_numpy(dtype=float)\n",
    "        actual_nav += grid[\"NAV\"].to_numpy(dtype=float)\n",
    "\n",
    "        actual_draw_b[:, bidx] += grid[\"Draw\"].to_numpy(dtype=float)\n",
    "        actual_rep_b[:, bidx] += grid[\"Rep\"].to_numpy(dtype=float)\n",
    "        actual_nav_b[:, bidx] += grid[\"NAV\"].to_numpy(dtype=float)\n",
    "\n",
    "    # =============================\n",
    "    # Simulation runner\n",
    "    # =============================\n",
    "\n",
    "    def run_backtest(scenario: str, conditional: bool) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        sim_draw = np.zeros((n_sims, T))\n",
    "        sim_rep = np.zeros((n_sims, T))\n",
    "        sim_nav = np.zeros((n_sims, T))\n",
    "\n",
    "        sim_draw_b = np.zeros((n_sims, T, B))\n",
    "        sim_rep_b = np.zeros((n_sims, T, B))\n",
    "        sim_nav_b = np.zeros((n_sims, T, B))\n",
    "\n",
    "        fund_ids = list(fund_states.keys())\n",
    "        n_funds = len(fund_ids)\n",
    "        fund_index = {fid: i for i, fid in enumerate(fund_ids)}\n",
    "\n",
    "        for s in range(n_sims):\n",
    "            rng = np.random.default_rng(seed + s)\n",
    "\n",
    "            # MSCI path\n",
    "            if conditional:\n",
    "                msci_path = pd.DataFrame({\"quarter_end\": test_quarters,\n",
    "                                          \"msci_ret_q\": [msci_map[qe] for qe in test_quarters]})\n",
    "            else:\n",
    "                msci_path = simulate_msci_path(msci_q[msci_q[\"quarter_end\"] <= train_end_qe],\n",
    "                                               start_qe=train_end_qe,\n",
    "                                               n_quarters=T,\n",
    "                                               scenario=scenario,\n",
    "                                               tilt_strength=tilt_strength,\n",
    "                                               rng=rng)\n",
    "\n",
    "            msci_path = msci_path.set_index(\"quarter_end\")\n",
    "\n",
    "            # Prepare per-quarter copula uniforms\n",
    "            U_by_q = {}\n",
    "            for qe in test_quarters:\n",
    "                U_by_q[qe] = {\n",
    "                    \"draw_event\": one_factor_uniforms(n_funds, rng, rho_event),\n",
    "                    \"draw_size\": one_factor_uniforms(n_funds, rng, rho_size),\n",
    "                    \"rep_event\": one_factor_uniforms(n_funds, rng, rho_event),\n",
    "                    \"rep_size\": one_factor_uniforms(n_funds, rng, rho_size),\n",
    "                    \"rc_event\": one_factor_uniforms(n_funds, rng, rho_event),\n",
    "                    \"rc_size\": one_factor_uniforms(n_funds, rng, rho_size),\n",
    "                }\n",
    "\n",
    "            # initialize fund states for this sim\n",
    "            sim_state = {}\n",
    "            for fid in fund_ids:\n",
    "                st0 = fund_states[fid]\n",
    "                sim_state[fid] = {\n",
    "                    \"strategy\": st0[\"strategy\"],\n",
    "                    \"grade\": st0[\"grade\"],\n",
    "                    \"age0\": st0[\"age0\"],\n",
    "                    \"nav\": float(st0[\"nav\"]),\n",
    "                    \"dd_commit\": float(st0[\"dd_commit\"]),\n",
    "                    \"ip_catchup_done\": False,\n",
    "                    \"ledger\": RecallableLedger(\n",
    "                        rho=st0[\"ledger\"].rho,\n",
    "                        expiry_quarters=st0[\"ledger\"].expiry_quarters,\n",
    "                        commitment=st0[\"ledger\"].commitment,\n",
    "                        buckets=[RecallableBucket(b.created_q, b.expiry_q, b.amount_remaining) for b in st0[\"ledger\"].buckets]\n",
    "                    ),\n",
    "                    \"commitment\": float(st0[\"commitment\"]),\n",
    "                    \"cap_qe\": st0[\"cap_qe\"],\n",
    "                    \"alive\": True,\n",
    "                }\n",
    "\n",
    "            for t_idx, qe in enumerate(test_quarters):\n",
    "                msci_r = float(msci_path.loc[qe, \"msci_ret_q\"]) if qe in msci_path.index else 0.0\n",
    "                msci_r_lag1 = float(msci_path.loc[test_quarters[t_idx - 1], \"msci_ret_q\"]) if t_idx > 0 else float(msci_lag_map.get(qe, 0.0) or 0.0)\n",
    "\n",
    "                msci_z = (msci_r - msci_mu_all) / msci_sigma_all\n",
    "                msci_z = float(np.clip(msci_z, -MSCI_Z_CLIP, MSCI_Z_CLIP))\n",
    "                msci_z_eff = max(msci_z, 0.0) if MSCI_REP_POS_ONLY else msci_z\n",
    "\n",
    "                U = U_by_q[qe]\n",
    "\n",
    "                for fid in fund_ids:\n",
    "                    st = sim_state[fid]\n",
    "                    if not st[\"alive\"]:\n",
    "                        continue\n",
    "\n",
    "                    age_q = int(st[\"age0\"] + t_idx)\n",
    "                    age_bucket = make_age_bucket_q(age_q)\n",
    "\n",
    "                    # annual grade transition\n",
    "                    if t_idx > 0 and t_idx % 4 == 0:\n",
    "                        P = get_transition_matrix(st[\"strategy\"])\n",
    "                        st[\"grade\"] = sample_next_grade(st[\"grade\"], P, rng)\n",
    "\n",
    "                    grade = st[\"grade\"]\n",
    "                    strategy = st[\"strategy\"]\n",
    "\n",
    "                    # omega\n",
    "                    a, b0, b1 = get_betas(strategy, grade)\n",
    "                    alpha, _ = get_alpha(strategy, grade, str(age_bucket))\n",
    "                    sigma, _ = get_sigma(strategy, grade)\n",
    "                    eps = rng.standard_normal()\n",
    "                    omega = alpha + b0 * msci_r + b1 * msci_r_lag1 + sigma * eps\n",
    "                    omega += float(GRADE_OMEGA_BIAS.get(grade, 0.0))\n",
    "                    omega = float(np.clip(omega, -OMEGA_CLIP, OMEGA_CLIP))\n",
    "\n",
    "                    # capacity\n",
    "                    ledger = st[\"ledger\"]\n",
    "                    start_qe = fund_start_qe[fid]\n",
    "                    step = quarter_diff(qe, start_qe)\n",
    "                    rc_avail_pre = ledger.available(step)\n",
    "                    remaining_commit_pre = max(st[\"commitment\"] - st[\"dd_commit\"], 0.0)\n",
    "                    capacity_pre = remaining_commit_pre + rc_avail_pre\n",
    "\n",
    "                    params = lookup_params(strategy, grade, age_bucket)\n",
    "\n",
    "                    # drawdown probability\n",
    "                    ip_q = int(ip_by_strategy.get(strategy, IP_Q_DEFAULT))\n",
    "                    draw_mult = 1.0\n",
    "                    if USE_DRAW_AGE_SHAPE and ip_q > 0:\n",
    "                        if ENFORCE_IP_LIMITS and age_q > ip_q:\n",
    "                            draw_mult = 0.0\n",
    "                        else:\n",
    "                            frac = float(age_q) / float(ip_q)\n",
    "                            draw_mult = max(DRAW_AGE_MIN_MULT, (1.0 - frac) ** DRAW_AGE_DECAY_POWER)\n",
    "\n",
    "                    if USE_HAZARD_MODELS and beta_draw is not None:\n",
    "                        Xr = build_feature_row(strategy, grade, age_q, 0.0, False, hazard_meta[\"draw_cols\"], hazard_meta[\"draw_means\"], hazard_meta[\"draw_stds\"])\n",
    "                        p_draw_base = float(_sigmoid(Xr @ beta_draw)[0])\n",
    "                    else:\n",
    "                        p_draw_base = float(params.get(\"p_draw\", 0.0))\n",
    "\n",
    "                    grade_key = grade if grade in GRADE_DRAW_P_MULT else \"D\"\n",
    "                    p_draw_adj = p_draw_base * draw_mult * float(GRADE_DRAW_P_MULT.get(grade_key, 1.0))\n",
    "                    p_draw_adj = min(p_draw_adj, 1.0)\n",
    "\n",
    "                    i = fund_index[fid]\n",
    "                    draw_event = (U[\"draw_event\"][i] < p_draw_adj) and (capacity_pre > 0.0)\n",
    "                    draw_amt = 0.0\n",
    "                    use_rc = 0.0\n",
    "                    use_commit = 0.0\n",
    "\n",
    "                    if draw_event:\n",
    "                        ratio = lognormal_from_u(params[\"mu_draw\"], params[\"sig_draw\"], float(U[\"draw_size\"][i]))\n",
    "                        ratio = float(np.clip(ratio, 0.0, 1.0))\n",
    "                        ratio = min(ratio * float(GRADE_DRAW_SIZE_MULT.get(grade_key, 1.0)), 1.0)\n",
    "                        if USE_DRAWDOWN_CALIBRATION:\n",
    "                            scale = draw_scale_sg.get((strategy, grade),\n",
    "                                                      draw_scale_s.get(strategy, draw_scale_g))\n",
    "                            ratio = ratio * float(scale)\n",
    "                        ratio = float(np.clip(ratio, 0.0, 1.0))\n",
    "                        draw_amt = ratio * capacity_pre\n",
    "                        cons = ledger.consume_for_drawdown(step, draw_amt)\n",
    "                        use_rc = cons[\"use_rc\"]\n",
    "                        use_commit = cons[\"use_commitment\"]\n",
    "                        st[\"dd_commit\"] += use_commit\n",
    "\n",
    "                    # Force full commitment deployment by end of IP, plus any available recallables\n",
    "                    if (not st[\"ip_catchup_done\"]) and (age_q >= ip_q):\n",
    "                        remaining_commit_after = max(st[\"commitment\"] - st[\"dd_commit\"], 0.0)\n",
    "                        if remaining_commit_after > 0.0:\n",
    "                            draw_amt += remaining_commit_after\n",
    "                            st[\"dd_commit\"] += remaining_commit_after\n",
    "                            draw_event = True\n",
    "                        rc_avail_after = ledger.available(step)\n",
    "                        if rc_avail_after > 0.0:\n",
    "                            cons2 = ledger.consume_for_drawdown(step, rc_avail_after)\n",
    "                            draw_amt += cons2[\"use_rc\"] + cons2[\"use_commitment\"]\n",
    "                            st[\"dd_commit\"] += cons2[\"use_commitment\"]\n",
    "                            draw_event = True\n",
    "                        st[\"ip_catchup_done\"] = True\n",
    "\n",
    "                    # repayment\n",
    "                    NAV_prev = float(st[\"nav\"])\n",
    "                    rep_regular = 0.0\n",
    "                    if USE_HAZARD_MODELS and beta_rep is not None:\n",
    "                        Xr = build_feature_row(strategy, grade, age_q, np.log1p(abs(NAV_prev)), True, hazard_meta[\"rep_cols\"], hazard_meta[\"rep_means\"], hazard_meta[\"rep_stds\"])\n",
    "                        p_rep_base = float(_sigmoid(Xr @ beta_rep)[0])\n",
    "                    else:\n",
    "                        p_rep_base = float(params.get(\"p_rep\", 0.0))\n",
    "\n",
    "                    grade_key = grade if grade in GRADE_P_MULT else \"D\"\n",
    "                    runoff_mult = float(runoff_mult_by_strategy.get(strategy, 1.0)) if USE_RUNOFF_CALIBRATION else 1.0\n",
    "\n",
    "                    cap_qe = st[\"cap_qe\"]\n",
    "                    q_left = 9999\n",
    "                    if pd.notna(cap_qe):\n",
    "                        q_left = max(quarter_diff(cap_qe, qe), 0)\n",
    "\n",
    "                    tail_factor = 0.0\n",
    "                    if RUNOFF_Q > 0:\n",
    "                        tail_factor = float(max(0.0, (RUNOFF_Q - q_left) / RUNOFF_Q))\n",
    "\n",
    "                    p_rep_adj = 1.0 - (1.0 - p_rep_base) ** (1.0 + (REP_RAMP_P * runoff_mult) * tail_factor)\n",
    "                    p_rep_adj = min(1.0, p_rep_adj + REP_RAMP_FLOOR * tail_factor)\n",
    "                    p_rep_adj = min(1.0, p_rep_adj * float(GRADE_P_MULT.get(grade_key, 1.0)))\n",
    "                    p_rep_adj = float(np.clip(p_rep_adj, 1e-6, 1.0 - 1e-6))\n",
    "                    logit_p = np.log(p_rep_adj / (1.0 - p_rep_adj))\n",
    "                    logit_p += MSCI_REP_P_BETA * msci_z_eff\n",
    "                    p_rep_adj = float(1.0 / (1.0 + np.exp(-logit_p)))\n",
    "\n",
    "                    rep_event = (U[\"rep_event\"][i] < p_rep_adj) and (NAV_prev > NAV_EPS)\n",
    "                    if rep_event:\n",
    "                        rep_ratio = lognormal_from_u(params[\"mu_rep\"], params[\"sig_rep\"], float(U[\"rep_size\"][i]))\n",
    "                        rep_ratio = float(np.clip(rep_ratio, 0.0, 1.0))\n",
    "                        rep_ratio = min(rep_ratio * (1.0 + (REP_RAMP_SIZE * runoff_mult) * tail_factor), 1.0)\n",
    "                        rep_ratio = min(rep_ratio * float(GRADE_SIZE_MULT.get(grade_key, 1.0)), 1.0)\n",
    "                        size_mult = max(0.0, 1.0 + MSCI_REP_SIZE_BETA * msci_z_eff)\n",
    "                        rep_ratio = min(rep_ratio * size_mult, 1.0)\n",
    "                        rep_regular = rep_ratio * NAV_prev\n",
    "\n",
    "                    # recallable\n",
    "                    rc_added = 0.0\n",
    "                    rc_event = (rep_regular > 0.0) and (U[\"rc_event\"][i] < params[\"p_rc_given_rep\"])\n",
    "                    if rc_event:\n",
    "                        rc_ratio = lognormal_from_u(params[\"mu_rc\"], params[\"sig_rc\"], float(U[\"rc_size\"][i]))\n",
    "                        rc_ratio = float(np.clip(rc_ratio, 0.0, 1.0))\n",
    "                        rc_amt_raw = rc_ratio * rep_regular\n",
    "                        rc_added = ledger.add_recallable(step, rc_amt_raw, enforce_cap=True)\n",
    "\n",
    "                    # NAV update\n",
    "                    available_nav = max(NAV_prev + float(draw_amt) - float(rep_regular), 0.0)\n",
    "                    rep_terminal = 0.0\n",
    "                    if RUNOFF_Q > 0 and q_left < RUNOFF_Q:\n",
    "                        base_ratio = q_left / (q_left + 1.0)\n",
    "                        target_nav = available_nav * (base_ratio ** max(runoff_mult, 0.0))\n",
    "                        rep_terminal = max(0.0, available_nav - target_nav)\n",
    "\n",
    "                    nav_after_flow = max(available_nav - rep_terminal, 0.0)\n",
    "                    nav_after_val = nav_after_flow * (1.0 + float(omega))\n",
    "                    if not np.isfinite(nav_after_val):\n",
    "                        nav_after_val = 0.0\n",
    "                    nav_after_val = max(float(nav_after_val), 0.0)\n",
    "\n",
    "                    st[\"nav\"] = nav_after_val\n",
    "\n",
    "                    if q_left == 0 or nav_after_val <= NAV_STOP_EPS:\n",
    "                        st[\"alive\"] = False\n",
    "\n",
    "                    # aggregates\n",
    "                    bkey = fund_bucket[fid]\n",
    "                    bidx = bucket_index[bkey]\n",
    "\n",
    "                    sim_draw[s, t_idx] += draw_amt\n",
    "                    sim_rep[s, t_idx] += (rep_regular + rep_terminal)\n",
    "                    sim_nav[s, t_idx] += nav_after_val\n",
    "\n",
    "                    sim_draw_b[s, t_idx, bidx] += draw_amt\n",
    "                    sim_rep_b[s, t_idx, bidx] += (rep_regular + rep_terminal)\n",
    "                    sim_nav_b[s, t_idx, bidx] += nav_after_val\n",
    "\n",
    "        # build portfolio series table\n",
    "        q_end = pd.Index(test_quarters, name=\"quarter_end\")\n",
    "        portfolio_series = pd.DataFrame({\n",
    "            \"quarter_end\": q_end,\n",
    "            \"actual_draw\": actual_draw,\n",
    "            \"actual_rep\": actual_rep,\n",
    "            \"actual_nav\": actual_nav,\n",
    "            \"sim_draw_mean\": sim_draw.mean(axis=0),\n",
    "            \"sim_rep_mean\": sim_rep.mean(axis=0),\n",
    "            \"sim_nav_mean\": sim_nav.mean(axis=0),\n",
    "            \"sim_draw_p05\": np.quantile(sim_draw, 0.05, axis=0),\n",
    "            \"sim_draw_p95\": np.quantile(sim_draw, 0.95, axis=0),\n",
    "            \"sim_rep_p05\": np.quantile(sim_rep, 0.05, axis=0),\n",
    "            \"sim_rep_p95\": np.quantile(sim_rep, 0.95, axis=0),\n",
    "            \"sim_nav_p05\": np.quantile(sim_nav, 0.05, axis=0),\n",
    "            \"sim_nav_p95\": np.quantile(sim_nav, 0.95, axis=0),\n",
    "        })\n",
    "\n",
    "        # portfolio summary\n",
    "        def _metrics(sim_mean, sim_p05, sim_p95, actual):\n",
    "            err = sim_mean - actual\n",
    "            rmse = float(np.sqrt(np.mean(err ** 2)))\n",
    "            mae = float(np.mean(np.abs(err)))\n",
    "            bias = float(np.mean(err))\n",
    "            coverage = float(np.mean((actual >= sim_p05) & (actual <= sim_p95)))\n",
    "            return rmse, mae, bias, coverage\n",
    "\n",
    "        draw_rmse, draw_mae, draw_bias, draw_cov = _metrics(\n",
    "            portfolio_series[\"sim_draw_mean\"].to_numpy(),\n",
    "            portfolio_series[\"sim_draw_p05\"].to_numpy(),\n",
    "            portfolio_series[\"sim_draw_p95\"].to_numpy(),\n",
    "            portfolio_series[\"actual_draw\"].to_numpy(),\n",
    "        )\n",
    "        rep_rmse, rep_mae, rep_bias, rep_cov = _metrics(\n",
    "            portfolio_series[\"sim_rep_mean\"].to_numpy(),\n",
    "            portfolio_series[\"sim_rep_p05\"].to_numpy(),\n",
    "            portfolio_series[\"sim_rep_p95\"].to_numpy(),\n",
    "            portfolio_series[\"actual_rep\"].to_numpy(),\n",
    "        )\n",
    "        nav_rmse, nav_mae, nav_bias, nav_cov = _metrics(\n",
    "            portfolio_series[\"sim_nav_mean\"].to_numpy(),\n",
    "            portfolio_series[\"sim_nav_p05\"].to_numpy(),\n",
    "            portfolio_series[\"sim_nav_p95\"].to_numpy(),\n",
    "            portfolio_series[\"actual_nav\"].to_numpy(),\n",
    "        )\n",
    "\n",
    "        portfolio_summary = pd.DataFrame([\n",
    "            {\n",
    "                \"scenario\": scenario,\n",
    "                \"bucket\": \"PORTFOLIO\",\n",
    "                \"n_funds\": len(fund_ids),\n",
    "                \"draw_rmse\": draw_rmse, \"draw_mae\": draw_mae, \"draw_bias\": draw_bias, \"draw_cov_90\": draw_cov,\n",
    "                \"rep_rmse\": rep_rmse, \"rep_mae\": rep_mae, \"rep_bias\": rep_bias, \"rep_cov_90\": rep_cov,\n",
    "                \"nav_rmse\": nav_rmse, \"nav_mae\": nav_mae, \"nav_bias\": nav_bias, \"nav_cov_90\": nav_cov,\n",
    "            }\n",
    "        ])\n",
    "\n",
    "        # bucket summary\n",
    "        bucket_rows = []\n",
    "        for bkey, bidx in bucket_index.items():\n",
    "            sim_draw_m = sim_draw_b[:, :, bidx].mean(axis=0)\n",
    "            sim_rep_m = sim_rep_b[:, :, bidx].mean(axis=0)\n",
    "            sim_nav_m = sim_nav_b[:, :, bidx].mean(axis=0)\n",
    "\n",
    "            sim_draw_p05 = np.quantile(sim_draw_b[:, :, bidx], 0.05, axis=0)\n",
    "            sim_draw_p95 = np.quantile(sim_draw_b[:, :, bidx], 0.95, axis=0)\n",
    "\n",
    "            sim_rep_p05 = np.quantile(sim_rep_b[:, :, bidx], 0.05, axis=0)\n",
    "            sim_rep_p95 = np.quantile(sim_rep_b[:, :, bidx], 0.95, axis=0)\n",
    "\n",
    "            sim_nav_p05 = np.quantile(sim_nav_b[:, :, bidx], 0.05, axis=0)\n",
    "            sim_nav_p95 = np.quantile(sim_nav_b[:, :, bidx], 0.95, axis=0)\n",
    "\n",
    "            act_draw = actual_draw_b[:, bidx]\n",
    "            act_rep = actual_rep_b[:, bidx]\n",
    "            act_nav = actual_nav_b[:, bidx]\n",
    "\n",
    "            d_rmse, d_mae, d_bias, d_cov = _metrics(sim_draw_m, sim_draw_p05, sim_draw_p95, act_draw)\n",
    "            r_rmse, r_mae, r_bias, r_cov = _metrics(sim_rep_m, sim_rep_p05, sim_rep_p95, act_rep)\n",
    "            n_rmse, n_mae, n_bias, n_cov = _metrics(sim_nav_m, sim_nav_p05, sim_nav_p95, act_nav)\n",
    "\n",
    "            n_funds_bucket = sum(1 for f, b in fund_bucket.items() if b == bkey)\n",
    "\n",
    "            bucket_rows.append({\n",
    "                \"scenario\": scenario,\n",
    "                \"strategy\": bkey[0],\n",
    "                \"grade\": bkey[1],\n",
    "                \"age_bucket\": bkey[2],\n",
    "                \"n_funds\": n_funds_bucket,\n",
    "                \"draw_rmse\": d_rmse, \"draw_mae\": d_mae, \"draw_bias\": d_bias, \"draw_cov_90\": d_cov,\n",
    "                \"rep_rmse\": r_rmse, \"rep_mae\": r_mae, \"rep_bias\": r_bias, \"rep_cov_90\": r_cov,\n",
    "                \"nav_rmse\": n_rmse, \"nav_mae\": n_mae, \"nav_bias\": n_bias, \"nav_cov_90\": n_cov,\n",
    "            })\n",
    "\n",
    "        bucket_summary = pd.DataFrame(bucket_rows)\n",
    "        return portfolio_series, portfolio_summary, bucket_summary\n",
    "\n",
    "    # Run conditional and unconditional\n",
    "    print(\"Running conditional backtest (actual MSCI)...\")\n",
    "    cond_series, cond_portfolio, cond_bucket = run_backtest(\"conditional\", conditional=True)\n",
    "\n",
    "    print(\"Running unconditional backtest (simulated MSCI)...\")\n",
    "    uncond_series, uncond_portfolio, uncond_bucket = run_backtest(scenario_uncond, conditional=False)\n",
    "\n",
    "    # Save\n",
    "    def _yq(qe: pd.Timestamp) -> str:\n",
    "        return f\"{qe.year}_Q{qe.quarter}\"\n",
    "\n",
    "    test_end_tag = _yq(test_end_qe)\n",
    "    out_cond_series = os.path.join(DATA_DIR, f\"backtest_portfolio_series_conditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_uncond_series = os.path.join(DATA_DIR, f\"backtest_portfolio_series_unconditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_cond_port = os.path.join(DATA_DIR, f\"backtest_portfolio_summary_conditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_uncond_port = os.path.join(DATA_DIR, f\"backtest_portfolio_summary_unconditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_cond_bucket = os.path.join(DATA_DIR, f\"backtest_bucket_summary_conditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "    out_uncond_bucket = os.path.join(DATA_DIR, f\"backtest_bucket_summary_unconditional_{train_year}_{train_quarter}_to_{test_end_tag}.csv\")\n",
    "\n",
    "    cond_series.to_csv(out_cond_series, index=False)\n",
    "    uncond_series.to_csv(out_uncond_series, index=False)\n",
    "    cond_portfolio.to_csv(out_cond_port, index=False)\n",
    "    uncond_portfolio.to_csv(out_uncond_port, index=False)\n",
    "    cond_bucket.to_csv(out_cond_bucket, index=False)\n",
    "    uncond_bucket.to_csv(out_uncond_bucket, index=False)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(out_cond_series)\n",
    "    print(out_uncond_series)\n",
    "    print(out_cond_port)\n",
    "    print(out_uncond_port)\n",
    "    print(out_cond_bucket)\n",
    "    print(out_uncond_bucket)\n",
    "\n",
    "    print(\"Runtime (seconds):\", round(time.perf_counter() - t0, 2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
