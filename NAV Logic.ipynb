{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f66df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MSCI projection file: C:\\Users\\MANJANID\\Documents\\Equity\\2025_Q3\\data\\msci_projection_2025_Q3_neutral_40q.parquet\n",
      "Projection start quarter-end: 2025-09-30\n",
      "Loaded data rows: 30857\n",
      "Funds: 1009\n",
      "Future MSCI quarters available: 40\n",
      "Calibration rows: 26354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manjanid\\AppData\\Local\\Temp\\ipykernel_24760\\2900854099.py:394: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for (s, g, a), grp in cal2.groupby([\"Adj Strategy\",\"Grade\",\"AgeBucket\"], dropna=False):\n",
      "C:\\Users\\manjanid\\AppData\\Local\\Temp\\ipykernel_24760\\2900854099.py:532: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  ratio_draw = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_draw\")).reset_index()\n",
      "C:\\Users\\manjanid\\AppData\\Local\\Temp\\ipykernel_24760\\2900854099.py:532: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ratio_draw = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_draw\")).reset_index()\n",
      "C:\\Users\\manjanid\\AppData\\Local\\Temp\\ipykernel_24760\\2900854099.py:533: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  ratio_size = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_size\")).reset_index()\n",
      "C:\\Users\\manjanid\\AppData\\Local\\Temp\\ipykernel_24760\\2900854099.py:533: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ratio_size = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_size\")).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Omega rows: 15513\n",
      "Omega funds: 945\n",
      "\n",
      "Saved:\n",
      "C:\\Users\\MANJANID\\Documents\\Equity\\2025_Q3\\data\\omega_projection_sota_2025_Q3_40q.csv\n",
      "C:\\Users\\MANJANID\\Documents\\Equity\\2025_Q3\\data\\omega_projection_sota_2025_Q3_40q.parquet\n",
      "C:\\Users\\MANJANID\\Documents\\Equity\\2025_Q3\\data\\nav_start_sota_2025_Q3.csv\n",
      "C:\\Users\\MANJANID\\Documents\\Equity\\2025_Q3\\data\\nav_start_sota_2025_Q3.parquet\n",
      "Diagnostics saved (beta/alpha/sigma).\n",
      "\n",
      "Omega projection head:\n",
      "                             FundID quarter_end  step_q  msci_ret_q  \\\n",
      "0  0084126E5AB84A059EFCD1CB88947783  2025-12-31       1    0.147330   \n",
      "1  0084126E5AB84A059EFCD1CB88947783  2026-03-31       2    0.023595   \n",
      "2  0084126E5AB84A059EFCD1CB88947783  2026-06-30       3    0.032187   \n",
      "3  0084126E5AB84A059EFCD1CB88947783  2026-09-30       4    0.001850   \n",
      "4  0084126E5AB84A059EFCD1CB88947783  2026-12-31       5   -0.116651   \n",
      "\n",
      "   msci_ret_q_lag1     omega  Fund_Age_Quarters     Adj Strategy Grade_prev  \\\n",
      "0         0.008573 -0.237889                 48  Venture Capital          C   \n",
      "1         0.147330  0.021583                 49  Venture Capital          C   \n",
      "2         0.023595  0.112375                 50  Venture Capital          C   \n",
      "3         0.032187  0.129428                 51  Venture Capital          C   \n",
      "4         0.001850  0.429229                 52  Venture Capital          C   \n",
      "\n",
      "  Grade AgeBucket     cap_qe  \n",
      "0     C    10-15y 2026-12-31  \n",
      "1     C    10-15y 2026-12-31  \n",
      "2     C    10-15y 2026-12-31  \n",
      "3     C    10-15y 2026-12-31  \n",
      "4     C    10-15y 2026-12-31  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "OMEGA Projection (for endogenous NAV) — “Institutional-grade” version\n",
    "\n",
    "This is a refactor of your Untitled-1 NAV projection:\n",
    "- Keeps calibration of omega on MSCI (distributed-lag), alpha/beta/sigma pooling, grade transitions, cap logic\n",
    "- Computes NAV_start (initial condition) EXACTLY as before\n",
    "- Instead of generating NAV_projected paths, it generates omega_t paths (valuation return shocks)\n",
    "  which will be used by structural cashflows to update NAV endogenously:\n",
    "\n",
    "    NAV_t = max((NAV_{t-1} + Draw_t - Rep_t) * (1 + omega_t), 0)\n",
    "\n",
    "Outputs:\n",
    "1) omega_projection_sota_{year}_{quarter}_{n_q}q.(csv|parquet)\n",
    "   Columns include: FundID, quarter_end, msci_ret_q, msci_ret_q_lag1, omega,\n",
    "                   strategy, grade path, age bucket, cap_qe, etc.\n",
    "\n",
    "2) nav_start_sota_{year}_{quarter}.(csv|parquet)\n",
    "   One row per fund: FundID, NAV_start, NAV_start_source, cap_qe, age0, strategy, grade0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "AGE_LABELS = [\"0-2y\", \"2-4y\", \"4-6y\", \"6-8y\", \"8-10y\", \"10-15y\", \"15-20y\", \"20y+\"]\n",
    "AGE_BINS_Q = [-1, 7, 15, 23, 31, 39, 59, 79, 10_000]  # quarters\n",
    "\n",
    "def quarter_end_from_year_quarter(year: int, quarter: str) -> pd.Timestamp:\n",
    "    q = quarter.upper().strip()\n",
    "    if q not in {\"Q1\", \"Q2\", \"Q3\", \"Q4\"}:\n",
    "        raise ValueError(\"Quarter must be one of: Q1, Q2, Q3, Q4\")\n",
    "    q_num = int(q[1])\n",
    "    return pd.Period(f\"{year}Q{q_num}\", freq=\"Q\").to_timestamp(\"Q\")\n",
    "\n",
    "def find_msci_projection_file(data_dir: str) -> str:\n",
    "    cands = glob.glob(os.path.join(data_dir, \"msci_projection_*.parquet\")) + \\\n",
    "            glob.glob(os.path.join(data_dir, \"msci_projection_*.csv\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No MSCI projection file found in {data_dir}. \"\n",
    "            \"Expected msci_projection_*.parquet or msci_projection_*.csv\"\n",
    "        )\n",
    "    cands.sort(key=os.path.getmtime, reverse=True)\n",
    "    return cands[0]\n",
    "\n",
    "def load_msci_projection(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(path) if path.lower().endswith(\".parquet\") else pd.read_csv(path)\n",
    "    if not {\"quarter_end\", \"msci_ret_q\"}.issubset(df.columns):\n",
    "        raise ValueError(\"MSCI projection file must contain columns: quarter_end, msci_ret_q\")\n",
    "    df = df.copy()\n",
    "    df[\"quarter_end\"] = pd.to_datetime(df[\"quarter_end\"])\n",
    "    df = df.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "    return df[[\"quarter_end\", \"msci_ret_q\"]]\n",
    "\n",
    "def add_quarters(qe: pd.Timestamp, q: float) -> pd.Timestamp:\n",
    "    if pd.isna(qe):\n",
    "        return pd.NaT\n",
    "    p = pd.Period(qe, freq=\"Q\")\n",
    "    return (p + int(round(q))).to_timestamp(\"Q\")\n",
    "\n",
    "def make_age_bucket_q(age_q: pd.Series) -> pd.Categorical:\n",
    "    return pd.cut(age_q, bins=AGE_BINS_Q, labels=AGE_LABELS)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "NAV_COL = \"NAV Adjusted EUR\"\n",
    "DRAW_COL = \"Adj Drawdown EUR\"\n",
    "REPAY_COL = \"Adj Repayment EUR\"\n",
    "SIZE_COL = \"Target Fund Size\"\n",
    "\n",
    "NAV_EPS = 100.0\n",
    "OMEGA_CLIP = 0.8\n",
    "\n",
    "MIN_FUNDS_BETA = 10\n",
    "MIN_OBS_BETA = 80\n",
    "\n",
    "MIN_FUNDS_ALPHA_BUCKET = 6\n",
    "MIN_OBS_ALPHA_BUCKET = 60\n",
    "\n",
    "SIGMA_SHRINK_K = 120.0\n",
    "\n",
    "DRAW_EPS = 1000.0\n",
    "SIZE_EPS = 1e6\n",
    "MIN_OBS_RATIO = 50\n",
    "\n",
    "# -----------------------------\n",
    "# Inputs\n",
    "# -----------------------------\n",
    "year = int(input(\"Enter year (e.g. 2025): \").strip())\n",
    "quarter = input(\"Enter quarter (Q1, Q2, Q3, Q4): \").strip().upper()\n",
    "\n",
    "n_q = int(input(\"Enter number of quarters to project (0 => default 40): \").strip() or \"0\")\n",
    "if n_q == 0:\n",
    "    n_q = 40\n",
    "\n",
    "BASE_DIR = os.path.join(\"C:\\\\Users\", os.environ.get(\"USERNAME\"), \"Documents\", \"Equity\")\n",
    "HOME = os.path.join(BASE_DIR, f\"{year}_{quarter}\")\n",
    "DATA_DIR = os.path.join(HOME, \"data\")\n",
    "\n",
    "data_path = os.path.join(DATA_DIR, \"data.parquet\")\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Missing data.parquet at: {data_path}\")\n",
    "\n",
    "msci_xlsx = os.path.join(DATA_DIR, \"MSCI.xlsx\")\n",
    "if not os.path.exists(msci_xlsx):\n",
    "    raise FileNotFoundError(f\"Missing MSCI.xlsx at: {msci_xlsx}\")\n",
    "\n",
    "msci_proj_path = find_msci_projection_file(DATA_DIR)\n",
    "print(\"Using MSCI projection file:\", msci_proj_path)\n",
    "\n",
    "start_qe = quarter_end_from_year_quarter(year, quarter)\n",
    "print(\"Projection start quarter-end:\", start_qe.date())\n",
    "\n",
    "# -----------------------------\n",
    "# Load fund panel\n",
    "# -----------------------------\n",
    "data = pd.read_parquet(data_path).copy()\n",
    "\n",
    "data[\"quarter_end\"] = pd.PeriodIndex(\n",
    "    data[\"Year of Transaction Date\"].astype(int).astype(str) + \"Q\" +\n",
    "    data[\"Quarter of Transaction Date\"].astype(int).astype(str),\n",
    "    freq=\"Q\"\n",
    ").to_timestamp(\"Q\")\n",
    "data[\"quarter_end\"] = pd.to_datetime(data[\"quarter_end\"])\n",
    "\n",
    "required_cols = [\n",
    "    \"FundID\", \"quarter_end\",\n",
    "    NAV_COL, DRAW_COL, REPAY_COL,\n",
    "    \"Adj Strategy\", \"Grade\",\n",
    "    SIZE_COL, \"Fund_Age_Quarters\",\n",
    "    \"Planned end date with add. years as per legal doc\",\n",
    "]\n",
    "missing = [c for c in required_cols if c not in data.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in data.parquet: {missing}\")\n",
    "\n",
    "data[\"planned_end_qe\"] = pd.to_datetime(\n",
    "    data[\"Planned end date with add. years as per legal doc\"],\n",
    "    errors=\"coerce\"\n",
    ").dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "\n",
    "data[NAV_COL] = pd.to_numeric(data[NAV_COL], errors=\"coerce\")\n",
    "for c in [DRAW_COL, REPAY_COL, SIZE_COL, \"Fund_Age_Quarters\"]:\n",
    "    data[c] = pd.to_numeric(data[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "data = data.sort_values([\"FundID\", \"quarter_end\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Loaded data rows:\", len(data))\n",
    "print(\"Funds:\", data[\"FundID\"].nunique())\n",
    "\n",
    "# -----------------------------\n",
    "# MSCI history (quarterly) + lag\n",
    "# -----------------------------\n",
    "msci_raw = pd.read_excel(msci_xlsx)[[\"Date\", \"SCXP Index\"]].copy()\n",
    "msci_raw[\"Date\"] = pd.to_datetime(msci_raw[\"Date\"], errors=\"coerce\")\n",
    "msci_raw[\"SCXP Index\"] = pd.to_numeric(msci_raw[\"SCXP Index\"], errors=\"coerce\")\n",
    "msci_raw = msci_raw.dropna().sort_values(\"Date\")\n",
    "\n",
    "msci_raw[\"quarter_end\"] = msci_raw[\"Date\"].dt.to_period(\"Q\").dt.to_timestamp(\"Q\")\n",
    "msci_hist = (\n",
    "    msci_raw.groupby(\"quarter_end\", as_index=False)[\"SCXP Index\"]\n",
    "    .last()\n",
    "    .rename(columns={\"SCXP Index\": \"index_level\"})\n",
    ")\n",
    "msci_hist[\"msci_ret_q\"] = msci_hist[\"index_level\"].pct_change()\n",
    "msci_hist = msci_hist.dropna(subset=[\"msci_ret_q\"])[[\"quarter_end\", \"msci_ret_q\"]]\n",
    "msci_hist[\"quarter_end\"] = pd.to_datetime(msci_hist[\"quarter_end\"])\n",
    "msci_hist = msci_hist.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "msci_hist[\"msci_ret_q_lag1\"] = msci_hist[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "# -----------------------------\n",
    "# MSCI future projection (+ lag) with first-lag fix\n",
    "# -----------------------------\n",
    "msci_proj = load_msci_projection(msci_proj_path)\n",
    "msci_proj = msci_proj.sort_values(\"quarter_end\").reset_index(drop=True)\n",
    "msci_proj[\"msci_ret_q_lag1\"] = msci_proj[\"msci_ret_q\"].shift(1)\n",
    "\n",
    "msci_future = msci_proj.loc[msci_proj[\"quarter_end\"] > start_qe].head(n_q).copy()\n",
    "if msci_future.empty:\n",
    "    raise ValueError(\"MSCI projection contains no quarters after the selected start date.\")\n",
    "\n",
    "last_hist_ret = msci_hist.loc[msci_hist[\"quarter_end\"] <= start_qe, \"msci_ret_q\"].tail(1)\n",
    "msci_future.loc[msci_future.index[0], \"msci_ret_q_lag1\"] = float(last_hist_ret.iloc[0]) if len(last_hist_ret) else 0.0\n",
    "msci_future[\"msci_ret_q_lag1\"] = msci_future[\"msci_ret_q_lag1\"].fillna(0.0)\n",
    "\n",
    "print(\"Future MSCI quarters available:\", len(msci_future))\n",
    "\n",
    "# -----------------------------\n",
    "# Planned end overrun by strategy (history-based)\n",
    "# -----------------------------\n",
    "last_obs = data.groupby(\"FundID\")[\"quarter_end\"].max().rename(\"last_qe\")\n",
    "fund_static = data.sort_values([\"FundID\", \"quarter_end\"]).groupby(\"FundID\").tail(1).copy()\n",
    "fund_static = fund_static.merge(last_obs, on=\"FundID\", how=\"left\")\n",
    "\n",
    "def quarters_diff(a: pd.Timestamp, b: pd.Timestamp) -> float:\n",
    "    if pd.isna(a) or pd.isna(b):\n",
    "        return np.nan\n",
    "    return float(pd.Period(a, freq=\"Q\").ordinal - pd.Period(b, freq=\"Q\").ordinal)\n",
    "\n",
    "fund_static[\"overrun_q\"] = fund_static.apply(\n",
    "    lambda r: max(quarters_diff(r[\"last_qe\"], r[\"planned_end_qe\"]), 0.0)\n",
    "    if pd.notna(r[\"planned_end_qe\"]) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "fund_static[\"ever_overran\"] = fund_static[\"overrun_q\"].fillna(0) > 0\n",
    "ever_overran_map = fund_static.set_index(\"FundID\")[\"ever_overran\"]\n",
    "\n",
    "overran_only = fund_static.loc[fund_static[\"overrun_q\"].notna() & (fund_static[\"overrun_q\"] > 0)].copy()\n",
    "avg_overrun_by_strategy = overran_only.groupby(\"Adj Strategy\")[\"overrun_q\"].mean().clip(lower=0.0)\n",
    "\n",
    "# -----------------------------\n",
    "# Build omega from history for calibration\n",
    "# -----------------------------\n",
    "df = data.copy().sort_values([\"FundID\", \"quarter_end\"]).reset_index(drop=True)\n",
    "\n",
    "df[\"nav_prev\"] = df.groupby(\"FundID\")[NAV_COL].shift(1)\n",
    "df[\"flow_net\"] = df[DRAW_COL] - df[REPAY_COL]\n",
    "\n",
    "m = df[\"nav_prev\"].abs() > NAV_EPS\n",
    "df[\"omega\"] = np.nan\n",
    "df.loc[m, \"omega\"] = ((df.loc[m, NAV_COL] - df.loc[m, \"nav_prev\"]) - df.loc[m, \"flow_net\"]) / df.loc[m, \"nav_prev\"]\n",
    "df[\"omega\"] = df[\"omega\"].clip(lower=-OMEGA_CLIP, upper=OMEGA_CLIP)\n",
    "\n",
    "# Calibration dataset: omega + MSCI + lag\n",
    "cal = df.merge(msci_hist, on=\"quarter_end\", how=\"left\")\n",
    "cal = cal.dropna(subset=[\"omega\", \"msci_ret_q\", \"msci_ret_q_lag1\"]).copy()\n",
    "cal[\"AgeBucket\"] = make_age_bucket_q(cal[\"Fund_Age_Quarters\"])\n",
    "cal = cal[[\"FundID\", \"Adj Strategy\", \"Grade\", \"AgeBucket\", \"omega\", \"msci_ret_q\", \"msci_ret_q_lag1\"]].copy()\n",
    "\n",
    "print(\"Calibration rows:\", len(cal))\n",
    "\n",
    "# ============================================================\n",
    "# Cluster-robust OLS helpers (unchanged)\n",
    "# ============================================================\n",
    "from scipy import stats\n",
    "\n",
    "def ols_cluster_robust(df, y_col, x_cols, cluster_col):\n",
    "    d = df.dropna(subset=[y_col] + x_cols + [cluster_col]).copy()\n",
    "    n = len(d)\n",
    "    if n == 0:\n",
    "        return None\n",
    "\n",
    "    y = d[y_col].to_numpy(float)\n",
    "    X = np.column_stack([np.ones(n)] + [d[c].to_numpy(float) for c in x_cols])\n",
    "    k = X.shape[1]\n",
    "\n",
    "    XtX = X.T @ X\n",
    "    XtX_inv = np.linalg.pinv(XtX)\n",
    "    beta = XtX_inv @ (X.T @ y)\n",
    "\n",
    "    u = y - X @ beta\n",
    "    clusters = d[cluster_col].to_numpy()\n",
    "    uniq = pd.unique(clusters)\n",
    "    G = len(uniq)\n",
    "    df_dof = G - 1\n",
    "    if G <= 1:\n",
    "        return None\n",
    "\n",
    "    meat = np.zeros((k, k), dtype=float)\n",
    "    for g in uniq:\n",
    "        mask = (clusters == g)\n",
    "        Xg = X[mask, :]\n",
    "        ug = u[mask]\n",
    "        Xgu = Xg.T @ ug\n",
    "        meat += np.outer(Xgu, Xgu)\n",
    "\n",
    "    V = XtX_inv @ meat @ XtX_inv\n",
    "    scale = (G / (G - 1)) * ((n - 1) / max(n - k, 1))\n",
    "    V *= scale\n",
    "\n",
    "    se = np.sqrt(np.diag(V))\n",
    "    tstats = beta / se\n",
    "    pvals = 2.0 * (1.0 - stats.t.cdf(np.abs(tstats), df=df_dof))\n",
    "\n",
    "    names = [\"alpha\"] + x_cols\n",
    "    return {\n",
    "        \"coef\": pd.Series(beta, index=names),\n",
    "        \"se\": pd.Series(se, index=names),\n",
    "        \"t\": pd.Series(tstats, index=names),\n",
    "        \"p\": pd.Series(pvals, index=names),\n",
    "        \"n_obs\": int(n),\n",
    "        \"n_clusters\": int(G),\n",
    "        \"df_dof\": int(df_dof),\n",
    "    }\n",
    "\n",
    "def cluster_mean_stats(df, y_col, cluster_col):\n",
    "    res = ols_cluster_robust(df, y_col=y_col, x_cols=[], cluster_col=cluster_col)\n",
    "    if res is None:\n",
    "        return None\n",
    "    return {\n",
    "        \"alpha\": float(res[\"coef\"][\"alpha\"]),\n",
    "        \"se_alpha\": float(res[\"se\"][\"alpha\"]),\n",
    "        \"t_alpha\": float(res[\"t\"][\"alpha\"]),\n",
    "        \"p_alpha\": float(res[\"p\"][\"alpha\"]),\n",
    "        \"n_obs\": res[\"n_obs\"],\n",
    "        \"n_funds\": res[\"n_clusters\"],\n",
    "        \"df\": res[\"df_dof\"],\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Statistical decision settings\n",
    "# ============================================================\n",
    "alpha_level = float(input(\"Significance level for using group params? [0.10]: \").strip() or \"0.10\")\n",
    "min_clusters_for_inference = int(input(\"Minimum #fund clusters for inference [8]: \").strip() or \"8\")\n",
    "\n",
    "# ============================================================\n",
    "# 1) Betas (cluster robust) with significance gating (unchanged)\n",
    "# ============================================================\n",
    "beta_rows_sg = []\n",
    "for (s, g), grp in cal.groupby([\"Adj Strategy\", \"Grade\"], dropna=False):\n",
    "    res = ols_cluster_robust(grp, \"omega\", [\"msci_ret_q\", \"msci_ret_q_lag1\"], \"FundID\")\n",
    "    if res is None:\n",
    "        continue\n",
    "    n_funds = res[\"n_clusters\"]\n",
    "    usable = (n_funds >= min_clusters_for_inference)\n",
    "\n",
    "    b0 = float(res[\"coef\"][\"msci_ret_q\"])\n",
    "    b1 = float(res[\"coef\"][\"msci_ret_q_lag1\"])\n",
    "    p0 = float(res[\"p\"][\"msci_ret_q\"])\n",
    "    p1 = float(res[\"p\"][\"msci_ret_q_lag1\"])\n",
    "    use_beta = bool(usable and ((p0 < alpha_level) or (p1 < alpha_level)))\n",
    "\n",
    "    beta_rows_sg.append({\n",
    "        \"Adj Strategy\": s, \"Grade\": g,\n",
    "        \"b0\": b0, \"b1\": b1,\n",
    "        \"p_b0\": p0, \"p_b1\": p1,\n",
    "        \"n_obs\": res[\"n_obs\"], \"n_funds\": n_funds,\n",
    "        \"use_beta\": use_beta\n",
    "    })\n",
    "beta_sg = pd.DataFrame(beta_rows_sg)\n",
    "\n",
    "beta_rows_s = []\n",
    "for s, grp in cal.groupby([\"Adj Strategy\"], dropna=False):\n",
    "    res = ols_cluster_robust(grp, \"omega\", [\"msci_ret_q\", \"msci_ret_q_lag1\"], \"FundID\")\n",
    "    if res is None:\n",
    "        continue\n",
    "    n_funds = res[\"n_clusters\"]\n",
    "    usable = (n_funds >= min_clusters_for_inference)\n",
    "\n",
    "    b0 = float(res[\"coef\"][\"msci_ret_q\"])\n",
    "    b1 = float(res[\"coef\"][\"msci_ret_q_lag1\"])\n",
    "    p0 = float(res[\"p\"][\"msci_ret_q\"])\n",
    "    p1 = float(res[\"p\"][\"msci_ret_q_lag1\"])\n",
    "    use_beta = bool(usable and ((p0 < alpha_level) or (p1 < alpha_level)))\n",
    "\n",
    "    beta_rows_s.append({\n",
    "        \"Adj Strategy\": s, \"b0\": b0, \"b1\": b1,\n",
    "        \"p_b0\": p0, \"p_b1\": p1,\n",
    "        \"n_obs\": res[\"n_obs\"], \"n_funds\": n_funds,\n",
    "        \"use_beta\": use_beta\n",
    "    })\n",
    "beta_s = pd.DataFrame(beta_rows_s)\n",
    "\n",
    "res_g = ols_cluster_robust(cal, \"omega\", [\"msci_ret_q\", \"msci_ret_q_lag1\"], \"FundID\")\n",
    "if res_g is None:\n",
    "    raise ValueError(\"Global beta regression failed.\")\n",
    "b0_g = float(res_g[\"coef\"][\"msci_ret_q\"])\n",
    "b1_g = float(res_g[\"coef\"][\"msci_ret_q_lag1\"])\n",
    "\n",
    "beta_sg_use = beta_sg.loc[beta_sg[\"use_beta\"]].set_index([\"Adj Strategy\", \"Grade\"])[[\"b0\", \"b1\"]].to_dict(\"index\")\n",
    "beta_s_use = beta_s.loc[beta_s[\"use_beta\"]].set_index([\"Adj Strategy\"])[[\"b0\", \"b1\"]].to_dict(\"index\")\n",
    "\n",
    "def get_betas(strategy, grade):\n",
    "    k = (strategy, grade)\n",
    "    if k in beta_sg_use:\n",
    "        d = beta_sg_use[k]\n",
    "        return float(d[\"b0\"]), float(d[\"b1\"]), \"sg_sig\"\n",
    "    if strategy in beta_s_use:\n",
    "        d = beta_s_use[strategy]\n",
    "        return float(d[\"b0\"]), float(d[\"b1\"]), \"s_sig\"\n",
    "    return float(b0_g), float(b1_g), \"global\"\n",
    "\n",
    "# ============================================================\n",
    "# 2) Alpha: omega_adj mean tests (unchanged)\n",
    "# ============================================================\n",
    "cal2 = cal.copy()\n",
    "b0_used = []\n",
    "b1_used = []\n",
    "for _, r in cal2.iterrows():\n",
    "    b0, b1, _ = get_betas(r[\"Adj Strategy\"], r[\"Grade\"])\n",
    "    b0_used.append(b0); b1_used.append(b1)\n",
    "cal2[\"b0_used\"] = b0_used\n",
    "cal2[\"b1_used\"] = b1_used\n",
    "cal2[\"omega_adj\"] = cal2[\"omega\"] - cal2[\"b0_used\"]*cal2[\"msci_ret_q\"] - cal2[\"b1_used\"]*cal2[\"msci_ret_q_lag1\"]\n",
    "\n",
    "alpha_rows_sga = []\n",
    "for (s, g, a), grp in cal2.groupby([\"Adj Strategy\",\"Grade\",\"AgeBucket\"], dropna=False):\n",
    "    st = cluster_mean_stats(grp, \"omega_adj\", \"FundID\")\n",
    "    if st is None:\n",
    "        continue\n",
    "    use_alpha = bool((st[\"n_funds\"] >= min_clusters_for_inference) and (st[\"p_alpha\"] < alpha_level))\n",
    "    alpha_rows_sga.append({\"Adj Strategy\": s, \"Grade\": g, \"AgeBucket\": a, **st, \"use_alpha\": use_alpha})\n",
    "alpha_sga = pd.DataFrame(alpha_rows_sga)\n",
    "\n",
    "alpha_rows_sg = []\n",
    "for (s, g), grp in cal2.groupby([\"Adj Strategy\",\"Grade\"], dropna=False):\n",
    "    st = cluster_mean_stats(grp, \"omega_adj\", \"FundID\")\n",
    "    if st is None:\n",
    "        continue\n",
    "    use_alpha = bool((st[\"n_funds\"] >= min_clusters_for_inference) and (st[\"p_alpha\"] < alpha_level))\n",
    "    alpha_rows_sg.append({\"Adj Strategy\": s, \"Grade\": g, **st, \"use_alpha\": use_alpha})\n",
    "alpha_sg = pd.DataFrame(alpha_rows_sg)\n",
    "\n",
    "alpha_rows_s = []\n",
    "for s, grp in cal2.groupby([\"Adj Strategy\"], dropna=False):\n",
    "    st = cluster_mean_stats(grp, \"omega_adj\", \"FundID\")\n",
    "    if st is None:\n",
    "        continue\n",
    "    use_alpha = bool((st[\"n_funds\"] >= min_clusters_for_inference) and (st[\"p_alpha\"] < alpha_level))\n",
    "    alpha_rows_s.append({\"Adj Strategy\": s, **st, \"use_alpha\": use_alpha})\n",
    "alpha_s = pd.DataFrame(alpha_rows_s)\n",
    "\n",
    "st_g = cluster_mean_stats(cal2, \"omega_adj\", \"FundID\")\n",
    "alpha_global = float(st_g[\"alpha\"]) if st_g else 0.0\n",
    "\n",
    "alpha_sga_use = alpha_sga.loc[alpha_sga[\"use_alpha\"]].set_index([\"Adj Strategy\",\"Grade\",\"AgeBucket\"])[\"alpha\"].to_dict()\n",
    "alpha_sg_use  = alpha_sg.loc[alpha_sg[\"use_alpha\"]].set_index([\"Adj Strategy\",\"Grade\"])[\"alpha\"].to_dict()\n",
    "alpha_s_use   = alpha_s.loc[alpha_s[\"use_alpha\"]].set_index([\"Adj Strategy\"])[\"alpha\"].to_dict()\n",
    "\n",
    "def get_alpha(strategy, grade, age_bucket):\n",
    "    k = (strategy, grade, age_bucket)\n",
    "    if k in alpha_sga_use:\n",
    "        return float(alpha_sga_use[k]), \"sga_sig\"\n",
    "    k2 = (strategy, grade)\n",
    "    if k2 in alpha_sg_use:\n",
    "        return float(alpha_sg_use[k2]), \"sg_sig\"\n",
    "    if strategy in alpha_s_use:\n",
    "        return float(alpha_s_use[strategy]), \"s_sig\"\n",
    "    return float(alpha_global), \"global\"\n",
    "\n",
    "# ============================================================\n",
    "# 3) Sigma: pooled SG + shrink to global (unchanged)\n",
    "# ============================================================\n",
    "resid = []\n",
    "for _, r in cal.iterrows():\n",
    "    b0, b1, _ = get_betas(r[\"Adj Strategy\"], r[\"Grade\"])\n",
    "    a, _ = get_alpha(r[\"Adj Strategy\"], r[\"Grade\"], r[\"AgeBucket\"])\n",
    "    pred = a + b0*r[\"msci_ret_q\"] + b1*r[\"msci_ret_q_lag1\"]\n",
    "    resid.append(float(r[\"omega\"] - pred))\n",
    "\n",
    "cal_res = cal.copy()\n",
    "cal_res[\"resid\"] = resid\n",
    "\n",
    "sigma_sg = (\n",
    "    cal_res.groupby([\"Adj Strategy\",\"Grade\"], dropna=False)\n",
    "           .agg(n_obs=(\"resid\",\"size\"),\n",
    "                sigma=(\"resid\", lambda x: float(np.std(x, ddof=1)) if len(x) > 2 else 0.10))\n",
    "           .reset_index()\n",
    ")\n",
    "sigma_global = float(np.std(cal_res[\"resid\"], ddof=1))\n",
    "sigma_global = max(sigma_global, 0.02)\n",
    "\n",
    "sigma_sg_map = sigma_sg.set_index([\"Adj Strategy\",\"Grade\"])[[\"sigma\",\"n_obs\"]].to_dict(\"index\")\n",
    "\n",
    "def get_sigma(strategy, grade):\n",
    "    k = (strategy, grade)\n",
    "    if k in sigma_sg_map:\n",
    "        s = float(sigma_sg_map[k][\"sigma\"])\n",
    "        n = float(sigma_sg_map[k][\"n_obs\"])\n",
    "        w = n / (n + SIGMA_SHRINK_K)\n",
    "        return float(w*s + (1.0-w)*sigma_global), \"sg_shrunk\"\n",
    "    return float(sigma_global), \"global\"\n",
    "\n",
    "# -----------------------------\n",
    "# NAV_start imputation (unchanged)\n",
    "# -----------------------------\n",
    "hist_upto = data.loc[data[\"quarter_end\"] <= start_qe].copy()\n",
    "if hist_upto.empty:\n",
    "    raise ValueError(\"No data at or before chosen start quarter.\")\n",
    "\n",
    "hist_upto = hist_upto.sort_values([\"FundID\",\"quarter_end\"])\n",
    "base_rows = hist_upto.groupby(\"FundID\").tail(1).copy()\n",
    "\n",
    "base_rows[\"ever_overran\"] = base_rows[\"FundID\"].map(ever_overran_map).fillna(False)\n",
    "\n",
    "caps = []\n",
    "for _, r in base_rows.iterrows():\n",
    "    planned = r[\"planned_end_qe\"]\n",
    "    if pd.isna(planned):\n",
    "        caps.append(msci_future[\"quarter_end\"].iloc[-1])\n",
    "        continue\n",
    "    if bool(r[\"ever_overran\"]):\n",
    "        avg_over = float(avg_overrun_by_strategy.get(r[\"Adj Strategy\"], 0.0))\n",
    "        caps.append(add_quarters(planned, avg_over))\n",
    "    else:\n",
    "        caps.append(planned)\n",
    "base_rows[\"cap_qe\"] = caps\n",
    "base_rows[\"AgeBucket\"] = make_age_bucket_q(base_rows[\"Fund_Age_Quarters\"])\n",
    "\n",
    "hist_upto[\"draw_cum\"] = hist_upto.groupby(\"FundID\")[DRAW_COL].cumsum()\n",
    "if \"draw_cum\" not in base_rows.columns:\n",
    "    base_rows = base_rows.merge(\n",
    "        hist_upto.groupby(\"FundID\")[\"draw_cum\"].last().reset_index(),\n",
    "        on=\"FundID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "tmp = hist_upto.copy()\n",
    "tmp[\"AgeBucket\"] = make_age_bucket_q(tmp[\"Fund_Age_Quarters\"])\n",
    "\n",
    "tmp[\"ratio_nav_draw\"] = np.where(\n",
    "    (tmp[NAV_COL].notna()) & (tmp[NAV_COL].abs() > NAV_EPS) & (tmp[\"draw_cum\"] > DRAW_EPS),\n",
    "    tmp[NAV_COL] / tmp[\"draw_cum\"],\n",
    "    np.nan\n",
    ")\n",
    "tmp[\"ratio_nav_size\"] = np.where(\n",
    "    (tmp[NAV_COL].notna()) & (tmp[NAV_COL].abs() > NAV_EPS) & (tmp[SIZE_COL] > SIZE_EPS),\n",
    "    tmp[NAV_COL] / tmp[SIZE_COL],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "tmp[\"log_ratio_nav_draw\"] = np.log(tmp[\"ratio_nav_draw\"])\n",
    "tmp[\"log_ratio_nav_size\"] = np.log(tmp[\"ratio_nav_size\"])\n",
    "tmp.loc[~np.isfinite(tmp[\"log_ratio_nav_draw\"]), \"log_ratio_nav_draw\"] = np.nan\n",
    "tmp.loc[~np.isfinite(tmp[\"log_ratio_nav_size\"]), \"log_ratio_nav_size\"] = np.nan\n",
    "\n",
    "ratio_key = [\"Adj Strategy\",\"Grade\",\"AgeBucket\"]\n",
    "\n",
    "def fit_lognorm(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    g = df[col].dropna()\n",
    "    if len(g) < MIN_OBS_RATIO:\n",
    "        return pd.Series({\"mu\": np.nan, \"sig\": np.nan, \"n\": len(g)})\n",
    "    return pd.Series({\"mu\": float(g.mean()), \"sig\": float(g.std(ddof=1)), \"n\": len(g)})\n",
    "\n",
    "ratio_draw = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_draw\")).reset_index()\n",
    "ratio_size = tmp.groupby(ratio_key, dropna=False).apply(lambda g: fit_lognorm(g, \"log_ratio_nav_size\")).reset_index()\n",
    "\n",
    "gdraw = ratio_draw.dropna(subset=[\"mu\",\"sig\"])\n",
    "gsize = ratio_size.dropna(subset=[\"mu\",\"sig\"])\n",
    "fallback_draw = {\"mu\": float(gdraw[\"mu\"].median()) if len(gdraw) else 0.0,\n",
    "                 \"sig\": float(gdraw[\"sig\"].median()) if len(gdraw) else 0.75}\n",
    "fallback_size = {\"mu\": float(gsize[\"mu\"].median()) if len(gsize) else -2.0,\n",
    "                 \"sig\": float(gsize[\"sig\"].median()) if len(gsize) else 0.75}\n",
    "\n",
    "ratio_draw_map = ratio_draw.set_index(ratio_key)[[\"mu\",\"sig\",\"n\"]].to_dict(\"index\")\n",
    "ratio_size_map = ratio_size.set_index(ratio_key)[[\"mu\",\"sig\",\"n\"]].to_dict(\"index\")\n",
    "\n",
    "def lookup_ratio(map_, strategy, grade, age_bucket, fallback):\n",
    "    k = (strategy, grade, age_bucket)\n",
    "    if k in map_:\n",
    "        d = map_[k]\n",
    "        if pd.notna(d[\"mu\"]) and pd.notna(d[\"sig\"]) and d[\"n\"] >= MIN_OBS_RATIO:\n",
    "            return float(d[\"mu\"]), float(d[\"sig\"]), \"bucket\"\n",
    "    return float(fallback[\"mu\"]), float(fallback[\"sig\"]), \"global\"\n",
    "\n",
    "rng_init = np.random.default_rng(2025)\n",
    "base_rows[\"NAV_start\"] = base_rows[NAV_COL]\n",
    "base_rows[\"NAV_start_source\"] = \"observed\"\n",
    "\n",
    "for idx, r in base_rows.iterrows():\n",
    "    nav_obs = r[\"NAV_start\"]\n",
    "    if pd.notna(nav_obs) and abs(nav_obs) > NAV_EPS:\n",
    "        continue\n",
    "\n",
    "    draw_cum = r.get(\"draw_cum\", 0.0)\n",
    "    size = r.get(SIZE_COL, 0.0)\n",
    "    draw_cum = 0.0 if pd.isna(draw_cum) else float(draw_cum)\n",
    "    size = 0.0 if pd.isna(size) else float(size)\n",
    "\n",
    "    strategy = r[\"Adj Strategy\"]\n",
    "    grade = r.get(\"AssignedGrade\", r[\"Grade\"])\n",
    "    if pd.isna(grade):\n",
    "        grade = r[\"Grade\"]\n",
    "    age_bucket = r[\"AgeBucket\"]\n",
    "\n",
    "    if draw_cum > DRAW_EPS:\n",
    "        mu, sig, src = lookup_ratio(ratio_draw_map, strategy, grade, age_bucket, fallback_draw)\n",
    "        ratio = float(np.exp(mu + sig * rng_init.standard_normal()))\n",
    "        ratio = float(np.clip(ratio, 0.05, 5.0))\n",
    "        base_rows.at[idx, \"NAV_start\"] = ratio * draw_cum\n",
    "        base_rows.at[idx, \"NAV_start_source\"] = f\"imputed_draw_{src}\"\n",
    "    elif size > SIZE_EPS:\n",
    "        mu, sig, src = lookup_ratio(ratio_size_map, strategy, grade, age_bucket, fallback_size)\n",
    "        ratio = float(np.exp(mu + sig * rng_init.standard_normal()))\n",
    "        ratio = float(np.clip(ratio, 0.01, 2.0))\n",
    "        base_rows.at[idx, \"NAV_start\"] = ratio * size\n",
    "        base_rows.at[idx, \"NAV_start_source\"] = f\"imputed_size_{src}\"\n",
    "    else:\n",
    "        base_rows.at[idx, \"NAV_start\"] = 0.0\n",
    "        base_rows.at[idx, \"NAV_start_source\"] = \"imputed_zero_noinfo\"\n",
    "\n",
    "base_rows[\"NAV_start\"] = pd.to_numeric(base_rows[\"NAV_start\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# -----------------------------\n",
    "# Grade transitions (UNCHANGED, uses your saved 1Y matrices if present)\n",
    "# -----------------------------\n",
    "GRADE_STATES = [\"A\",\"B\",\"C\",\"D\"]\n",
    "MIN_TRANSITIONS = 30\n",
    "DEFAULT_YEARLY_CHANGE = 0.25\n",
    "\n",
    "# Load preferred 1Y matrices derived from 10Y root if present\n",
    "p1_all_path = os.path.join(DATA_DIR, \"grade_transition_1y_all.csv\")\n",
    "p1_pe_path  = os.path.join(DATA_DIR, \"grade_transition_1y_pe.csv\")\n",
    "p1_vc_path  = os.path.join(DATA_DIR, \"grade_transition_1y_vc.csv\")\n",
    "P1_ALL = pd.read_csv(p1_all_path, index_col=0) if os.path.exists(p1_all_path) else None\n",
    "P1_PE  = pd.read_csv(p1_pe_path, index_col=0) if os.path.exists(p1_pe_path) else None\n",
    "P1_VC  = pd.read_csv(p1_vc_path, index_col=0) if os.path.exists(p1_vc_path) else None\n",
    "\n",
    "def _row_norm_df(P):\n",
    "    P = P.reindex(index=GRADE_STATES, columns=GRADE_STATES).fillna(0.0).clip(lower=0.0)\n",
    "    rs = P.sum(axis=1).replace(0.0, 1.0)\n",
    "    return P.div(rs, axis=0)\n",
    "\n",
    "if P1_ALL is not None: P1_ALL = _row_norm_df(P1_ALL)\n",
    "if P1_PE  is not None: P1_PE  = _row_norm_df(P1_PE)\n",
    "if P1_VC  is not None: P1_VC  = _row_norm_df(P1_VC)\n",
    "\n",
    "def get_transition_matrix(strategy):\n",
    "    if strategy == \"Private Equity\" and P1_PE is not None:\n",
    "        return P1_PE, \"PE_1Y\"\n",
    "    if strategy == \"Venture Capital\" and P1_VC is not None:\n",
    "        return P1_VC, \"VC_1Y\"\n",
    "    if P1_ALL is not None:\n",
    "        return P1_ALL, \"ALL_1Y\"\n",
    "    # fallback identity\n",
    "    return pd.DataFrame(np.eye(4), index=GRADE_STATES, columns=GRADE_STATES), \"IDENTITY\"\n",
    "\n",
    "def get_yearly_change_prob(strategy):\n",
    "    # keep your fallback constant for now (you had richer estimation earlier; keep minimal here)\n",
    "    return DEFAULT_YEARLY_CHANGE\n",
    "\n",
    "def sample_next_grade(curr_grade, P_df, rng):\n",
    "    if curr_grade not in GRADE_STATES:\n",
    "        curr_grade = \"D\"\n",
    "    row = P_df.loc[curr_grade].values.astype(float)\n",
    "    return str(rng.choice(GRADE_STATES, p=row))\n",
    "\n",
    "# -----------------------------\n",
    "# PROJECTION LOOP: simulate omega only (NO NAV update)\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "omega_rows = []\n",
    "for _, r in base_rows.iterrows():\n",
    "    fund_id = r[\"FundID\"]\n",
    "    age0 = int(r[\"Fund_Age_Quarters\"]) if pd.notna(r[\"Fund_Age_Quarters\"]) else 0\n",
    "\n",
    "    strategy = r[\"Adj Strategy\"]\n",
    "    grade = r[\"Grade\"] if pd.notna(r[\"Grade\"]) else \"D\"\n",
    "\n",
    "    cap_qe = r[\"cap_qe\"]\n",
    "    if pd.isna(cap_qe):\n",
    "        cap_qe = msci_future[\"quarter_end\"].iloc[-1]\n",
    "\n",
    "    for step, (qe, msci_r, msci_r_lag1) in enumerate(\n",
    "        zip(msci_future[\"quarter_end\"], msci_future[\"msci_ret_q\"], msci_future[\"msci_ret_q_lag1\"]),\n",
    "        start=1\n",
    "    ):\n",
    "        if qe > cap_qe:\n",
    "            break\n",
    "\n",
    "        msci_r_lag1 = 0.0 if pd.isna(msci_r_lag1) else float(msci_r_lag1)\n",
    "\n",
    "        age = age0 + step\n",
    "        age_bucket = make_age_bucket_q(pd.Series([age])).iloc[0]\n",
    "\n",
    "        # Annual grade transition\n",
    "        prev_grade = grade\n",
    "        if step % 4 == 0:\n",
    "            pchg = get_yearly_change_prob(strategy)\n",
    "            if rng.random() < pchg:\n",
    "                P, _ = get_transition_matrix(strategy)\n",
    "                grade = sample_next_grade(grade, P, rng)\n",
    "\n",
    "        b0, b1, _ = get_betas(strategy, grade)\n",
    "        alpha, _ = get_alpha(strategy, grade, age_bucket)\n",
    "        sigma, _ = get_sigma(strategy, grade)\n",
    "\n",
    "        eps = rng.standard_normal()\n",
    "        omega = alpha + b0*float(msci_r) + b1*msci_r_lag1 + sigma*eps\n",
    "        if not np.isfinite(omega):\n",
    "            omega = 0.0\n",
    "        omega = float(np.clip(omega, -OMEGA_CLIP, OMEGA_CLIP))\n",
    "\n",
    "        omega_rows.append({\n",
    "            \"FundID\": fund_id,\n",
    "            \"quarter_end\": qe,\n",
    "            \"step_q\": step,\n",
    "            \"msci_ret_q\": float(msci_r),\n",
    "            \"msci_ret_q_lag1\": float(msci_r_lag1),\n",
    "            \"omega\": float(omega),\n",
    "\n",
    "            \"Fund_Age_Quarters\": int(age),\n",
    "            \"Adj Strategy\": strategy,\n",
    "            \"Grade_prev\": prev_grade,\n",
    "            \"Grade\": grade,\n",
    "            \"AgeBucket\": age_bucket,\n",
    "            \"cap_qe\": cap_qe,\n",
    "        })\n",
    "\n",
    "omega_proj = pd.DataFrame(omega_rows)\n",
    "print(\"\\nOmega rows:\", len(omega_proj))\n",
    "print(\"Omega funds:\", omega_proj[\"FundID\"].nunique())\n",
    "\n",
    "# -----------------------------\n",
    "# Save outputs\n",
    "# -----------------------------\n",
    "save = input(\"Save omega projection + NAV_start? (y/n) [y]: \").strip().lower()\n",
    "if save in {\"\", \"y\", \"yes\"}:\n",
    "    omega_csv = os.path.join(DATA_DIR, f\"omega_projection_sota_{year}_{quarter}_{n_q}q.csv\")\n",
    "    omega_pq  = os.path.join(DATA_DIR, f\"omega_projection_sota_{year}_{quarter}_{n_q}q.parquet\")\n",
    "\n",
    "    omega_proj.to_csv(omega_csv, index=False)\n",
    "    omega_proj.to_parquet(omega_pq, index=False)\n",
    "\n",
    "    navstart = base_rows[[\n",
    "        \"FundID\",\"Adj Strategy\",\"Grade\",\"Fund_Age_Quarters\",\"NAV_start\",\"NAV_start_source\",\"cap_qe\"\n",
    "    ]].copy()\n",
    "    navstart_csv = os.path.join(DATA_DIR, f\"nav_start_sota_{year}_{quarter}.csv\")\n",
    "    navstart_pq  = os.path.join(DATA_DIR, f\"nav_start_sota_{year}_{quarter}.parquet\")\n",
    "    navstart.to_csv(navstart_csv, index=False)\n",
    "    navstart.to_parquet(navstart_pq, index=False)\n",
    "\n",
    "    # Diagnostics tables (same as before; keep useful)\n",
    "    beta_sg.to_csv(os.path.join(DATA_DIR, \"cal_beta_strategy_grade.csv\"), index=False)\n",
    "    beta_s.to_csv(os.path.join(DATA_DIR, \"cal_beta_strategy.csv\"), index=False)\n",
    "    alpha_sga.to_csv(os.path.join(DATA_DIR, \"cal_alpha_strategy_grade_agebucket.csv\"), index=False)\n",
    "    sigma_sg.to_csv(os.path.join(DATA_DIR, \"cal_sigma_strategy_grade.csv\"), index=False)\n",
    "\n",
    "    print(\"\\nSaved:\")\n",
    "    print(omega_csv)\n",
    "    print(omega_pq)\n",
    "    print(navstart_csv)\n",
    "    print(navstart_pq)\n",
    "    print(\"Diagnostics saved (beta/alpha/sigma).\")\n",
    "\n",
    "print(\"\\nOmega projection head:\")\n",
    "print(omega_proj.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
